[
{
	"uri": "/post/",
	"title": "Posts",
	"tags": [],
	"description": "",
	"content": " Posts Convertion to new HUGO is still WIP\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/cont/pages/",
	"title": "Pages organization",
	"tags": [],
	"description": "",
	"content": " In Hugo, pages are the core of your site. Once it is configured, pages are definitely the added value to your documentation site.\nFolders Organize your site like any other Hugo project. Typically, you will have a content folder with all your pages.\ncontent ├── level-one │ ├── level-two │ │ ├── level-three │ │ │ ├── level-four │ │ │ │ ├── _index.md \u0026lt;-- /level-one/level-two/level-three/level-four │ │ │ │ ├── page-4-a.md \u0026lt;-- /level-one/level-two/level-three/level-four/page-4-a │ │ │ │ ├── page-4-b.md \u0026lt;-- /level-one/level-two/level-three/level-four/page-4-b │ │ │ │ └── page-4-c.md \u0026lt;-- /level-one/level-two/level-three/level-four/page-4-c │ │ │ ├── _index.md \u0026lt;-- /level-one/level-two/level-three │ │ │ ├── page-3-a.md \u0026lt;-- /level-one/level-two/level-three/page-3-a │ │ │ ├── page-3-b.md \u0026lt;-- /level-one/level-two/level-three/page-3-b │ │ │ └── page-3-c.md \u0026lt;-- /level-one/level-two/level-three/page-3-c │ │ ├── _index.md \u0026lt;-- /level-one/level-two │ │ ├── page-2-a.md \u0026lt;-- /level-one/level-two/page-2-a │ │ ├── page-2-b.md \u0026lt;-- /level-one/level-two/page-2-b │ │ └── page-2-c.md \u0026lt;-- /level-one/level-two/page-2-c │ ├── _index.md \u0026lt;-- /level-one │ ├── page-1-a.md \u0026lt;-- /level-one/page-1-a │ ├── page-1-b.md \u0026lt;-- /level-one/page-1-b │ └── page-1-c.md \u0026lt;-- /level-one/page-1-c ├── _index.md \u0026lt;-- / └── page-top.md \u0026lt;-- /page-top  _index.md is required in each folder, it’s your “folder home page”\n Types Hugo-theme-learn defines two types of pages. Default and Chapter. Both can be used at any level of the documentation, the only difference being layout display.\nA Chapter displays a page meant to be used as introduction for a set of child pages. Commonly, it contains a simple title and a catch line to define content that can be found under it. You can define any HTML as prefix for the menu. In the example below, it\u0026rsquo;s just a number but that could be an icon.\n+++ title = \u0026quot;Basics\u0026quot; chapter = true weight = 5 pre = \u0026quot;\u0026lt;b\u0026gt;1. \u0026lt;/b\u0026gt;\u0026quot; +++ ### Chapter 1 # Basics Discover what this Hugo theme is all about and the core-concepts behind it.  To tell Hugo-theme-learn to consider a page as a chapter, set chapter=true in the Front Matter of the page.\nA Default page is any other content page.\n+++ title = \u0026quot;Installation\u0026quot; weight = 15 +++  The following steps are here to help you initialize your new website. If you don\u0026rsquo;t know Hugo at all, we strongly suggest you to train by following this great documentation for beginners.\nCreate your project Hugo provides a new command to create a new website.\nhugo new site \u0026lt;new_project\u0026gt;  Hugo-theme-learn provides to help you create this kind of pages.\nFront Matter configuration Each Hugo page has to define a Front Matter in yaml, toml or json.\nHugo-theme-learn uses the following parameters on top of Hugo ones :\n+++ # Table of content (toc) is enabled by default. Set this parameter to true to disable it. # Note: Toc is always disabled for chapter pages disableToc = \u0026quot;false\u0026quot; # If set, this will be used for the page's menu entry (instead of the `title` attribute) menuTitle = \u0026quot;\u0026quot; # The title of the page in menu will be prefixed by this HTML content pre = \u0026quot;\u0026quot; # The title of the page in menu will be postfixed by this HTML content post = \u0026quot;\u0026quot; # Set the page as a chapter, changing the way it's displayed chapter = false # Hide a menu entry by setting this to true hidden = false # Display name of this page modifier. If set, it will be displayed in the footer. LastModifierDisplayName = \u0026quot;\u0026quot; # Email of this page modifier. If set with LastModifierDisplayName, it will be displayed in the footer LastModifierEmail = \u0026quot;\u0026quot; +++  Add icon to a menu entry In the page frontmatter, add a pre param to insert any HTML code before the menu label. The example below uses the Github icon.\n+++ title = \u0026quot;Github repo\u0026quot; pre = \u0026quot;\u0026lt;i class='fab fa-github'\u0026gt;\u0026lt;/i\u0026gt; \u0026quot; +++  Ordering sibling menu/page entries Hugo provides a flexible way to handle order for your pages.\nThe simplest way is to set weight parameter to a number.\n+++ title = \u0026quot;My page\u0026quot; weight = 5 +++  Using a custom title for menu entries By default, Hugo-theme-learn will use a page\u0026rsquo;s title attribute for the menu item (or linkTitle if defined).\nBut a page\u0026rsquo;s title has to be descriptive on its own while the menu is a hierarchy. We\u0026rsquo;ve added the menuTitle parameter for that purpose:\nFor example (for a page named content/install/linux.md):\n+++ title = \u0026quot;Install on Linux\u0026quot; menuTitle = \u0026quot;Linux\u0026quot; +++  Homepage To configure your home page, you basically have three choices:\n Create an _index.md document in content folder and fill the file with Markdown content Create an index.html file in the static folder and fill the file with HTML content Configure your server to automatically redirect home page to one your documentation page  "
},
{
	"uri": "/devops/",
	"title": "DevOps",
	"tags": [],
	"description": "This is devops tutorial page",
	"content": " DevOps This is a devops tutorial page\n"
},
{
	"uri": "/lte_to_5g/lte_and_5g_core_simulation/",
	"title": "EPC and 5GC",
	"tags": [],
	"description": "This is lte_to_5g/lte_and_5g_core_simulation tutorial page",
	"content": " LTE and 5G Core This is a lte_to_5g/lte_and_5g_core_simulation tutorial page\n"
},
{
	"uri": "/nfv/fd_io_and_opnfv/",
	"title": "FD.io &amp; OPNFV",
	"tags": [],
	"description": "This is nfv/fd_io_and_opnfv tutorial page",
	"content": " FD.io and OPNFV This is a nfv/fd_io_and_opnfv tutorial page\n"
},
{
	"uri": "/devops/git_gerrit/",
	"title": "Git/Gerrit",
	"tags": [],
	"description": "This is devops/git_gerrit tutorial page",
	"content": " GIT/GERRIT This is a devops/git_gerrit tutorial page\n"
},
{
	"uri": "/pi_cluster/os_installation/",
	"title": "Operating System",
	"tags": [],
	"description": "This is pi_cluster/os_installation tutorial page",
	"content": " OS Installation This is a pi_cluster/os_installation tutorial page\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/cont/archetypes/",
	"title": "Archetypes",
	"tags": [],
	"description": "",
	"content": " Using the command: hugo new [relative new content path], you can start a content file with the date and title automatically set. While this is a welcome feature, active writers need more : archetypes.\nIt is pre-configured skeleton pages with default front matter. Please refer to the documentation for types of page to understand the differences.\nChapter To create a Chapter page, run the following commands\nhugo new --kind chapter \u0026lt;name\u0026gt;/_index.md  It will create a page with predefined Front-Matter:\n+++ title = \u0026quot;{{ replace .Name \u0026quot;-\u0026quot; \u0026quot; \u0026quot; | title }}\u0026quot; date = {{ .Date }} weight = 5 chapter = true pre = \u0026quot;\u0026lt;b\u0026gt;X. \u0026lt;/b\u0026gt;\u0026quot; +++ ### Chapter X # Some Chapter title Lorem Ipsum.  Default To create a default page, run either one of the following commands\n# Either hugo new \u0026lt;chapter\u0026gt;/\u0026lt;name\u0026gt;/_index.md # Or hugo new \u0026lt;chapter\u0026gt;/\u0026lt;name\u0026gt;.md  It will create a page with predefined Front-Matter:\n+++ title = \u0026quot;{{ replace .Name \u0026quot;-\u0026quot; \u0026quot; \u0026quot; | title }}\u0026quot; date = {{ .Date }} weight = 5 +++ Lorem Ipsum.  "
},
{
	"uri": "/devops/cicd/",
	"title": "CI/CD",
	"tags": [],
	"description": "This is devops/cicd tutorial page",
	"content": " CI/CD This is a devops/cicd tutorial page\n"
},
{
	"uri": "/pi_cluster/docker_kubernetes/",
	"title": "Kubernetes",
	"tags": [],
	"description": "This is pi_cluster/docker_kubernetes tutorial page",
	"content": " Docker and Kubernetes This is a pi_cluster/docker_kubernetes tutorial page\n"
},
{
	"uri": "/lte_to_5g/lte_and_5g_ran_simulation/",
	"title": "LTE, eLTE and 5G RAN",
	"tags": [],
	"description": "This is lte_to_5g/lte_and_5g_ran_simulation tutorial page",
	"content": " LTE and 5G RAN This is a lte_to_5g/lte_and_5g_ran_simulation tutorial page\n"
},
{
	"uri": "/nfv/onap/",
	"title": "ONAP",
	"tags": [],
	"description": "This is nfv/onap tutorial page",
	"content": " ONAP This is a nfv/onap tutorial page\n"
},
{
	"uri": "/pi_cluster/",
	"title": "RPI Cluster",
	"tags": [],
	"description": "This is pi_cluster tutorial page",
	"content": " Rapsberry PI Cluster "
},
{
	"uri": "/devops/hugo_githubpages/hugo/basics/requirements/",
	"title": "Requirements",
	"tags": [],
	"description": "",
	"content": "Thanks to the simplicity of Hugo, this page is as empty as this theme needs requirements.\nJust download latest version of Hugo binary (\u0026gt; 0.25) for your OS (Windows, Linux, Mac) : it\u0026rsquo;s that simple.\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/cont/markdown/",
	"title": "Markdown syntax",
	"tags": [],
	"description": "",
	"content": " This page is a shameful copy of the great Grav original page. Only difference is information about image customization (resizing, add CSS classes\u0026hellip;)\n Let\u0026rsquo;s face it: Writing content for the Web is tiresome. WYSIWYG editors help alleviate this task, but they generally result in horrible code, or worse yet, ugly web pages.\nMarkdown is a better way to write HTML, without all the complexities and ugliness that usually accompanies it.\nSome of the key benefits are:\n Markdown is simple to learn, with minimal extra characters so it\u0026rsquo;s also quicker to write content. Less chance of errors when writing in markdown. Produces valid XHTML output. Keeps the content and the visual display separate, so you cannot mess up the look of your site. Write in any text editor or Markdown application you like. Markdown is a joy to use!  John Gruber, the author of Markdown, puts it like this:\n The overriding design goal for Markdown’s formatting syntax is to make it as readable as possible. The idea is that a Markdown-formatted document should be publishable as-is, as plain text, without looking like it’s been marked up with tags or formatting instructions. While Markdown’s syntax has been influenced by several existing text-to-HTML filters, the single biggest source of inspiration for Markdown’s syntax is the format of plain text email. \u0026ndash; John Gruber\n Grav ships with built-in support for Markdown and Markdown Extra. You must enable Markdown Extra in your system.yaml configuration file\nWithout further delay, let us go over the main elements of Markdown and what the resulting HTML looks like:\n Bookmark this page for easy future reference!\n Headings Headings from h1 through h6 are constructed with a # for each level:\n# h1 Heading ## h2 Heading ### h3 Heading #### h4 Heading ##### h5 Heading ###### h6 Heading  Renders to:\nh1 Heading h2 Heading h3 Heading h4 Heading h5 Heading h6 Heading HTML:\n\u0026lt;h1\u0026gt;h1 Heading\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;h2 Heading\u0026lt;/h2\u0026gt; \u0026lt;h3\u0026gt;h3 Heading\u0026lt;/h3\u0026gt; \u0026lt;h4\u0026gt;h4 Heading\u0026lt;/h4\u0026gt; \u0026lt;h5\u0026gt;h5 Heading\u0026lt;/h5\u0026gt; \u0026lt;h6\u0026gt;h6 Heading\u0026lt;/h6\u0026gt;  Comments Comments should be HTML compatible\n\u0026lt;!-- This is a comment --\u0026gt;  Comment below should NOT be seen:\nHorizontal Rules The HTML \u0026lt;hr\u0026gt; element is for creating a \u0026ldquo;thematic break\u0026rdquo; between paragraph-level elements. In markdown, you can create a \u0026lt;hr\u0026gt; with any of the following:\n ___: three consecutive underscores ---: three consecutive dashes ***: three consecutive asterisks  renders to:\nBody Copy Body copy written as normal, plain text will be wrapped with \u0026lt;p\u0026gt;\u0026lt;/p\u0026gt; tags in the rendered HTML.\nSo this body copy:\nLorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad.  renders to this HTML:\n\u0026lt;p\u0026gt;Lorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad.\u0026lt;/p\u0026gt;  Emphasis Bold For emphasizing a snippet of text with a heavier font-weight.\nThe following snippet of text is rendered as bold text.\n**rendered as bold text**  renders to:\nrendered as bold text\nand this HTML\n\u0026lt;strong\u0026gt;rendered as bold text\u0026lt;/strong\u0026gt;  Italics For emphasizing a snippet of text with italics.\nThe following snippet of text is rendered as italicized text.\n_rendered as italicized text_  renders to:\nrendered as italicized text\nand this HTML:\n\u0026lt;em\u0026gt;rendered as italicized text\u0026lt;/em\u0026gt;  strikethrough In GFM (GitHub flavored Markdown) you can do strikethroughs.\n~~Strike through this text.~~  Which renders to:\nStrike through this text.\nHTML:\n\u0026lt;del\u0026gt;Strike through this text.\u0026lt;/del\u0026gt;  Blockquotes For quoting blocks of content from another source within your document.\nAdd \u0026gt; before any text you want to quote.\n\u0026gt; **Fusion Drive** combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined.  Renders to:\n Fusion Drive combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined.\n and this HTML:\n\u0026lt;blockquote\u0026gt; \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Fusion Drive\u0026lt;/strong\u0026gt; combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined.\u0026lt;/p\u0026gt; \u0026lt;/blockquote\u0026gt;  Blockquotes can also be nested:\n\u0026gt; Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. \u0026gt;\u0026gt; Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam.  Renders to:\n Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. \u0026gt; Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam.\n Notices The old mechanism for notices overriding the block quote syntax (\u0026gt;\u0026gt;\u0026gt;) has been deprecated. Notices are now handled via a dedicated plugin called Markdown Notices\n Lists Unordered A list of items in which the order of the items does not explicitly matter.\nYou may use any of the following symbols to denote bullets for each list item:\n* valid bullet - valid bullet + valid bullet  For example\n+ Lorem ipsum dolor sit amet + Consectetur adipiscing elit + Integer molestie lorem at massa + Facilisis in pretium nisl aliquet + Nulla volutpat aliquam velit - Phasellus iaculis neque - Purus sodales ultricies - Vestibulum laoreet porttitor sem - Ac tristique libero volutpat at + Faucibus porta lacus fringilla vel + Aenean sit amet erat nunc + Eget porttitor lorem  Renders to:\n Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit  Phasellus iaculis neque Purus sodales ultricies Vestibulum laoreet porttitor sem Ac tristique libero volutpat at  Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem  And this HTML\n\u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;Lorem ipsum dolor sit amet\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Consectetur adipiscing elit\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Integer molestie lorem at massa\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Facilisis in pretium nisl aliquet\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Nulla volutpat aliquam velit \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;Phasellus iaculis neque\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Purus sodales ultricies\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Vestibulum laoreet porttitor sem\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Ac tristique libero volutpat at\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Faucibus porta lacus fringilla vel\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Aenean sit amet erat nunc\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Eget porttitor lorem\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt;  Ordered A list of items in which the order of items does explicitly matter.\n1. Lorem ipsum dolor sit amet 2. Consectetur adipiscing elit 3. Integer molestie lorem at massa 4. Facilisis in pretium nisl aliquet 5. Nulla volutpat aliquam velit 6. Faucibus porta lacus fringilla vel 7. Aenean sit amet erat nunc 8. Eget porttitor lorem  Renders to:\n Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem  And this HTML:\n\u0026lt;ol\u0026gt; \u0026lt;li\u0026gt;Lorem ipsum dolor sit amet\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Consectetur adipiscing elit\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Integer molestie lorem at massa\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Facilisis in pretium nisl aliquet\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Nulla volutpat aliquam velit\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Faucibus porta lacus fringilla vel\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Aenean sit amet erat nunc\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Eget porttitor lorem\u0026lt;/li\u0026gt; \u0026lt;/ol\u0026gt;  TIP: If you just use 1. for each number, Markdown will automatically number each item. For example:\n1. Lorem ipsum dolor sit amet 1. Consectetur adipiscing elit 1. Integer molestie lorem at massa 1. Facilisis in pretium nisl aliquet 1. Nulla volutpat aliquam velit 1. Faucibus porta lacus fringilla vel 1. Aenean sit amet erat nunc 1. Eget porttitor lorem  Renders to:\n Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem  Code Inline code Wrap inline snippets of code with `.\nIn this example, `\u0026lt;section\u0026gt;\u0026lt;/section\u0026gt;` should be wrapped as **code**.  Renders to:\nIn this example, \u0026lt;section\u0026gt;\u0026lt;/section\u0026gt; should be wrapped with code.\nHTML:\n\u0026lt;p\u0026gt;In this example, \u0026lt;code\u0026gt;\u0026amp;lt;section\u0026amp;gt;\u0026amp;lt;/section\u0026amp;gt;\u0026lt;/code\u0026gt; should be wrapped with \u0026lt;strong\u0026gt;code\u0026lt;/strong\u0026gt;.\u0026lt;/p\u0026gt;  Indented code Or indent several lines of code by at least four spaces, as in:\n // Some comments line 1 of code line 2 of code line 3 of code  Renders to:\n// Some comments line 1 of code line 2 of code line 3 of code  HTML:\n\u0026lt;pre\u0026gt; \u0026lt;code\u0026gt; // Some comments line 1 of code line 2 of code line 3 of code \u0026lt;/code\u0026gt; \u0026lt;/pre\u0026gt;  Block code \u0026ldquo;fences\u0026rdquo; Use \u0026ldquo;fences\u0026rdquo; ``` to block in multiple lines of code.\n ``` markup Sample text here... ```  Sample text here...  HTML:\n\u0026lt;pre\u0026gt; \u0026lt;code\u0026gt;Sample text here...\u0026lt;/code\u0026gt; \u0026lt;/pre\u0026gt;  Syntax highlighting GFM, or \u0026ldquo;GitHub Flavored Markdown\u0026rdquo; also supports syntax highlighting. To activate it, simply add the file extension of the language you want to use directly after the first code \u0026ldquo;fence\u0026rdquo;, `js, and syntax highlighting will automatically be applied in the rendered HTML. For example, to apply syntax highlighting to JavaScript code:\n ```js grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; ```  Renders to:\ngrunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } };  Tables Tables are created by adding pipes as dividers between each cell, and by adding a line of dashes (also separated by bars) beneath the header. Note that the pipes do not need to be vertically aligned.\n| Option | Description | | ------ | ----------- | | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. |  Renders to:\n   Option Description     data path to data files to supply the data that will be passed into templates.   engine engine to be used for processing templates. Handlebars is the default.   ext extension to be used for dest files.    And this HTML:\n\u0026lt;table\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Option\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Description\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;data\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;path to data files to supply the data that will be passed into templates.\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;engine\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;engine to be used for processing templates. Handlebars is the default.\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;ext\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;extension to be used for dest files.\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt;  Right aligned text Adding a colon on the right side of the dashes below any heading will right align text for that column.\n| Option | Description | | ------:| -----------:| | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. |     Option Description     data path to data files to supply the data that will be passed into templates.   engine engine to be used for processing templates. Handlebars is the default.   ext extension to be used for dest files.    Links Basic link [Assemble](http://assemble.io)  Renders to (hover over the link, there is no tooltip):\nAssemble\nHTML:\n\u0026lt;a href=\u0026quot;http://assemble.io\u0026quot;\u0026gt;Assemble\u0026lt;/a\u0026gt;  Add a title [Upstage](https://github.com/upstage/ \u0026quot;Visit Upstage!\u0026quot;)  Renders to (hover over the link, there should be a tooltip):\nUpstage\nHTML:\n\u0026lt;a href=\u0026quot;https://github.com/upstage/\u0026quot; title=\u0026quot;Visit Upstage!\u0026quot;\u0026gt;Upstage\u0026lt;/a\u0026gt;  Named Anchors Named anchors enable you to jump to the specified anchor point on the same page. For example, each of these chapters:\n# Table of Contents * [Chapter 1](#chapter-1) * [Chapter 2](#chapter-2) * [Chapter 3](#chapter-3)  will jump to these sections:\n## Chapter 1 \u0026lt;a id=\u0026quot;chapter-1\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; Content for chapter one. ## Chapter 2 \u0026lt;a id=\u0026quot;chapter-2\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; Content for chapter one. ## Chapter 3 \u0026lt;a id=\u0026quot;chapter-3\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; Content for chapter one.  NOTE that specific placement of the anchor tag seems to be arbitrary. They are placed inline here since it seems to be unobtrusive, and it works.\nImages Images have a similar syntax to links but include a preceding exclamation point.\n![Minion](https://octodex.github.com/images/minion.png)  or\n![Alt text](https://octodex.github.com/images/stormtroopocat.jpg \u0026quot;The Stormtroopocat\u0026quot;)  Like links, Images also have a footnote style syntax\nAlternative usage : note images ![Alt text][id]  With a reference later in the document defining the URL location:\n[id]: https://octodex.github.com/images/dojocat.jpg \u0026quot;The Dojocat\u0026quot;  Resizing image Add HTTP parameters width and/or height to the link image to resize the image. Values are CSS values (default is auto).\n![Minion](https://octodex.github.com/images/minion.png?width=20pc)  ![Minion](https://octodex.github.com/images/minion.png?height=50px)  ![Minion](https://octodex.github.com/images/minion.png?height=50px\u0026amp;width=300px)  Add CSS classes Add a HTTP classes parameter to the link image to add CSS classes. shadowand border are available but you could define other ones.\n![stormtroopocat](https://octodex.github.com/images/stormtroopocat.jpg?classes=shadow)  ![stormtroopocat](https://octodex.github.com/images/stormtroopocat.jpg?classes=border)  ![stormtroopocat](https://octodex.github.com/images/stormtroopocat.jpg?classes=border,shadow)  "
},
{
	"uri": "/nfv/akraino/",
	"title": "Akraino",
	"tags": [],
	"description": "This is nfv/akraino tutorial page",
	"content": " Akraino This is a nfv/akraino tutorial page\n"
},
{
	"uri": "/pi_cluster/maintenance/",
	"title": "Helm",
	"tags": [],
	"description": "This is pi_cluster/maintenance tutorial page",
	"content": " HELM This is a pi_cluster/maintenance tutorial page\n"
},
{
	"uri": "/devops/hugo_githubpages/",
	"title": "Hugo/GitHubPages",
	"tags": [],
	"description": "This is devops/hugo_githubpages tutorial page",
	"content": " Hugo and GitHub Pages This is a devops/hugo_githubpages tutorial page\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/basics/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": " The following steps are here to help you initialize your new website. If you don\u0026rsquo;t know Hugo at all, we strongly suggest you learn more about it by following this great documentation for beginners.\nCreate your project Hugo provides a new command to create a new website.\nhugo new site \u0026lt;new_project\u0026gt;  Install the theme Install the Hugo-theme-learn theme by following this documentation\nThis theme\u0026rsquo;s repository is: https://github.com/matcornic/hugo-theme-learn.git\nAlternatively, you can download the theme as .zip file and extract it in the themes directory\nBasic configuration When building the website, you can set a theme by using --theme option. However, we suggest you modify the configuration file (config.toml) and set the theme as the default. You can also add the [outputs] section to enable the search functionality.\n# Change the default theme to be use when building the site with Hugo theme = \u0026quot;hugo-theme-learn\u0026quot; # For search functionality [outputs] home = [ \u0026quot;HTML\u0026quot;, \u0026quot;RSS\u0026quot;, \u0026quot;JSON\u0026quot;]  Create your first chapter page Chapters are pages that contain other child pages. It has a special layout style and usually just contains a chapter name, the title and a brief abstract of the section.\n### Chapter 1 # Basics Discover what this Hugo theme is all about and the core concepts behind it.  renders as\nHugo-theme-learn provides archetypes to create skeletons for your website. Begin by creating your first chapter page with the following command\nhugo new --kind chapter basics/_index.md  By opening the given file, you should see the property chapter=true on top, meaning this page is a chapter.\nBy default all chapters and pages are created as a draft. If you want to render these pages, remove the property draft: true from the metadata.\nCreate your first content pages Then, create content pages inside the previously created chapter. Here are two ways to create content in the chapter:\nhugo new basics/first-content.md hugo new basics/second-content/_index.md  Feel free to edit thoses files by adding some sample content and replacing the title value in the beginning of the files.\nLaunching the website locally Launch by using the following command:\nhugo serve  Go to http://localhost:1313\nYou should notice three things:\n You have a left-side Basics menu, containing two submenus with names equal to the title properties in the previously created files. The home page explains how to customize it by following the instructions. When you run hugo serve, when the contents of the files change, the page automatically refreshes with the changes. Neat!  Build the website When your site is ready to deploy, run the following command:\nhugo  A public folder will be generated, containing all static content and assets for your website. It can now be deployed on any web server.\nThis website can be automatically published and hosted with Netlify (Read more about Automated HUGO deployments with Netlify). Alternatively, you can use Github pages\n "
},
{
	"uri": "/lte_to_5g/",
	"title": "LTE to 5G Simulations",
	"tags": [],
	"description": "This is lte_to_5g tutorial page",
	"content": " LTE to 5G Transition This is a lte_to_5g tutorial page\n"
},
{
	"uri": "/lte_to_5g/rpi_wifi_bluetooth/",
	"title": "Spectrum",
	"tags": [],
	"description": "This is lte_to_5g/rpi_wifi_bluetooth tutorial page",
	"content": " WIFI AP and Bluetook PAN This is a lte_to_5g/rpi_wifi_bluetooth tutorial page\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/basics/configuration/",
	"title": "Configuration",
	"tags": [],
	"description": "",
	"content": " Global site parameters On top of Hugo global configuration, Hugo-theme-learn lets you define the following parameters in your config.toml (here, values are default).\nNote that some of these parameters are explained in details in other sections of this documentation.\n[params] # Prefix URL to edit current page. Will display an \u0026quot;Edit this page\u0026quot; button on top right hand corner of every page. # Useful to give opportunity to people to create merge request for your doc. # See the config.toml file from this documentation site to have an example. editURL = \u0026quot;\u0026quot; # Author of the site, will be used in meta information author = \u0026quot;\u0026quot; # Description of the site, will be used in meta information description = \u0026quot;\u0026quot; # Shows a checkmark for visited pages on the menu showVisitedLinks = false # Disable search function. It will hide search bar disableSearch = false # Javascript and CSS cache are automatically busted when new version of site is generated. # Set this to true to disable this behavior (some proxies don't handle well this optimization) disableAssetsBusting = false # Set this to true to disable copy-to-clipboard button for inline code. disableInlineCopyToClipBoard = false # A title for shortcuts in menu is set by default. Set this to true to disable it. disableShortcutsTitle = false # When using mulitlingual website, disable the switch language button. disableLanguageSwitchingButton = false # Order sections in menu by \u0026quot;weight\u0026quot; or \u0026quot;title\u0026quot;. Default to \u0026quot;weight\u0026quot; ordersectionsby = \u0026quot;weight\u0026quot; # Change default color scheme with a variant one. Can be \u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;green\u0026quot;. themeVariant = \u0026quot;\u0026quot;  Activate search If not already present, add the follow lines in the same config.toml file.\n[outputs] home = [ \u0026quot;HTML\u0026quot;, \u0026quot;RSS\u0026quot;, \u0026quot;JSON\u0026quot;]  Learn theme uses the last improvement available in hugo version 20+ to generate a json index file ready to be consumed by lunr.js javascript search engine.\n Hugo generate lunrjs index.json at the root of public folder. When you build the site with hugo server, hugo generates it internally and of course it doesn’t show up in the filesystem\n "
},
{
	"uri": "/devops/kubedgesdk/",
	"title": "Kubedge SDK",
	"tags": [],
	"description": "This is devops/kubedgesdk tutorial page",
	"content": " KUBEDGE SDK This is a devops/kubedgesdk tutorial page\n"
},
{
	"uri": "/pi_cluster/microservices/",
	"title": "MicroServices",
	"tags": [],
	"description": "This is pi_cluster/microservices tutorial page",
	"content": " Micro Services This is a pi_cluster/microservices tutorial page\n Build and Deploy Kubernetes test-infra   Goal test-infra seems to somewhat overlap with sonobuoy features. The purpose of this post is to fetch the code, compile and deploy it on a Kubernetes cluster. Key Aspects Compile and deploy the test-infra code in test-infra Deploy WIP Conclusion WIP Reference Links Official test-infra Code  Creating simple Python server container  Goal As we did for Go and Java, where is was possible to create an Dockerfile starting from \u0026ldquo;scratch\u0026rdquo;, the goal of this post is to create a python base server container with a minimum about of packages (debian and python) to reduce the security exposure of the container as well as the image size. Key Aspects Use SCRATCH has base image to keep size minimum Simple HelloWorld Python web server Create associated HELM chart for Kubernetes deployment Provide deployment for both amd64 and arm32v7 Simple Python Server The pythonhttpserver repo showcases: - How to create a simple Python3 server - How to leverage Travis to compile for amd64 and arm32v7.\n Creating simple GO server container  Goal Use SCRATCH has base image to keep size minimum Simple HelloWorld GO web server Create associated HELM chart for Kubernetes deployment Provide deployment for both amd64 and arm32v7 Simple GO Server compilation The gohttpserver repo showcases: - How to compile a GO process - How to leverage Travis to compile for amd64 and arm32v7. - Branch amd64 is for normal PC and HP server. - Branch arm32v7 produces software usable on Raspberry PI 3B+\n Creating simple Java 10 server container  Goal Very often people associated Java to quite bulky and difficult to use in the microservice context, unless you have very large image containing the JRE. But since Java 9, Java did kind of catchup with golang on the subject. Where you can obtain a standalone executable when we running go build, java is now proposing jlink which always you to acheive a very similar result. The goal of this post is to build a container image as small as possible running Java.\n Setup your GOLANG environment  Goal A lot of the opensource projects evolvoving around Kubernetes are written in go. It is very usefull to be able to rebuild so projects using go get or go build. Installing the right version of GO If you have strange errors, when running go get \u0026hellip;., chances are that your version of GO is old. On Ubuntu, it is actually quite simple to address the issue. If you are still running Ubuntu 16.\n "
},
{
	"uri": "/nfv/",
	"title": "NFV/SDN/Network Slicing",
	"tags": [],
	"description": "This is nfv tutorial page",
	"content": " Network Slicing "
},
{
	"uri": "/lte_to_5g/nsa_and_sa/",
	"title": "NSA vs SA. Option 3",
	"tags": [],
	"description": "This is lte_to_5g/nsa_and_sa tutorial page",
	"content": " NSA and SA This is a lte_to_5g/nsa_and_sa tutorial page\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/cont/menushortcuts/",
	"title": "Menu extra shortcuts",
	"tags": [],
	"description": "",
	"content": " You can define additional menu entries or shortcuts in the navigation menu without any link to content.\nBasic configuration Edit the website configuration config.toml and add a [[menu.shortcuts]] entry for each link your want to add.\nExample from the current website:\n[[menu.shortcuts]] name = \u0026quot;\u0026lt;i class='fab fa-github'\u0026gt;\u0026lt;/i\u0026gt; Github repo\u0026quot; identifier = \u0026quot;ds\u0026quot; url = \u0026quot;https://github.com/matcornic/hugo-theme-learn\u0026quot; weight = 10 [[menu.shortcuts]] name = \u0026quot;\u0026lt;i class='fas fa-camera'\u0026gt;\u0026lt;/i\u0026gt; Showcases\u0026quot; url = \u0026quot;/showcase\u0026quot; weight = 11 [[menu.shortcuts]] name = \u0026quot;\u0026lt;i class='fas fa-bookmark'\u0026gt;\u0026lt;/i\u0026gt; Hugo Documentation\u0026quot; identifier = \u0026quot;hugodoc\u0026quot; url = \u0026quot;https://gohugo.io/\u0026quot; weight = 20 [[menu.shortcuts]] name = \u0026quot;\u0026lt;i class='fas fa-bullhorn'\u0026gt;\u0026lt;/i\u0026gt; Credits\u0026quot; url = \u0026quot;/credits\u0026quot; weight = 30  By default, shortcuts are preceded by a title. This title can be disabled by setting disableShortcutsTitle=true. However, if you want to keep the title but change its value, it can be overriden by changing your local i18n translation string configuration.\nFor example, in your local i18n/en.toml file, add the following content\n[Shortcuts-Title] other = \u0026quot;\u0026lt;Your value\u0026gt;\u0026quot;  Read more about hugo menu and hugo i18n translation strings\nConfiguration for Multilingual mode When using a multilingual website, you can set different menus for each language. In the config.toml file, prefix your menu configuration by Languages.\u0026lt;language-id\u0026gt;.\nExample from the current website:\n[Languages] [Languages.en] title = \u0026quot;Documentation for Hugo Learn Theme\u0026quot; weight = 1 languageName = \u0026quot;English\u0026quot; [[Languages.en.menu.shortcuts]] name = \u0026quot;\u0026lt;i class='fab fa-github'\u0026gt;\u0026lt;/i\u0026gt; Github repo\u0026quot; identifier = \u0026quot;ds\u0026quot; url = \u0026quot;https://github.com/matcornic/hugo-theme-learn\u0026quot; weight = 10 [[Languages.en.menu.shortcuts]] name = \u0026quot;\u0026lt;i class='fas fa-camera'\u0026gt;\u0026lt;/i\u0026gt; Showcases\u0026quot; url = \u0026quot;/showcase\u0026quot; weight = 11 [[Languages.en.menu.shortcuts]] name = \u0026quot;\u0026lt;i class='fas fa-bookmark'\u0026gt;\u0026lt;/i\u0026gt; Hugo Documentation\u0026quot; identifier = \u0026quot;hugodoc\u0026quot; url = \u0026quot;https://gohugo.io/\u0026quot; weight = 20 [[Languages.en.menu.shortcuts]] name = \u0026quot;\u0026lt;i class='fas fa-bullhorn'\u0026gt;\u0026lt;/i\u0026gt; Credits\u0026quot; url = \u0026quot;/credits\u0026quot; weight = 30 [Languages.fr] title = \u0026quot;Documentation du thème Hugo Learn\u0026quot; weight = 2 languageName = \u0026quot;Français\u0026quot; [[Languages.fr.menu.shortcuts]] name = \u0026quot;\u0026lt;i class='fab fa-github'\u0026gt;\u0026lt;/i\u0026gt; Repo Github\u0026quot; identifier = \u0026quot;ds\u0026quot; url = \u0026quot;https://github.com/matcornic/hugo-theme-learn\u0026quot; weight = 10 [[Languages.fr.menu.shortcuts]] name = \u0026quot;\u0026lt;i class='fas fa-camera'\u0026gt;\u0026lt;/i\u0026gt; Vitrine\u0026quot; url = \u0026quot;/showcase\u0026quot; weight = 11 [[Languages.fr.menu.shortcuts]] name = \u0026quot;\u0026lt;i class='fas fa-bookmark'\u0026gt;\u0026lt;/i\u0026gt; Documentation Hugo\u0026quot; identifier = \u0026quot;hugodoc\u0026quot; url = \u0026quot;https://gohugo.io/\u0026quot; weight = 20 [[Languages.fr.menu.shortcuts]] name = \u0026quot;\u0026lt;i class='fas fa-bullhorn'\u0026gt;\u0026lt;/i\u0026gt; Crédits\u0026quot; url = \u0026quot;/credits\u0026quot; weight = 30  Read more about hugo menu and hugo multilingual menus\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/basics/style-customization/",
	"title": "Style customization",
	"tags": [],
	"description": "",
	"content": " Hugo-theme-learn has been built to be as configurable as possible by defining multiple partials\nIn themes/hugo-theme-learn/layouts/partials/, you will find all the partials defined for this theme. If you need to overwrite something, don\u0026rsquo;t change the code directly. Instead follow this page. You\u0026rsquo;d create a new partial in the layouts/partials folder of your local project. This partial will have the priority.\nThis theme defines the following partials :\n header: the header of the content page (contains the breadcrumbs). Not meant to be overwritten custom-header: custom headers in page. Meant to be overwritten when adding CSS imports. Don\u0026rsquo;t forget to include style HTML tag directive in your file footer: the footer of the content page (contains the arrows). Not meant to be overwritten custom-footer: custom footer in page. Meant to be overwritten when adding Javacript. Don\u0026rsquo;t forget to include javascript HTML tag directive in your file favicon: the favicon logo: the logo, on top left hand corner. meta: HTML meta tags, if you want to change default behavior menu: left menu. Not meant to be overwritten menu-footer: footer of the the left menu search: search box toc: table of contents  Change the logo Create a new file in layouts/partials/ named logo.html. Then write any HTML you want. You could use an img HTML tag and reference an image created under the static folder, or you could paste a SVG definition !\nThe size of the logo will adapt automatically\n Change the favicon If your favicon is a png, just drop off your image in your local static/images/ folder and name it favicon.png\nIf you need to change this default behavior, create a new file in layouts/partials/ named favicon.html. Then write something like this:\n\u0026lt;link rel=\u0026quot;shortcut icon\u0026quot; href=\u0026quot;/images/favicon.png\u0026quot; type=\u0026quot;image/x-icon\u0026quot; /\u0026gt;  Change default colors Hugo Learn theme let you choose between 3 native color scheme variants, but feel free to add one yourself ! Default color scheme is based on Grav Learn Theme.\nRed variant [params] # Change default color scheme with a variant one. Can be \u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;green\u0026quot;. themeVariant = \u0026quot;red\u0026quot;  Blue variant [params] # Change default color scheme with a variant one. Can be \u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;green\u0026quot;. themeVariant = \u0026quot;blue\u0026quot;  Green variant [params] # Change default color scheme with a variant one. Can be \u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;green\u0026quot;. themeVariant = \u0026quot;green\u0026quot;  \u0026lsquo;Yours‘ variant First, create a new CSS file in your local static/css folder prefixed by theme (e.g. with mine theme static/css/theme-mine.css). Copy the following content and modify colors in CSS variables.\n:root{ --MAIN-TEXT-color:#323232; /* Color of text by default */ --MAIN-TITLES-TEXT-color: #5e5e5e; /* Color of titles h2-h3-h4-h5 */ --MAIN-LINK-color:#1C90F3; /* Color of links */ --MAIN-LINK-HOVER-color:#167ad0; /* Color of hovered links */ --MAIN-ANCHOR-color: #1C90F3; /* color of anchors on titles */ --MENU-HEADER-BG-color:#1C90F3; /* Background color of menu header */ --MENU-HEADER-BORDER-color:#33a1ff; /*Color of menu header border */ --MENU-SEARCH-BG-color:#167ad0; /* Search field background color (by default borders + icons) */ --MENU-SEARCH-BOX-color: #33a1ff; /* Override search field border color */ --MENU-SEARCH-BOX-ICONS-color: #a1d2fd; /* Override search field icons color */ --MENU-SECTIONS-ACTIVE-BG-color:#20272b; /* Background color of the active section and its childs */ --MENU-SECTIONS-BG-color:#252c31; /* Background color of other sections */ --MENU-SECTIONS-LINK-color: #ccc; /* Color of links in menu */ --MENU-SECTIONS-LINK-HOVER-color: #e6e6e6; /* Color of links in menu, when hovered */ --MENU-SECTION-ACTIVE-CATEGORY-color: #777; /* Color of active category text */ --MENU-SECTION-ACTIVE-CATEGORY-BG-color: #fff; /* Color of background for the active category (only) */ --MENU-VISITED-color: #33a1ff; /* Color of 'page visited' icons in menu */ --MENU-SECTION-HR-color: #20272b; /* Color of \u0026lt;hr\u0026gt; separator in menu */ } body { color: var(--MAIN-TEXT-color) !important; } textarea:focus, input[type=\u0026quot;email\u0026quot;]:focus, input[type=\u0026quot;number\u0026quot;]:focus, input[type=\u0026quot;password\u0026quot;]:focus, input[type=\u0026quot;search\u0026quot;]:focus, input[type=\u0026quot;tel\u0026quot;]:focus, input[type=\u0026quot;text\u0026quot;]:focus, input[type=\u0026quot;url\u0026quot;]:focus, input[type=\u0026quot;color\u0026quot;]:focus, input[type=\u0026quot;date\u0026quot;]:focus, input[type=\u0026quot;datetime\u0026quot;]:focus, input[type=\u0026quot;datetime-local\u0026quot;]:focus, input[type=\u0026quot;month\u0026quot;]:focus, input[type=\u0026quot;time\u0026quot;]:focus, input[type=\u0026quot;week\u0026quot;]:focus, select[multiple=multiple]:focus { border-color: none; box-shadow: none; } h2, h3, h4, h5 { color: var(--MAIN-TITLES-TEXT-color) !important; } a { color: var(--MAIN-LINK-color); } .anchor { color: var(--MAIN-ANCHOR-color); } a:hover { color: var(--MAIN-LINK-HOVER-color); } #sidebar ul li.visited \u0026gt; a .read-icon { color: var(--MENU-VISITED-color); } #body a.highlight:after { display: block; content: \u0026quot;\u0026quot;; height: 1px; width: 0%; -webkit-transition: width 0.5s ease; -moz-transition: width 0.5s ease; -ms-transition: width 0.5s ease; transition: width 0.5s ease; background-color: var(--MAIN-LINK-HOVER-color); } #sidebar { background-color: var(--MENU-SECTIONS-BG-color); } #sidebar #header-wrapper { background: var(--MENU-HEADER-BG-color); color: var(--MENU-SEARCH-BOX-color); border-color: var(--MENU-HEADER-BORDER-color); } #sidebar .searchbox { border-color: var(--MENU-SEARCH-BOX-color); background: var(--MENU-SEARCH-BG-color); } #sidebar ul.topics \u0026gt; li.parent, #sidebar ul.topics \u0026gt; li.active { background: var(--MENU-SECTIONS-ACTIVE-BG-color); } #sidebar .searchbox * { color: var(--MENU-SEARCH-BOX-ICONS-color); } #sidebar a { color: var(--MENU-SECTIONS-LINK-color); } #sidebar a:hover { color: var(--MENU-SECTIONS-LINK-HOVER-color); } #sidebar ul li.active \u0026gt; a { background: var(--MENU-SECTION-ACTIVE-CATEGORY-BG-color); color: var(--MENU-SECTION-ACTIVE-CATEGORY-color) !important; } #sidebar hr { border-color: var(--MENU-SECTION-HR-color); }  Then, set the themeVariant value with the name of your custom theme file. That\u0026rsquo;s it !\n[params] # Change default color scheme with a variant one. Can be \u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;green\u0026quot;. themeVariant = \u0026quot;mine\u0026quot;  "
},
{
	"uri": "/devops/advanced/",
	"title": "Advanced &amp; WIP",
	"tags": [],
	"description": "Advanced tutorials and Work In Progress",
	"content": " Advanced This is a devops/advanced tutorial page\n"
},
{
	"uri": "/lte_to_5g/advanced/",
	"title": "Advanced &amp; WIP",
	"tags": [],
	"description": "Advanced tutorials and Work In Progress",
	"content": " Advanced This is a lte_to_5g/advanced tutorial page\n"
},
{
	"uri": "/nfv/advanced/",
	"title": "Advanced &amp; WIP",
	"tags": [],
	"description": "Advanced tutorials and Work In Progress",
	"content": " Advanced This is a pi_cluster/advanced tutorial page\n"
},
{
	"uri": "/pi_cluster/advanced/",
	"title": "Advanced &amp; WIP",
	"tags": [],
	"description": "Advanced tutorials and Work In Progress",
	"content": " Advanced This is a devops/advanced tutorial page\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/cont/icons/",
	"title": "Icons and logos",
	"tags": [],
	"description": "",
	"content": " The Learn theme for Hugo loads the Font Awesome library, allowing you to easily display any icon or logo available in the Font Awesome free collection.\nFinding an icon Browse through the available icons in the Font Awesome Gallery. Notice that the free filter is enabled, as only the free icons are available by default.\nOnce on the Font Awesome page for a specific icon, for example the page for the heart, copy the HTML reference and paste into the markdown content.\nThe HTML to include the heart icon is:\n\u0026lt;i class=\u0026quot;fas fa-heart\u0026quot;\u0026gt;\u0026lt;/i\u0026gt;  Including in markdown Paste the \u0026lt;i\u0026gt; HTML into markup and Font Awesome will load the relevant icon.\nBuilt with \u0026lt;i class=\u0026quot;fas fa-heart\u0026quot;\u0026gt;\u0026lt;/i\u0026gt; from Grav and Hugo  Which appears as\nBuilt with  from Grav and Hugo\nCustomising icons Font Awesome provides many ways to modify the icon\n Change colour (by default the icon will inherit the parent colour) Increase or decrease size Rotate Combine with other icons  Check the full documentation on web fonts with CSS for more.\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/cont/i18n/",
	"title": "Multilingual and i18n",
	"tags": [],
	"description": "",
	"content": " Learn theme is fully compatible with Hugo multilingual mode.\nIt provides:\n Translation strings for default values (English and French). Feel free to contribute ! Automatic menu generation from multilingual content In-browser language switching  Basic configuration After learning how Hugo handle multilingual websites, define your languages in your config.toml file.\nFor example with current French and English website.\n# English is the default language defaultContentLanguage = \u0026quot;en\u0026quot; # Force to have /en/my-page and /fr/my-page routes, even for default language. defaultContentLanguageInSubdir= true [Languages] [Languages.en] title = \u0026quot;Documentation for Hugo Learn Theme\u0026quot; weight = 1 languageName = \u0026quot;English\u0026quot; [Languages.fr] title = \u0026quot;Documentation du thème Hugo Learn\u0026quot; weight = 2 languageName = \u0026quot;Français\u0026quot;  Then, for each new page, append the id of the language to the file.\n Single file my-page.md is split in two files:  in English: my-page.en.md in French: my-page.fr.md  Single file _index.md is split in two files:  in English: _index.en.md in French: _index.fr.md   Be aware that only translated pages are displayed in menu. It\u0026rsquo;s not replaced with default language content.\n Use slug Front Matter parameter to translate urls too.\n Overwrite translation strings Translations strings are used for common default values used in the theme (Edit this page button, Search placeholder and so on). Translations are available in french and english but you may use another language or want to override default values.\nTo override these values, create a new file in your local i18n folder i18n/\u0026lt;idlanguage\u0026gt;.toml and inspire yourself from the theme themes/hugo-theme-learn/i18n/en.toml\nBy the way, as these translations could be used by other people, please take the time to propose a translation by making a PR to the theme !\nDisable language switching Switching the language in the browser is a great feature, but for some reasons you may want to disable it.\nJust set disableLanguageSwitchingButton=true in your config.toml\n[params] # When using mulitlingual website, disable the switch language button. disableLanguageSwitchingButton = true  "
},
{
	"uri": "/about/",
	"title": "About KUBEDGE",
	"tags": [],
	"description": "",
	"content": " About WIP\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/basics/",
	"title": "Basics",
	"tags": [],
	"description": "",
	"content": " Chapter 11 Basics Discover what this Hugo theme is all about and the core-concepts behind it.\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/cont/",
	"title": "Content",
	"tags": [],
	"description": "",
	"content": " Chapter 12 Content Find out how to create and organize your content quickly and intuitively.\n"
},
{
	"uri": "/pi_cluster/maintenance/children/2018-09-28-a/",
	"title": "Upgrade RPI Kubernetes cluster to 1.12",
	"tags": ["kubernetes", "rpi"],
	"description": "",
	"content": " Goal The new Kubernetes 1.12 is out. THe goal is to update my two clusters to 1.12 using kubeadm 1.12\nMaster node upgrade using kubeadm # apt-mark unhold kubeadm \u0026amp;\u0026amp; \\ \u0026gt; apt-get update \u0026amp;\u0026amp; apt-get install -y kubeadm \u0026amp;\u0026amp; \\ \u0026gt; apt-mark hold kubeadm kubeadm was already not hold. Hit:2 http://raspbian.raspberrypi.org/raspbian stretch InRelease Hit:3 https://download.docker.com/linux/raspbian stretch InRelease Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease Hit:5 http://archive.raspberrypi.org/debian stretch InRelease Hit:4 https://packagecloud.io/Hypriot/rpi/debian stretch InRelease Reading package lists... Done Reading package lists... Done Building dependency tree Reading state information... Done The following packages will be upgraded: kubeadm 1 upgraded, 0 newly installed, 0 to remove and 38 not upgraded. Need to get 8,095 kB of archives. After this operation, 3,100 kB disk space will be freed. Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main armhf kubeadm armhf 1.12.0-00 [8,095 kB] Fetched 8,095 kB in 4s (1,962 kB/s) (Reading database ... 30574 files and directories currently installed.) Preparing to unpack .../kubeadm_1.12.0-00_armhf.deb ... Unpacking kubeadm (1.12.0-00) over (1.11.1-00) ... Setting up kubeadm (1.12.0-00) ... kubeadm set on hold.  sudo kubeadm upgrade plan [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [upgrade] Fetching available versions to upgrade to [upgrade/versions] Cluster version: v1.11.0 [upgrade/versions] kubeadm version: v1.12.0 [upgrade/versions] Latest stable version: v1.12.0 [upgrade/versions] Latest version in the v1.11 series: v1.11.3 Components that must be upgraded manually after you have upgraded the control plane with 'kubeadm upgrade apply': COMPONENT CURRENT AVAILABLE Kubelet 3 x v1.11.1 v1.11.3 Upgrade to the latest version in the v1.11 series: COMPONENT CURRENT AVAILABLE API Server v1.11.0 v1.11.3 Controller Manager v1.11.0 v1.11.3 Scheduler v1.11.0 v1.11.3 Kube Proxy v1.11.0 v1.11.3 CoreDNS 1.1.3 1.2.2 Etcd 3.2.18 3.2.18 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.11.3 _____________________________________________________________________ Components that must be upgraded manually after you have upgraded the control plane with 'kubeadm upgrade apply': COMPONENT CURRENT AVAILABLE Kubelet 3 x v1.11.1 v1.12.0 Upgrade to the latest stable version: COMPONENT CURRENT AVAILABLE API Server v1.11.0 v1.12.0 Controller Manager v1.11.0 v1.12.0 Scheduler v1.11.0 v1.12.0 Kube Proxy v1.11.0 v1.12.0 CoreDNS 1.1.3 1.2.2 Etcd 3.2.18 3.2.24 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.12.0 _____________________________________________________________________  $ sudo kubeadm upgrade apply v1.12.0 [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [upgrade/apply] Respecting the --cri-socket flag that is set with higher priority than the config file. [upgrade/version] You have chosen to change the cluster version to \u0026quot;v1.12.0\u0026quot; [upgrade/versions] Cluster version: v1.11.0 [upgrade/versions] kubeadm version: v1.12.0 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd] [upgrade/prepull] Prepulling image for component kube-apiserver. [upgrade/prepull] Prepulling image for component kube-controller-manager. [upgrade/prepull] Prepulling image for component kube-scheduler. [upgrade/prepull] Prepulling image for component etcd. [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd [upgrade/prepull] Prepulled image for component etcd. [upgrade/prepull] Prepulled image for component kube-apiserver. [upgrade/prepull] Prepulled image for component kube-controller-manager. [upgrade/prepull] Prepulled image for component kube-scheduler. [upgrade/prepull] Successfully prepulled the images for all the control plane components [upgrade/apply] Upgrading your Static Pod-hosted control plane to version \u0026quot;v1.12.0\u0026quot;... Static pod: kube-apiserver-master-pi hash: c30b2fa49c49e091538b2ce8e4dae186 Static pod: kube-controller-manager-master-pi hash: 22f67939f8b1abea8ba99666b78b5c93 Static pod: kube-scheduler-master-pi hash: 0e545194d6b033abd681f02dfd11f4c8 Static pod: etcd-master-pi hash: 00575b778fb80d4e48241f80ceb2ac0f [etcd] Wrote Static Pod manifest for a local etcd instance to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests040184315/etcd.yaml\u0026quot; [upgrade/staticpods] Moved new manifest to \u0026quot;/etc/kubernetes/manifests/etcd.yaml\u0026quot; and backed up old manifest to \u0026quot;/etc/kubernetes/tmp/kubeadm-backup-manifests-2018-09-30-00-46-56/etcd.yaml\u0026quot; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s Static pod: etcd-master-pi hash: 00575b778fb80d4e48241f80ceb2ac0f Static pod: etcd-master-pi hash: 00575b778fb80d4e48241f80ceb2ac0f Static pod: etcd-master-pi hash: 00575b778fb80d4e48241f80ceb2ac0f Static pod: etcd-master-pi hash: 77c6076a4d6ee044b744b041125cf918 [apiclient] Found 1 Pods for label selector component=etcd [upgrade/staticpods] Component \u0026quot;etcd\u0026quot; upgraded successfully! [upgrade/etcd] Waiting for etcd to become available [util/etcd] Waiting 0s for initial delay [util/etcd] Attempting to see if all cluster endpoints are available 1/10 [upgrade/staticpods] Writing new Static Pod manifests to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests040184315\u0026quot; [controlplane] wrote Static Pod manifest for component kube-apiserver to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests040184315/kube-apiserver.yaml\u0026quot; [controlplane] wrote Static Pod manifest for component kube-controller-manager to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests040184315/kube-controller-manager.yaml\u0026quot; [controlplane] wrote Static Pod manifest for component kube-scheduler to \u0026quot;/etc/kubernetes/tmp/kubeadm-upgraded-manifests040184315/kube-scheduler.yaml\u0026quot; [upgrade/staticpods] Moved new manifest to \u0026quot;/etc/kubernetes/manifests/kube-apiserver.yaml\u0026quot; and backed up old manifest to \u0026quot;/etc/kubernetes/tmp/kubeadm-backup-manifests-2018-09-30-00-46-56/kube-apiserver.yaml\u0026quot; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s Static pod: kube-apiserver-master-pi hash: c30b2fa49c49e091538b2ce8e4dae186 Static pod: kube-apiserver-master-pi hash: a92106d6db4c8b5835a47f5f56c33fdb [apiclient] Found 1 Pods for label selector component=kube-apiserver [upgrade/staticpods] Component \u0026quot;kube-apiserver\u0026quot; upgraded successfully! [upgrade/staticpods] Moved new manifest to \u0026quot;/etc/kubernetes/manifests/kube-controller-manager.yaml\u0026quot; and backed up old manifest to \u0026quot;/etc/kubernetes/tmp/kubeadm-backup-manifests-2018-09-30-00-46-56/kube-controller-manager.yaml\u0026quot; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s Static pod: kube-controller-manager-master-pi hash: 22f67939f8b1abea8ba99666b78b5c93 Static pod: kube-controller-manager-master-pi hash: 980b4156606df8caafd0ad8abacc1485 [apiclient] Found 1 Pods for label selector component=kube-controller-manager [upgrade/staticpods] Component \u0026quot;kube-controller-manager\u0026quot; upgraded successfully! [upgrade/staticpods] Moved new manifest to \u0026quot;/etc/kubernetes/manifests/kube-scheduler.yaml\u0026quot; and backed up old manifest to \u0026quot;/etc/kubernetes/tmp/kubeadm-backup-manifests-2018-09-30-00-46-56/kube-scheduler.yaml\u0026quot; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s Static pod: kube-scheduler-master-pi hash: 0e545194d6b033abd681f02dfd11f4c8 Static pod: kube-scheduler-master-pi hash: 1b5ec5be325bf29f60be62789416a99e [apiclient] Found 1 Pods for label selector component=kube-scheduler [upgrade/staticpods] Component \u0026quot;kube-scheduler\u0026quot; upgraded successfully! [uploadconfig] storing the configuration used in ConfigMap \u0026quot;kubeadm-config\u0026quot; in the \u0026quot;kube-system\u0026quot; Namespace [kubelet] Creating a ConfigMap \u0026quot;kubelet-config-1.12\u0026quot; in namespace kube-system with the configuration for the kubelets in the cluster [kubelet] Downloading configuration for the kubelet from the \u0026quot;kubelet-config-1.12\u0026quot; ConfigMap in the kube-system namespace [kubelet] Writing kubelet configuration to file \u0026quot;/var/lib/kubelet/config.yaml\u0026quot; [patchnode] Uploading the CRI Socket information \u0026quot;/var/run/dockershim.sock\u0026quot; to the Node API object \u0026quot;master-pi\u0026quot; as an annotation [bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy [upgrade/successful] SUCCESS! Your cluster was upgraded to \u0026quot;v1.12.0\u0026quot;. Enjoy! [upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven't already done so.  Kubernetes servers are running v1.12\n$ kubectl version Client Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;11\u0026quot;, GitVersion:\u0026quot;v1.11.1\u0026quot;, GitCommit:\u0026quot;b1b29978270dc22fecc592ac55d903350454310a\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-07-17T18:53:20Z\u0026quot;, GoVersion:\u0026quot;go1.10.3\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/arm\u0026quot;} Server Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;12\u0026quot;, GitVersion:\u0026quot;v1.12.0\u0026quot;, GitCommit:\u0026quot;0ed33881dc4355495f623c6f22e7dd0b7632b7c0\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-09-27T16:55:41Z\u0026quot;, GoVersion:\u0026quot;go1.10.4\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/arm\u0026quot;}  my kubelets are still running kubernetes v1.11.1\n$ kubectl get nodes NAME STATUS ROLES AGE VERSION home-pi Ready \u0026lt;none\u0026gt; 86d v1.11.1 master-pi Ready master 86d v1.11.1 nas-pi Ready \u0026lt;none\u0026gt; 85d v1.11.1  Upgrade kubectl Install newer version of kubectl using apt-get\n$ sudo apt-get install kubectl Reading package lists... Done Building dependency tree Reading state information... Done The following packages will be upgraded: kubectl 1 upgraded, 0 newly installed, 0 to remove and 37 not upgraded. Need to get 8,639 kB of archives. After this operation, 1,783 kB of additional disk space will be used. Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main armhf kubectl armhf 1.12.0-00 [8,639 kB] Fetched 8,639 kB in 6s (1,270 kB/s) (Reading database ... 30574 files and directories currently installed.) Preparing to unpack .../kubectl_1.12.0-00_armhf.deb ... Unpacking kubectl (1.12.0-00) over (1.11.1-00) ... Setting up kubectl (1.12.0-00) ...  Check that kubectl is now 1.12\n$ kubectl version Client Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;12\u0026quot;, GitVersion:\u0026quot;v1.12.0\u0026quot;, GitCommit:\u0026quot;0ed33881dc4355495f623c6f22e7dd0b7632b7c0\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-09-27T17:05:32Z\u0026quot;, GoVersion:\u0026quot;go1.10.4\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/arm\u0026quot;} Server Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;12\u0026quot;, GitVersion:\u0026quot;v1.12.0\u0026quot;, GitCommit:\u0026quot;0ed33881dc4355495f623c6f22e7dd0b7632b7c0\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-09-27T16:55:41Z\u0026quot;, GoVersion:\u0026quot;go1.10.4\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/arm\u0026quot;}  Upgrade kubelet on master node $ sudo apt-get upgrade -y kubelet Reading package lists... Done Building dependency tree Reading state information... Done Calculating upgrade... Done The following packages will be upgraded: ...  $ sudo systemctl restart kubelet  $ kubectl get nodes NAME STATUS ROLES AGE VERSION home-pi Ready \u0026lt;none\u0026gt; 86d v1.11.1 master-pi Ready master 86d v1.12.0 nas-pi Ready \u0026lt;none\u0026gt; 85d v1.11.1  Looks that as useual something is wrong with flannel CNI\n$ kubectl get all --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE default pod/helm-rpi-kubeplay-arm32v7-6cb66496c6-6gvf6 1/1 Running 0 60d kube-system pod/coredns-576cbf47c7-nzhfj 1/1 Running 0 37m kube-system pod/coredns-576cbf47c7-wkmhr 1/1 Running 0 37m kube-system pod/etcd-master-pi 1/1 Running 0 3m43s kube-system pod/kube-apiserver-master-pi 1/1 Running 2 3m43s kube-system pod/kube-controller-manager-master-pi 1/1 Running 1 3m43s kube-system pod/kube-flannel-ds-4495g 1/1 Running 4 75d kube-system pod/kube-flannel-ds-52ssk 0/1 Error 10 75d kube-system pod/kube-flannel-ds-gj65n 1/1 Running 4 75d Investigation shows: ```bash $ kubectl logs pod/kube-flannel-ds-52ssk -n kube-system I0930 01:34:13.768925 1 main.go:475] Determining IP address of default interface I0930 01:34:13.778622 1 main.go:488] Using interface with name wlan0 and address 192.168.1.95 I0930 01:34:13.778716 1 main.go:505] Defaulting external address to interface address (192.168.1.95) I0930 01:34:14.168318 1 kube.go:131] Waiting 10m0s for node controller to sync I0930 01:34:14.168890 1 kube.go:294] Starting kube subnet manager I0930 01:34:15.169929 1 kube.go:138] Node controller sync successful I0930 01:34:15.170035 1 main.go:235] Created subnet manager: Kubernetes Subnet Manager - master-pi I0930 01:34:15.170064 1 main.go:238] Installing signal handlers I0930 01:34:15.170415 1 main.go:353] Found network config - Backend type: vxlan I0930 01:34:15.170797 1 vxlan.go:120] VXLAN config: VNI=1 Port=0 GBP=false DirectRouting=false E0930 01:34:15.256843 1 main.go:280] Error registering network: failed to configure interface flannel.1: failed to ensure address of interface flannel.1: link has incompatible addresses. Remove additional addresses and try again. \u0026amp;netlink.Vxlan{LinkAttrs:netlink.LinkAttrs{Index:5, MTU:1450, TxQLen:0, Name:\u0026quot;flannel.1\u0026quot;, HardwareAddr:net.HardwareAddr{0x26, 0xd5, 0xd0, 0xdd, 0x56, 0x1a}, ...  Let\u0026rsquo;s apply usual receipe ``bash sudo ip link delete flannel.1\n Brute force fix seems to have done the fix....This is lucky we don't have production traffic on that node. ```bash $ kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-576cbf47c7-nzhfj 1/1 Running 0 51m coredns-576cbf47c7-wkmhr 1/1 Running 0 51m etcd-master-pi 1/1 Running 0 17m kube-apiserver-master-pi 1/1 Running 2 17m kube-controller-manager-master-pi 1/1 Running 1 17m kube-flannel-ds-4495g 1/1 Running 4 75d kube-flannel-ds-52ssk 1/1 Running 13 75d kube-flannel-ds-gj65n 1/1 Running 4 75d kube-proxy-c2264 1/1 Running 0 51m kube-proxy-snjsg 1/1 Running 0 49m kube-proxy-zgqjb 1/1 Running 1 50m kube-scheduler-master-pi 1/1 Running 1 17m kubernetes-dashboard-7d59788d44-rchkk 1/1 Running 25 83d tiller-deploy-b59fcc885-dbvlv 1/1 Running 0 60d  Update first slave node sudo apt-get clean sudo apt-get update sudo apt-get install kubeadm sudo apt-get install kubelet sudo kubeadm upgrade node config --kubelet-version $(kubelet --version | cut -d ' ' -f 2) sudo systemctl restart kubelet  Same flannel issue\n$ kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-576cbf47c7-nzhfj 1/1 Running 0 87m coredns-576cbf47c7-wkmhr 1/1 Running 1 87m etcd-master-pi 1/1 Running 0 53m kube-apiserver-master-pi 1/1 Running 2 53m kube-controller-manager-master-pi 1/1 Running 1 53m kube-flannel-ds-4495g 0/1 CrashLoopBackOff 10 75d ...  same hack to fix the issue\nsudo ip link delete flannel.1  same hack seems to be effective\n$ kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-576cbf47c7-nzhfj 1/1 Running 0 111m coredns-576cbf47c7-wkmhr 1/1 Running 1 111m etcd-master-pi 1/1 Running 0 77m kube-apiserver-master-pi 1/1 Running 2 77m kube-controller-manager-master-pi 1/1 Running 1 77m kube-flannel-ds-4495g 1/1 Running 11 75d ...  Other slave node sudo apt-get clean sudo apt-get update sudo apt-get install kubeadm sudo apt-get install kubelet sudo kubeadm upgrade node config --kubelet-version $(kubelet --version | cut -d ' ' -f 2) sudo systemctl restart kubelet sudo ip link delete flannel.1  Check consistency of the cluster $ kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-576cbf47c7-nzhfj 1/1 Running 1 143m coredns-576cbf47c7-wkmhr 1/1 Running 1 143m etcd-master-pi 1/1 Running 0 109m kube-apiserver-master-pi 1/1 Running 2 109m kube-controller-manager-master-pi 1/1 Running 1 109m kube-flannel-ds-4495g 1/1 Running 11 76d kube-flannel-ds-52ssk 1/1 Running 13 76d kube-flannel-ds-gj65n 1/1 Running 13 76d kube-proxy-c2264 1/1 Running 1 143m kube-proxy-snjsg 1/1 Running 1 141m kube-proxy-zgqjb 1/1 Running 1 142m kube-scheduler-master-pi 1/1 Running 1 109m kubernetes-dashboard-7d59788d44-rchkk 1/1 Running 25 83d tiller-deploy-b59fcc885-dbvlv 1/1 Running 0 60d  $ kubectl get nodes NAME STATUS ROLES AGE VERSION home-pi Ready \u0026lt;none\u0026gt; 86d v1.12.0 master-pi Ready master 86d v1.12.0 nas-pi Ready \u0026lt;none\u0026gt; 86d v1.12.0  Conclusion  At a glance, the cluster seems to be healthy I still need to find sometool like sonobuoy to validate that the cluster is healthy  Reference Links  Official Upgrade documentation  "
},
{
	"uri": "/pi_cluster/advanced/children/2018-08-01-a/",
	"title": "Build and Deploy Kubernetes Hashicorp Vault",
	"tags": ["kubernetes", "security", "vault", "rpi"],
	"description": "",
	"content": " Goal Vault is aiming at improving security of the containers by rotating token and credential much more often than usual. Looks like it is especially effectiv to help rotate passwords used to access internal databases.\nKey Aspects  Compile and deploy the vault code in vault  Deploy  WIP  Conclusion  WIP  Reference Links  Official HashiCorp Code  "
},
{
	"uri": "/pi_cluster/advanced/children/2018-07-31-a/",
	"title": "Build and Deploy Kubernetes Istio",
	"tags": ["kubernetes", "security", "istio", "rpi"],
	"description": "",
	"content": " Goal Istio is aiming at improving security of the containers. One of the key aspects is the end to end encryption of the commnucation, the role of citadel to ensure the management of the certificates, the renewal of the certificates. As always, the goal of this post is to study that new tool and figure out I can leverage it in my day to day work.\nKey Aspects  Compile and deploy the istio code in istio  Deploy  WIP  Conclusion  WIP  Reference Links  Official istio Code  "
},
{
	"uri": "/pi_cluster/microservices/children/2018-07-30-a/",
	"title": "Build and Deploy Kubernetes test-infra",
	"tags": ["kubernetes", "test-infra", "sonobuoy", "testing", "rpi"],
	"description": "",
	"content": " Goal test-infra seems to somewhat overlap with sonobuoy features. The purpose of this post is to fetch the code, compile and deploy it on a Kubernetes cluster.\nKey Aspects  Compile and deploy the test-infra code in test-infra  Deploy  WIP  Conclusion  WIP  Reference Links  Official test-infra Code  "
},
{
	"uri": "/pi_cluster/advanced/children/2018-07-29-a/",
	"title": "Build and Deploy Kubernetes Kustomize",
	"tags": ["kubernetes", "kustomize", "rpi"],
	"description": "",
	"content": " Goal kustomize seems to help the setup of multiple clusters by removing copy paste accross cluster and still keeping the configuration file has plain yaml instead of the template like it is often the case with t\nKey Aspects  Compile and deploy the Kustomize code in Kustomize  Deploy  WIP  Conclusion  WIP  Reference Links  Kustomize Description Official Kustomize Code  "
},
{
	"uri": "/pi_cluster/advanced/children/2018-07-18-a/",
	"title": "Compile and Test Portieris",
	"tags": ["kubernetes", "security", "portieris"],
	"description": "",
	"content": " Goal One of the biggest security risks related to Kubernetes are often linked to the fact that it is really hard to ensure that only \u0026ldquo;approved\u0026rdquo; images are deployed in your Kubernetes cluster. The goal here is to leverage Notary and the a project called \u0026ldquo;Portieris\u0026rdquo; created by IBM.\nKey Aspects  Rebuild the Notary Rebuild and Deploy Portieris using Helm  Build Notary Clone go get github.com/theupdateframework/notary go install -tags pkcs11 github.com/theupdateframework/notary/cmd/notary  Run notary -s https://notary.docker.io -d ~/.docker/trust list docker.io/library/alpine  $ notary -s https://notary.docker.io -d ~/.docker/trust list docker.io/library/alpine NAME DIGEST SIZE (BYTES) ROLE ---- ------ ------------ ---- 2.6 9ace551613070689a12857d62c30ef0daa9a376107ec0fff0e34786cedb3399b 528 targets 2.7 9f08005dff552038f0ad2f46b8e65ff3d25641747d3912e3ea8da6785046561a 1374 targets 3.1 2f9dfa6adf602d3d7379f11f3d4fd0b7b4d1c526616ee7c0fd5e553a72e4bf79 433 targets 3.2 4b02d27451aabdf2b6bcd09888deed56b2a3b645aab3b77bc9511cf80d0820a6 433 targets 3.3 37f4d7bb352bde58797d0f0c4e6c4e69a9ed44d4e47a8ab4461888d117d14c6a 433 targets 3.4 c1aa0f93d13258dc8b4e87391f02432dc214736c3f176e2e433629c2afe96aa0 433 targets 3.5 4d3ec631cdde98a03b91477b411a1fb42a9cadd8139c2e78029e44e199e58433 433 targets 3.6 de5701d6a3a36dc6a5db260d21be0422fd30dd2d158c1e048b34263e73205cb6 2029 targets 3.7 56e2f91ef15847a2b02a5a03cbfa483949d67a242c37e33ea178e3e7e01e0dfd 2029 targets 3.8 7043076348bf5040220df6ad703798fd8593a0918d06d3ce30c6c93be117e430 2029 targets edge 8d9872bf7dc946db1b3cd2bf70752f59085ec3c5035ca1d820d30f1d1267d65d 2029 targets integ-test-base 3952dc48dcc4136ccdde37fbef7e250346538a55a0366e3fccc683336377e372 528 targets latest 7043076348bf5040220df6ad703798fd8593a0918d06d3ce30c6c93be117e430 2029 targets  $ notary -s https://notary.docker.io -d ~/.docker/trust list docker.io/library/nginx NAME DIGEST SIZE (BYTES) ROLE ---- ------ ------------ ---- 1 4a5573037f358b6cdfa2f3e8a9c33a5cf11bcd1675ca72ca76fbe5bd77d0d682 2029 targets 1-alpine 56a9367b64eaef37894842a6f7a19a0ef8e7bd5de964aa844a70b3e2d758033c 2035 targets 1-alpine-perl 26f3b1633ad04d85b76c867d0c46b309b41c5a8d42d5c5b9652769ba9e2c578e 2035 targets 1-perl a070af1e88c071310080cbe4d7b03e06d7fd2b9d982f520edccc8f93af5c641c 2029 targets 1.10 6202beb06ea61f44179e02ca965e8e13b961d12640101fca213efbfd145d7575 948 targets 1.10-alpine 4aacdcf186934dcb02f642579314075910f1855590fd3039d8fa4c9f96e48315 1154 targets 1.10.0-alpine 5b99c2a3ec2b3273a7f77b661941a94e6fa2aa38e5a94c1d90e0924eceefb1e6 13412 targets 1.10.1 35779791c05d119df4fe476db8f47c0bee5943c83eba5656a15fc046db48178b 948 targets 1.10.1-alpine dabd1d182f12e2a7d372338dfd0cde303ef042a6ba01cc829ef464982f9c9e2c 1154 targets 1.10.2 06f933c3fceac34b87bba85074fe7b24fe18ae5e4439d8f9dd038371f02947c3 948 targets 1.10.2-alpine ce50816e7216a66ff1e0d99e7d74891c4019952c9e38c690b3c5407f7af57555 1154 targets 1.10.3 6202beb06ea61f44179e02ca965e8e13b961d12640101fca213efbfd145d7575 948 targets 1.10.3-alpine 4aacdcf186934dcb02f642579314075910f1855590fd3039d8fa4c9f96e48315 1154 targets 1.11 e6693c20186f837fc393390135d8a598a96a833917917789d63766cab6c59582 1156 targets 1.11-alpine 5aadb68304a38a8e2719605e4e180413f390cd6647602bee9bdedd59753c3590 1154 targets 1.11.0 b2e588a4486786239561d73a14ec546cf5ac508bc1890b097dcc60fede1825b8 1956 targets 1.11.0-alpine ddafab6770f3f604672143757000fa1614dcf6afb1d5308dcc47153252fd0817 2369 targets 1.11.1 0fe6413f3e30fcc5920bc8fa769280975b10b1c26721de956e1428b9e2f29d04 1956 targets 1.11.1-alpine 23f809e7fd5952e7d5be065b4d3643fbbceccd349d537b62a123ef2201bc886f 1133 targets  Build and Deploy Portieris Clone $ mkdir -p ~/src/github.com/IBM $ cd ~/src/github.com/IBM $ git clone https://github.com/jbrette/portieris.git  Install helm package $ cd portieris/helm/portieris $ helm install -n portieris . --set IBMContainerService=false --debug  $ kubectl get all -n ibm-system NAME READY STATUS RESTARTS AGE pod/portieris-7b7cbf58c5-gmpwm 1/1 Running 0 1h pod/portieris-7b7cbf58c5-r5vvv 1/1 Running 0 1h pod/portieris-7b7cbf58c5-vkhkh 1/1 Running 0 1h NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/portieris ClusterIP 10.101.194.144 \u0026lt;none\u0026gt; 443/TCP 1h NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/portieris 3 3 3 3 1h NAME DESIRED CURRENT READY AGE replicaset.apps/portieris-7b7cbf58c5 3 3 3 1h  Reference Links  [Kubernetes cross build]()  "
},
{
	"uri": "/nfv/fd_io_and_opnfv/children/2018-07-17-a/",
	"title": "Rebuild Calico for AMD64 ad ARM32V7",
	"tags": ["kubernetes", "calico", "cni"],
	"description": "",
	"content": " Goal Neither calico nor canal seems to be available for usage yet on ARM32V7 for PI. The attempt here is to cross-compile the calico containers and use them on the PI cluster.\nKey Aspects  Rebuild the Calico  Build Kubernetes executables for AMD64 and ARM  WIP  Conclusion  WIP  Reference Links  [Kubernetes cross build]()  "
},
{
	"uri": "/devops/advanced/children/2018-07-16-a/",
	"title": "Rebuild Hyperkube images",
	"tags": ["kubernetes"],
	"description": "",
	"content": " Goal This post is to validate that it would be possible if urgency dictates it to rebuild the hyperkube Kubernetes image.\nKey Aspects  Rebuild Hyperkube images for amd64 and arm32v7 Rebuild the individual images deployed by kubeadm  Build Kubernetes executables for AMD64 and ARM  WIP  Conclusion  WIP  Reference Links  [Kubernetes cross build]()  "
},
{
	"uri": "/devops/kubedgesdk/children/2018-07-15-a/",
	"title": "Recompile Kubernetes components for Raspberry PI",
	"tags": ["kubernetes", "rpi"],
	"description": "",
	"content": " Goal During the installation of official Kubernetes 1.11.0 on RPI Cluster 1, encountered a bug on the controller manager preventing the controller-manager from starting. The problem here was to be able to cross compiled the latest version of Kubernetes 1.11.1 before the code was officially released and of course rebuild the images.\nKey Aspects  The bug had been fixed by the Kubernetes kube-controller-manager - panic: runtime error: index out of range has been fixed and will be built as part of 1.11.1 The goal is to learn how to recompile Kubernetes from the source to be able to contribute when possible and address problems as soon as possible  Build Kubernetes executables for AMD64 and ARM Cross Compiling from Ubuntu Machine First check the go setup. Fetch the code\nLet\u0026rsquo;s check the go environment. See Setup GOLANG environment\n$ which go /usr/bin/go  $ go version go version go1.10.1 linux/amd64  Clone the code\n$ export GOPATH=$HOME/src $ mkdir -p src/k8s.io $ cd src/k8s.io $ git clone -b release-1.11 git@github.com:kubernetes/kubernetes.git $ cd kubernertes  To save time, I removed platforms I had not use of and only kept amd64 and arm on linux\n$ cat hack/lib/golang.sh  # The server platform we are building on. readonly KUBE_SERVER_PLATFORMS=( linux/amd64 linux/arm ) # The node platforms we build for readonly KUBE_NODE_PLATFORMS=( linux/amd64 linux/arm ) # If we update this we should also update the set of platforms whose standard library is precompiled for in build/build-image/cross/Dockerfile readonly KUBE_CLIENT_PLATFORMS=( linux/amd64 linux/arm ) # Which platforms we should compile test targets for. Not all client platforms need these tests readonly KUBE_TEST_PLATFORMS=( linux/amd64 linux/arm )  Double check your Docker setup is correct\n$ docker run hello-world  Clean the directory\n$ ./build/make-clean.sh  Rebuild the amd64 and arm executable\n$ ./build/run.sh make cross  Check the executables transfered from the docker build container to your vm by rsync\n$ cd _output/dockerized/bin/linux  Check the amd64 executables\nls -lt amd64 total 2322696 -rwxr-xr-x 1 xxxxxx yyyyyy 209961168 Jul 16 01:57 e2e_node.test -rwxr-xr-x 1 xxxxxx yyyyyy 10645252 Jul 16 01:57 ginkgo -rwxr-xr-x 1 xxxxxx yyyyyy 160051600 Jul 16 01:57 kubemark -rwxr-xr-x 1 xxxxxx yyyyyy 231997872 Jul 16 01:55 genman -rwxr-xr-x 1 xxxxxx yyyyyy 54099081 Jul 16 01:55 gendocs -rwxr-xr-x 1 xxxxxx yyyyyy 54039865 Jul 16 01:55 genyaml -rwxr-xr-x 1 xxxxxx yyyyyy 6694536 Jul 16 01:55 linkcheck -rwxr-xr-x 1 xxxxxx yyyyyy 5481582 Jul 16 01:55 genswaggertypedocs -rwxr-xr-x 1 xxxxxx yyyyyy 226061456 Jul 16 01:55 genkubedocs -rwxr-xr-x 1 xxxxxx yyyyyy 173411368 Jul 16 01:55 e2e.test -rwxr-xr-x 1 xxxxxx yyyyyy 55241186 Jul 16 01:52 kubectl -rwxr-xr-x 1 xxxxxx yyyyyy 51912114 Jul 16 01:52 kube-proxy -rwxr-xr-x 1 xxxxxx yyyyyy 57246829 Jul 16 01:51 kubeadm -rwxr-xr-x 1 xxxxxx yyyyyy 162716256 Jul 16 01:51 kubelet -rwxr-xr-x 1 xxxxxx yyyyyy 57908740 Jul 16 01:50 kube-aggregator -rwxr-xr-x 1 xxxxxx yyyyyy 185152632 Jul 16 01:50 kube-apiserver -rwxr-xr-x 1 xxxxxx yyyyyy 2330265 Jul 16 01:50 mounter -rwxr-xr-x 1 xxxxxx yyyyyy 138048783 Jul 16 01:50 cloud-controller-manager -rwxr-xr-x 1 xxxxxx yyyyyy 153798994 Jul 16 01:50 kube-controller-manager -rwxr-xr-x 1 xxxxxx yyyyyy 227283184 Jul 16 01:50 hyperkube -rwxr-xr-x 1 xxxxxx yyyyyy 59296776 Jul 16 01:50 apiextensions-apiserver -rwxr-xr-x 1 xxxxxx yyyyyy 55471235 Jul 16 01:50 kube-scheduler -rwxr-xr-x 1 xxxxxx yyyyyy 2835466 Jul 16 01:40 go-bindata -rwxr-xr-x 1 xxxxxx yyyyyy 13630237 Jul 16 01:40 openapi-gen -rwxr-xr-x 1 xxxxxx yyyyyy 7699847 Jul 16 01:40 conversion-gen -rwxr-xr-x 1 xxxxxx yyyyyy 7669238 Jul 16 01:39 defaulter-gen -rwxr-xr-x 1 xxxxxx yyyyyy 7695690 Jul 16 01:39 deepcopy-gen  Check the RPI executables\n$ ls -lt arm total 2089216 -rwxr-xr-x 1 xxxxxx yyyyyy 191189688 Jul 16 01:58 e2e_node.test -rwxr-xr-x 1 xxxxxx yyyyyy 9286102 Jul 16 01:58 ginkgo -rwxr-xr-x 1 xxxxxx yyyyyy 142111524 Jul 16 01:58 kubemark -rwxr-xr-x 1 xxxxxx yyyyyy 210989712 Jul 16 01:55 genman -rwxr-xr-x 1 xxxxxx yyyyyy 48169969 Jul 16 01:55 gendocs -rwxr-xr-x 1 xxxxxx yyyyyy 48102745 Jul 16 01:55 genyaml -rwxr-xr-x 1 xxxxxx yyyyyy 5847821 Jul 16 01:55 linkcheck -rwxr-xr-x 1 xxxxxx yyyyyy 4927730 Jul 16 01:55 genswaggertypedocs -rwxr-xr-x 1 xxxxxx yyyyyy 205458748 Jul 16 01:55 genkubedocs -rwxr-xr-x 1 xxxxxx yyyyyy 155653412 Jul 16 01:55 e2e.test -rwxr-xr-x 1 xxxxxx yyyyyy 49252169 Jul 16 01:52 kubectl -rwxr-xr-x 1 xxxxxx yyyyyy 46156229 Jul 16 01:52 kube-proxy -rwxr-xr-x 1 xxxxxx yyyyyy 50989514 Jul 16 01:52 kubeadm -rwxr-xr-x 1 xxxxxx yyyyyy 144291264 Jul 16 01:52 kubelet -rwxr-xr-x 1 xxxxxx yyyyyy 52024300 Jul 16 01:50 kube-aggregator -rwxr-xr-x 1 xxxxxx yyyyyy 168751462 Jul 16 01:50 kube-apiserver -rwxr-xr-x 1 xxxxxx yyyyyy 2231154 Jul 16 01:50 mounter -rwxr-xr-x 1 xxxxxx yyyyyy 122701327 Jul 16 01:50 cloud-controller-manager -rwxr-xr-x 1 xxxxxx yyyyyy 136828051 Jul 16 01:50 kube-controller-manager -rwxr-xr-x 1 xxxxxx yyyyyy 206769888 Jul 16 01:50 hyperkube -rwxr-xr-x 1 xxxxxx yyyyyy 53220784 Jul 16 01:50 apiextensions-apiserver -rwxr-xr-x 1 xxxxxx yyyyyy 49501810 Jul 16 01:50 kube-scheduler -rwxr-xr-x 1 xxxxxx yyyyyy 2649635 Jul 16 01:40 go-bindata -rwxr-xr-x 1 xxxxxx yyyyyy 11885551 Jul 16 01:40 openapi-gen -rwxr-xr-x 1 xxxxxx yyyyyy 6770458 Jul 16 01:40 conversion-gen -rwxr-xr-x 1 xxxxxx yyyyyy 6764729 Jul 16 01:39 defaulter-gen -rwxr-xr-x 1 xxxxxx yyyyyy 6770309 Jul 16 01:39 deepcopy-gen  Transfer the binaries to RPI machine\nscp -r arm rpiuser@192.168.1.94:/home/rpiuser/kubernetes_binaries  Build the docker image $ mkdir -p images/kube-controller-manager $ cd images/kube-controller-manager $ cp $HOME/kubernetes_binaries/kube-controller-manager  Create a simple Dockerfile to update the executable\n$ cat Dockerfile  FROM k8s.gcr.io/kube-controller-manager-arm:v1.11.0 COPY kube-controller-manager /usr/local/bin/kube-controller-manager  Build the image\n$ docker build -t jbrette/kube-controller-manager-arm:v1.11.1  Because of the brute force approach the image is twice as big since the executable (130MB) is contained in two layers of the container image\n$ docker image list REPOSITORY TAG IMAGE ID CREATED SIZE jbrette/kube-controller-manager-arm v1.11.1 b7023eef8fdf 8 hours ago 275MB k8s.gcr.io/kube-apiserver-arm v1.11.0 383bd2c4314e 2 weeks ago 170MB k8s.gcr.io/kube-controller-manager-arm v1.11.0 5b25f8a97aec 2 weeks ago 138MB k8s.gcr.io/kube-scheduler-arm v1.11.0 555ee860fa3c 2 weeks ago 50.5MB k8s.gcr.io/kube-proxy-arm v1.11.0 d7ebe361fe95 2 weeks ago 89.1MB k8s.gcr.io/coredns 1.1.3 7ceeb40862fb 7 weeks ago 31.3MB k8s.gcr.io/etcd-arm 3.2.18 ae02bf7047c8 3 months ago 221MB quay.io/coreos/flannel v0.10.0-arm c663d02f7966 5 months ago 39.9MB k8s.gcr.io/pause-arm 3.1 e11a8cbeda86 6 months ago 374kB k8s.gcr.io/pause 3.1 e11a8cbeda86 6 months ago 374kB  First push the controller-manager docker image to the repo\n$ docker login $ docker push jbrette/kube-controller-manager-arm:v1.11.1  Updating Kubeadm and Kubernetes configuration to use the patched images Because I only rebuild one image, I can not use the kubeadm feature which allows to point to a different repo. Have to edit manually the configuration.\n$ more kube-controller-manager.yaml  apiVersion: v1 kind: Pod metadata: annotations: scheduler.alpha.kubernetes.io/critical-pod: \u0026quot;\u0026quot; creationTimestamp: null labels: component: kube-controller-manager tier: control-plane name: kube-controller-manager namespace: kube-system spec: containers: - command: - kube-controller-manager - --address=127.0.0.1 - --allocate-node-cidrs=true - --cluster-cidr=10.244.0.0/16 - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key - --controllers=*,bootstrapsigner,tokencleaner - --kubeconfig=/etc/kubernetes/controller-manager.conf - --leader-elect=true - --node-cidr-mask-size=24 - --root-ca-file=/etc/kubernetes/pki/ca.crt - --service-account-private-key-file=/etc/kubernetes/pki/sa.key - --use-service-account-credentials=true image: jbrette/kube-controller-manager-arm:v1.11.1 imagePullPolicy: IfNotPresent livenessProbe: failureThreshold: 8 httpGet: host: 127.0.0.1 path: /healthz port: 10252 scheme: HTTP initialDelaySeconds: 15 timeoutSeconds: 15 name: kube-controller-manager resources: requests: cpu: 200m volumeMounts: - mountPath: /etc/ssl/certs name: ca-certs readOnly: true - mountPath: /etc/kubernetes/controller-manager.conf name: kubeconfig readOnly: true - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec name: flexvolume-dir - mountPath: /usr/share/ca-certificates name: usr-share-ca-certificates readOnly: true - mountPath: /usr/local/share/ca-certificates name: usr-local-share-ca-certificates readOnly: true - mountPath: /etc/ca-certificates name: etc-ca-certificates readOnly: true - mountPath: /etc/kubernetes/pki name: k8s-certs readOnly: true hostNetwork: true priorityClassName: system-cluster-critical volumes: - hostPath: path: /etc/kubernetes/pki type: DirectoryOrCreate name: k8s-certs - hostPath: path: /etc/ssl/certs type: DirectoryOrCreate name: ca-certs - hostPath: path: /etc/kubernetes/controller-manager.conf type: FileOrCreate name: kubeconfig - hostPath: path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec type: DirectoryOrCreate name: flexvolume-dir - hostPath: path: /usr/share/ca-certificates type: DirectoryOrCreate name: usr-share-ca-certificates - hostPath: path: /usr/local/share/ca-certificates type: DirectoryOrCreate name: usr-local-share-ca-certificates - hostPath: path: /etc/ca-certificates type: DirectoryOrCreate name: etc-ca-certificates status: {}  Conclusion  Need to streamline the build process Need to streamline the image patching processed  Reference Links  [Kubernetes cross build]()  "
},
{
	"uri": "/pi_cluster/docker_kubernetes/children/2018-07-14-a/",
	"title": "Deploy Flannel in Raspberry PI cluster",
	"tags": ["kubernetes", "rpi", "cni"],
	"description": "",
	"content": " Goal In order to get the nodes and pods interface with each other accross the cluster. This post describes how I deployed Flannel acounting with the fact that some of the nodes have multiple interfaces (wlan0 and eth0).\nKey Aspects  Flannel seems to deploy ok. Looks like in trouble when multiple interfaces available Calico in not compiled by default for Rapsberry PI  Flannel Setup through kubectl $ mkdir -p $HOME/kube-deployments/flannel $ cd $HOME/kube-deployments/flannel $ curl -sSL https://rawgit.com/coreos/flannel/v0.9.1/Documentation/kube-flannel.yml | sed \u0026quot;s/amd64/arm/g\u0026quot; \u0026gt; flannel.yaml $ kubectl create -f flannel.yaml  Note: realized that should be using flannel v0.10.0 instead of v0.9.1\nFlannel Issue 1: flannel.1. Link has incompatible address on master-pi, both the WLAN and LAN interfaces were activated. After unplugging the CAT5, behavior was similar. Moreover this had some impact on the kube-apiserver (see the number of restarts).\n$ kubectl get all --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE default pod/helm-rpi-kubeplay-arm32v7-6cb66496c6-9w97m 1/1 Running 0 4h kube-system pod/coredns-78fcdf6894-cw5p8 1/1 Running 15 10d kube-system pod/coredns-78fcdf6894-czjcj 1/1 Running 15 10d kube-system pod/etcd-master-pi 1/1 Running 11 10d kube-system pod/kube-apiserver-master-pi 1/1 Running 599 10d kube-system pod/kube-controller-manager-master-pi 1/1 Running 38 10d kube-system pod/kube-flannel-ds-bhllh 1/1 Running 13 9d kube-system pod/kube-flannel-ds-q7cp2 0/1 CrashLoopBackOff 401 9d kube-system pod/kube-flannel-ds-wqxsz 1/1 Running 16 9d kube-system pod/kube-proxy-4chwh 1/1 Running 9 9d kube-system pod/kube-proxy-6r5mn 1/1 Running 5 9d kube-system pod/kube-proxy-vvj6j 1/1 Running 11 10d kube-system pod/kube-scheduler-master-pi 1/1 Running 13 10d kube-system pod/kubernetes-dashboard-7d59788d44-rchkk 1/1 Running 20 7d kube-system pod/tiller-deploy-b59fcc885-66l7s 1/1 Running 0 6h  $ kubectl logs pod/kube-flannel-ds-q7cp2 -n kube-system I0716 00:42:46.596796 1 main.go:474] Determining IP address of default interface I0716 00:42:46.598043 1 main.go:487] Using interface with name wlan0 and address 192.168.1.95 I0716 00:42:46.598138 1 main.go:504] Defaulting external address to interface address (192.168.1.95) I0716 00:42:46.775936 1 kube.go:283] Starting kube subnet manager I0716 00:42:46.775907 1 kube.go:130] Waiting 10m0s for node controller to sync I0716 00:42:47.776280 1 kube.go:137] Node controller sync successful I0716 00:42:47.776400 1 main.go:234] Created subnet manager: Kubernetes Subnet Manager - master-pi I0716 00:42:47.776431 1 main.go:237] Installing signal handlers I0716 00:42:47.776697 1 main.go:352] Found network config - Backend type: vxlan I0716 00:42:47.776900 1 vxlan.go:119] VXLAN config: VNI=1 Port=0 GBP=false DirectRouting=false E0716 00:42:47.778884 1 main.go:279] Error registering network: failed to configure interface flannel.1: link has incompatible addresses. Remove additional addresses and try again.... I0716 00:42:47.778991 1 main.go:332] Stopping shutdownHandler...  Deleting the pod, did not help. After recreation same issue reappeared.\n$ kubectl delete pod/kube-flannel-ds-q7cp2 -n kube-system  $ kubectl get all --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system pod/kube-flannel-ds-z7w4f 0/1 Error 1 17s  Deleting the interface flannel.1 interface actually worked:\n$ sudo ip link delete flannel.1  $ kubectl get all --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system pod/kube-flannel-ds-z7w4f 1/1 Running 5 3m  $ kubectl logs pod/kube-flannel-ds-z7w4f -n kube-system I0716 00:52:14.555290 1 main.go:474] Determining IP address of default interface I0716 00:52:14.564490 1 main.go:487] Using interface with name wlan0 and address 192.168.1.95 I0716 00:52:14.564578 1 main.go:504] Defaulting external address to interface address (192.168.1.95) I0716 00:52:14.802491 1 kube.go:130] Waiting 10m0s for node controller to sync I0716 00:52:14.802544 1 kube.go:283] Starting kube subnet manager I0716 00:52:15.803114 1 kube.go:137] Node controller sync successful I0716 00:52:15.803308 1 main.go:234] Created subnet manager: Kubernetes Subnet Manager - master-pi I0716 00:52:15.803909 1 main.go:237] Installing signal handlers I0716 00:52:15.804662 1 main.go:352] Found network config - Backend type: vxlan I0716 00:52:15.804985 1 vxlan.go:119] VXLAN config: VNI=1 Port=0 GBP=false DirectRouting=false I0716 00:52:15.875242 1 main.go:299] Wrote subnet file to /run/flannel/subnet.env I0716 00:52:15.875367 1 main.go:303] Running backend. I0716 00:52:15.875489 1 main.go:321] Waiting for all goroutines to exit I0716 00:52:15.875559 1 vxlan_network.go:56] watching for new subnet leases  Flannel issue 2: Multiple interfaces Some of the PI have two interfaces running: wlan0 and eth0. The internal cluster network is using eth0. We need to force Flannel to use it.\nSetup through kubectl Realize I was using v0.9.1 instead of v0.10.0. Let\u0026rsquo;s update the file\n$ mkdir -p $HOME/kube-deployments/flannel $ cd $HOME/kube-deployments/flannel $ curl -sSL https://rawgit.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml | sed \u0026quot;s/amd64/arm/g\u0026quot; \u0026gt; flannel.yaml  Let\u0026rsquo;s add \u0026ndash;iface=eth0 to the flanneld to in the flannel.yaml\n Let\u0026rsquo;s update flannel from 0.9.1 to 0.10.0 at the same time we specify which interface to use.\n$ kubectl apply -f flannel.yaml clusterrole.rbac.authorization.k8s.io/flannel configured clusterrolebinding.rbac.authorization.k8s.io/flannel configured serviceaccount/flannel unchanged configmap/kube-flannel-cfg configured daemonset.extensions/kube-flannel-ds configured  It seems it solved the flannel issue. The bug in kube 1.11.0 still there (restart of kube-apiserver) Will update to 1.11.1 when it is published\n$ kubectl get all --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system pod/coredns-78fcdf6894-bn6wl 1/1 Running 0 6d kube-system pod/coredns-78fcdf6894-k52xb 1/1 Running 0 6d kube-system pod/etcd-kubemaster-pi 1/1 Running 3 6d kube-system pod/kube-apiserver-kubemaster-pi 1/1 Running 3 6d kube-system pod/kube-controller-manager-kubemaster-pi 0/1 CrashLoopBackOff 1740 6d kube-system pod/kube-flannel-ds-62fz9 1/1 Running 984 6d kube-system pod/kube-flannel-ds-gwzdt 1/1 Running 0 6d kube-system pod/kube-flannel-ds-h7ln5 1/1 Running 0 6d kube-system pod/kube-flannel-ds-qs9lf 1/1 Running 0 6d kube-system pod/kube-flannel-ds-vwsjk 1/1 Running 0 6d kube-system pod/kube-proxy-45z5s 1/1 Running 0 6d kube-system pod/kube-proxy-4trsd 1/1 Running 0 6d kube-system pod/kube-proxy-ksj7c 1/1 Running 4 6d kube-system pod/kube-proxy-t7gmc 1/1 Running 0 6d kube-system pod/kube-proxy-tfmqb 1/1 Running 0 6d kube-system pod/kube-scheduler-kubemaster-pi 1/1 Running 4 6d NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default service/kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 6d kube-system service/kube-dns ClusterIP 10.96.0.10 \u0026lt;none\u0026gt; 53/UDP,53/TCP 6d NAMESPACE NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE kube-system daemonset.apps/kube-flannel-ds 5 5 5 5 5 beta.kubernetes.io/arch=arm 6d kube-system daemonset.apps/kube-proxy 5 5 5 5 5 beta.kubernetes.io/arch=arm 6d NAMESPACE NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE kube-system deployment.apps/coredns 2 2 2 2 6d NAMESPACE NAME DESIRED CURRENT READY AGE kube-system replicaset.apps/coredns-78fcdf6894 2 2 2 6d  $ kubectl logs pod/kube-flannel-ds-62fz9 -n kube-system I0714 14:34:26.719081 1 main.go:474] Determining IP address of default interface I0714 14:34:26.728184 1 main.go:487] Using interface with name wlan0 and address 192.168.1.94 I0714 14:34:26.728273 1 main.go:504] Defaulting external address to interface address (192.168.1.94) I0714 14:34:26.942686 1 kube.go:283] Starting kube subnet manager I0714 14:34:26.943203 1 kube.go:130] Waiting 10m0s for node controller to sync I0714 14:34:27.943672 1 kube.go:137] Node controller sync successful I0714 14:34:27.943771 1 main.go:234] Created subnet manager: Kubernetes Subnet Manager - kubemaster-pi I0714 14:34:27.943819 1 main.go:237] Installing signal handlers I0714 14:34:27.944064 1 main.go:352] Found network config - Backend type: vxlan I0714 14:34:27.944222 1 vxlan.go:119] VXLAN config: VNI=1 Port=0 GBP=false DirectRouting=false I0714 14:34:28.004675 1 main.go:299] Wrote subnet file to /run/flannel/subnet.env I0714 14:34:28.004748 1 main.go:303] Running backend. I0714 14:34:28.004880 1 main.go:321] Waiting for all goroutines to exit I0714 14:34:28.004931 1 vxlan_network.go:56] watching for new subnet leases I0714 14:34:28.049933 1 iptables.go:114] Some iptables rules are missing; deleting and recreating rules I0714 14:34:28.050202 1 iptables.go:136] Deleting iptables rule: -s 10.244.0.0/16 -j ACCEPT I0714 14:34:28.053918 1 iptables.go:114] Some iptables rules are missing; deleting and recreating rules I0714 14:34:28.054003 1 iptables.go:136] Deleting iptables rule: -s 10.244.0.0/16 -d 10.244.0.0/16 -j RETURN I0714 14:34:28.057332 1 iptables.go:136] Deleting iptables rule: -d 10.244.0.0/16 -j ACCEPT I0714 14:34:28.061665 1 iptables.go:136] Deleting iptables rule: -s 10.244.0.0/16 ! -d 224.0.0.0/4 -j MASQUERADE I0714 14:34:28.066452 1 iptables.go:124] Adding iptables rule: -s 10.244.0.0/16 -j ACCEPT I0714 14:34:28.069910 1 iptables.go:136] Deleting iptables rule: ! -s 10.244.0.0/16 -d 10.244.0.0/24 -j RETURN I0714 14:34:28.075067 1 iptables.go:136] Deleting iptables rule: ! -s 10.244.0.0/16 -d 10.244.0.0/16 -j MASQUERADE I0714 14:34:28.078310 1 iptables.go:124] Adding iptables rule: -d 10.244.0.0/16 -j ACCEPT I0714 14:34:28.082389 1 iptables.go:124] Adding iptables rule: -s 10.244.0.0/16 -d 10.244.0.0/16 -j RETURN I0714 14:34:28.098375 1 iptables.go:124] Adding iptables rule: -s 10.244.0.0/16 ! -d 224.0.0.0/4 -j MASQUERADE I0714 14:34:28.111379 1 iptables.go:124] Adding iptables rule: ! -s 10.244.0.0/16 -d 10.244.0.0/24 -j RETURN I0714 14:34:28.122424 1 iptables.go:124] Adding iptables rule: ! -s 10.244.0.0/16 -d 10.244.0.0/16 -j MASQUERADE  Calico Compile Calico for Raspberry PI  WIP  Deploy on Raspberry PI  WIP  Results  WIP  Reference Links  Flannel Issue Flannel Issue2 Flannel Issue3  "
},
{
	"uri": "/pi_cluster/docker_kubernetes/children/2018-07-13-a/",
	"title": "Deploy Helm and Tiller on Rasberry PI Cluster",
	"tags": ["kubernetes", "helm"],
	"description": "",
	"content": " Goal The main purpose of this exercise is to be able to use Helm on the Rapsberry PI Cluster.\nKey Aspects  The goal is to setup helm and tiller on the Raspberry PI cluster Having the golang, glide\u0026hellip;and related libraries setup in a PI for compilation is kind of complicated. I started but encounter too many issues (even small), had to install too many compilation related packages on my PI system, hence decided to use an Ubuntu VM to compile and prepare the binaries for image for helm and tiller. This will be usefull to setup CI/CD pipeline with Travis-CI.  Build Tiller executable and Docker image Cross Compiling from Ubuntu Machine First check the go setup. Fetch the code\nLet\u0026rsquo;s check the go environment. See Setup GOLANG environment\nwhich go /usr/bin/go  go version go version go1.10.1 linux/amd64  export GOPATH=$HOME/src mkdir -p src/k8s.io cd src/k8s.io git clone -b release-2.9 git@github.com:kubernetes/helm.git  cd $HOME/src/k8s.io/helm make clean bootstrap build-cross dist APP=helm VERSION=2.9 TARGETS=linux/arm ... go build -o bin/protoc-gen-go ./vendor/github.com/golang/protobuf/protoc-gen-go CGO_ENABLED=0 gox -parallel=3 -output=\u0026quot;_dist/{{.OS}}-{{.Arch}}/{{.Dir}}\u0026quot; -osarch='linux/arm' -tags '' -ldflags '-w -s -X k8s.io/helm/pkg/version.Version=2.9 -X k8s.io/helm/pkg/version.BuildMetadata= -X k8s.io/helm/pkg/version.GitCommit=20adb27c7c5868466912eebdf6664e7390ebe710 -X k8s.io/helm/pkg/version.GitTreeState=clean -extldflags \u0026quot;-static\u0026quot;' k8s.io/helm/cmd/helm Number of parallel builds: 3 --\u0026gt; linux/arm: k8s.io/helm/cmd/helm ( \\ cd _dist \u0026amp;\u0026amp; \\ find * -type d -exec cp ../LICENSE {} \\; \u0026amp;\u0026amp; \\ find * -type d -exec cp ../README.md {} \\; \u0026amp;\u0026amp; \\ find * -type d -exec tar -zcf helm-2.9-{}.tar.gz {} \\; \u0026amp;\u0026amp; \\ find * -type d -exec zip -r helm-2.9-{}.zip {} \\; \\ ) adding: linux-arm/ (stored 0%) adding: linux-arm/LICENSE (deflated 65%) adding: linux-arm/README.md (deflated 59%) adding: linux-arm/helm (deflated 67%)  Let\u0026rsquo;s transfer the helm binarie to RPI\nscp -r _dist/linux-arm/ rpiuser@192.168.1.95:/home/rpiuser/helm_binaries  Cross Compiling and Image cration from Travis-CI  WIP  Helm Cross Compiling from Ubuntu Machine Let\u0026rsquo;s assume we cloned the code for helm already.\nmake clean bootstrap build-cross dist APP=tiller VERSION=2.9 TARGETS=linux/arm ... go build -o bin/protoc-gen-go ./vendor/github.com/golang/protobuf/protoc-gen-go CGO_ENABLED=0 gox -parallel=3 -output=\u0026quot;_dist/{{.OS}}-{{.Arch}}/{{.Dir}}\u0026quot; -osarch='linux/arm' -tags '' -ldflags '-w -s -X k8s.io/helm/pkg/version.Version=2.9 -X k8s.io/helm/pkg/version.BuildMetadata= -X k8s.io/helm/pkg/version.GitCommit=20adb27c7c5868466912eebdf6664e7390ebe710 -X k8s.io/helm/pkg/version.GitTreeState=clean -extldflags \u0026quot;-static\u0026quot;' k8s.io/helm/cmd/tiller Number of parallel builds: 3 --\u0026gt; linux/arm: k8s.io/helm/cmd/tiller ( \\ cd _dist \u0026amp;\u0026amp; \\ find * -type d -exec cp ../LICENSE {} \\; \u0026amp;\u0026amp; \\ find * -type d -exec cp ../README.md {} \\; \u0026amp;\u0026amp; \\ find * -type d -exec tar -zcf helm-2.9-{}.tar.gz {} \\; \u0026amp;\u0026amp; \\ find * -type d -exec zip -r helm-2.9-{}.zip {} \\; \\ ) adding: linux-arm/ (stored 0%) adding: linux-arm/LICENSE (deflated 65%) adding: linux-arm/README.md (deflated 59%) adding: linux-arm/tiller (deflated 67%)  Build the docker image on the remote PI Create a Dockerfile called rootfs/Dockerfile.arm32v7\nFROM debian:jessie-slim RUN apt-get update \\ \u0026amp;\u0026amp; apt-get install -y --no-install-recommends ca-certificates \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* ENV HOME /tmp COPY _dist/linux-arm / EXPOSE 44134 CMD [\u0026quot;/tiller\u0026quot;]  export DHUBREPO=jbrette/tiller-arm32v7 export VERSION=2.9 docker build -t $DHUBREPO:$VERSION -f rootfs/Dockerfile.arm32v7 . Sending build context to Docker daemon 284.1MB Step 1/6 : FROM debian:jessie-slim ---\u0026gt; d273fca45b31 Step 2/6 : RUN apt-get update \u0026amp;\u0026amp; apt-get install -y --no-install-recommends ca-certificates \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* ---\u0026gt; Running in e51ea5c31ad7 Get:1 http://security.debian.org jessie/updates InRelease [44.9 kB] Ign http://deb.debian.org jessie InRelease Get:2 http://deb.debian.org jessie-updates InRelease [145 kB] Get:3 http://deb.debian.org jessie Release.gpg [2420 B] Get:4 http://deb.debian.org jessie Release [148 kB] Get:5 http://security.debian.org jessie/updates/main armel Packages [576 kB] Get:6 http://deb.debian.org jessie-updates/main armel Packages [23.7 kB] Get:7 http://deb.debian.org jessie/main armel Packages [8902 kB] Fetched 9843 kB in 49s (199 kB/s) Reading package lists... Reading package lists... Building dependency tree... Reading state information... The following extra packages will be installed: libssl1.0.0 openssl The following NEW packages will be installed: ca-certificates libssl1.0.0 openssl 0 upgraded, 3 newly installed, 0 to remove and 1 not upgraded. Need to get 1692 kB of archives. After this operation, 3770 kB of additional disk space will be used. Get:1 http://security.debian.org/debian-security/ jessie/updates/main ca-certificates all 20141019+deb8u4 [185 kB] Get:2 http://deb.debian.org/debian/ jessie/main libssl1.0.0 armel 1.0.1t-1+deb8u8 [852 kB] Get:3 http://deb.debian.org/debian/ jessie/main openssl armel 1.0.1t-1+deb8u8 [655 kB] debconf: delaying package configuration, since apt-utils is not installed Fetched 1692 kB in 7s (235 kB/s) Selecting previously unselected package libssl1.0.0:armel. (Reading database ... 7451 files and directories currently installed.) Preparing to unpack .../libssl1.0.0_1.0.1t-1+deb8u8_armel.deb ... Unpacking libssl1.0.0:armel (1.0.1t-1+deb8u8) ... Selecting previously unselected package openssl. Preparing to unpack .../openssl_1.0.1t-1+deb8u8_armel.deb ... Unpacking openssl (1.0.1t-1+deb8u8) ... Selecting previously unselected package ca-certificates. Preparing to unpack .../ca-certificates_20141019+deb8u4_all.deb ... Unpacking ca-certificates (20141019+deb8u4) ... Setting up libssl1.0.0:armel (1.0.1t-1+deb8u8) ... debconf: unable to initialize frontend: Dialog debconf: (TERM is not set, so the dialog frontend is not usable.) debconf: falling back to frontend: Readline debconf: unable to initialize frontend: Readline debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/arm-linux-gnueabi/perl/5.20.2 /usr/local/share/perl/5.20.2 /usr/lib/arm-linux-gnueabi/perl5/5.20 /usr/share/perl5 /usr/lib/arm-linux-gnueabi/perl/5.20 /usr/share/perl/5.20 /usr/local/lib/site_perl .) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.) debconf: falling back to frontend: Teletype Setting up openssl (1.0.1t-1+deb8u8) ... Setting up ca-certificates (20141019+deb8u4) ... debconf: unable to initialize frontend: Dialog debconf: (TERM is not set, so the dialog frontend is not usable.) debconf: falling back to frontend: Readline debconf: unable to initialize frontend: Readline debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/arm-linux-gnueabi/perl/5.20.2 /usr/local/share/perl/5.20.2 /usr/lib/arm-linux-gnueabi/perl5/5.20 /usr/share/perl5 /usr/lib/arm-linux-gnueabi/perl/5.20 /usr/share/perl/5.20 /usr/local/lib/site_perl .) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.) debconf: falling back to frontend: Teletype Updating certificates in /etc/ssl/certs... 152 added, 0 removed; done. Processing triggers for libc-bin (2.19-18+deb8u10) ... Processing triggers for ca-certificates (20141019+deb8u4) ... Updating certificates in /etc/ssl/certs... 0 added, 0 removed; done. Running hooks in /etc/ca-certificates/update.d....done. Removing intermediate container e51ea5c31ad7 ---\u0026gt; 1dccf46769e7 Step 3/6 : ENV HOME /tmp ---\u0026gt; Running in 45de8c047bd3 Removing intermediate container 45de8c047bd3 ---\u0026gt; baa6d8b15164 Step 4/6 : COPY _dist/linux-arm / ---\u0026gt; 59a6cc8bfdbe Step 5/6 : EXPOSE 44134 ---\u0026gt; Running in d2c6d9b3a3bc Removing intermediate container d2c6d9b3a3bc ---\u0026gt; 28a331217c52 Step 6/6 : CMD [\u0026quot;/tiller\u0026quot;] ---\u0026gt; Running in 9760ea4dc6c5 Removing intermediate container 9760ea4dc6c5 ---\u0026gt; 9384b4f39ab3 Successfully built 9384b4f39ab3 Successfully tagged jbrette/tiller-arm32v7:2.9  Cross Compiling and Image cration from Travis-CI  WIP  Install Tiller and Helm on RPI Install helm on PI ssh rpiuser@192.168.1.95 sudo cp /home/rpiuser/helm_binaries/helm /usr/bin/helm  Deploy Tiller POD First push the tiller docker image to the repo\ndocker login docker push jbrette/tiller-arm32v7:2.9  Prepare the POD deployment files\nmkdir -p ~/kube-deployments/tiller cd ~/kube-deployments/tiller  Create the kubectl file for tiller service account\ncat tiller-serviceaccount.yaml  --- apiVersion: v1 kind: ServiceAccount metadata: name: tiller namespace: kube-system ... --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: tiller roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: tiller namespace: kube-system ...  Create the tiller service account\nkubectl create -f tiller-serviceaccount.yaml serviceaccount/tiller created clusterrolebinding.rbac.authorization.k8s.io/tiller created  Create manually the tiller deployment file and leverage the tiller service account\nhelm init --service-account tiller --output yaml \u0026gt; tiller.yaml  Edit the image and replace gcr.io/kubernetes-helm/tiller:2.9 by jbrette/tiller-arm32v7:2.9\napiVersion: extensions/v1beta1 kind: Deployment metadata: creationTimestamp: null labels: app: helm name: tiller name: tiller-deploy namespace: kube-system spec: replicas: 1 strategy: {} template: metadata: creationTimestamp: null labels: app: helm name: tiller spec: containers: - env: - name: TILLER_NAMESPACE value: kube-system - name: TILLER_HISTORY_MAX value: \u0026quot;0\u0026quot; image: gcr.io/kubernetes-helm/tiller:2.9 imagePullPolicy: IfNotPresent livenessProbe: httpGet: path: /liveness port: 44135 initialDelaySeconds: 1 timeoutSeconds: 1 name: tiller ports: - containerPort: 44134 name: tiller - containerPort: 44135 name: http readinessProbe: httpGet: path: /readiness port: 44135 initialDelaySeconds: 1 timeoutSeconds: 1 resources: {} serviceAccountName: tiller status: {}  Deploy tiller in the kubernetes cluster\nkubectl create -f tiller.yaml  Check the deployment state\nkubectl get all -n kube-system NAME READY STATUS RESTARTS AGE pod/tiller-deploy-b59fcc885-66l7s 1/1 Running 0 5m NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/tiller-deploy 1 1 1 1 5m NAME DESIRED CURRENT READY AGE replicaset.apps/tiller-deploy-b59fcc885 1 1 1 5m  Check the logs\nkubectl logs pod/tiller-deploy-b59fcc885-66l7s -n kube-system [main] 2018/07/15 18:08:10 Starting Tiller 2.9 (tls=false) [main] 2018/07/15 18:08:10 GRPC listening on :44134 [main] 2018/07/15 18:08:10 Probes listening on :44135 [main] 2018/07/15 18:08:10 Storage driver is ConfigMap [main] 2018/07/15 18:08:10 Max history per release is 0  Init the Helm client side helm init --client-only Creating /home/rpiuser/.helm Creating /home/rpiuser/.helm/repository Creating /home/rpiuser/.helm/repository/cache Creating /home/rpiuser/.helm/repository/local Creating /home/rpiuser/.helm/plugins Creating /home/rpiuser/.helm/starters Creating /home/rpiuser/.helm/cache/archive Creating /home/rpiuser/.helm/repository/repositories.yaml Adding stable repo with URL: https://kubernetes-charts.storage.googleapis.com Adding local repo with URL: http://127.0.0.1:8879/charts $HELM_HOME has been configured at /home/rpiuser/.helm. Not installing Tiller due to 'client-only' flag having been set Happy Helming!  Check helm commands are working properly\nhelm ls helm search stable/nginx-ingress helm inspect stable/nginx-ingress  Use helm on RPI Let\u0026rsquo;s access the simple helm repo designed for\nhelm repo add kubeplay 'https://raw.githubusercontent.com/jbrette/kubeplay/arm32v7/helmrepo/'  helm repo list NAME URL stable https://kubernetes-charts.storage.googleapis.com local http://127.0.0.1:8879/charts kubeplay https://raw.githubusercontent.com/jbrette/kubeplay/arm32v7/helmrepo/  helm search kubeplay NAME CHART VERSION APP VERSION DESCRIPTION kubeplay/kubeplay-arm32v7 0.1.0 0.1.0 A Helm chart for Kubernetes  Install simple hello world helm chart from kubeplay\nhelm install kubeplay/kubeplay-arm32v7 --name helm-rpi NAME: helm-rpi LAST DEPLOYED: Sun Jul 15 19:23:58 2018 NAMESPACE: default STATUS: DEPLOYED RESOURCES: ==\u0026gt; v1/Service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helm-rpi-kubeplay-arm32v7 NodePort 10.96.168.184 \u0026lt;none\u0026gt; 8005:31439/TCP 2s ==\u0026gt; v1beta1/Deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE helm-rpi-kubeplay-arm32v7 1 0 0 0 2s  Check the installation\nhelm ls NAME REVISION UPDATED STATUS CHART NAMESPACE helm-rpi 1 Sun Jul 15 19:23:58 2018 DEPLOYED kubeplay-arm32v7-0.1.0 default  Check with kubectl if the POD is ready\nkubectl get all -n default NAME READY STATUS RESTARTS AGE pod/helm-rpi-kubeplay-arm32v7-58567c4756-fj968 0/1 Running 4 4m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/helm-rpi-kubeplay-arm32v7 NodePort 10.96.168.184 \u0026lt;none\u0026gt; 8005:31439/TCP 4m service/kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 9d NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/helm-rpi-kubeplay-arm32v7 1 1 1 0 4m NAME DESIRED CURRENT READY AGE replicaset.apps/helm-rpi-kubeplay-arm32v7-58567c4756 1 1 0 4m  Helm chart is not really consistent. Current image hardcoded to listen on port 80 Let\u0026rsquo;s use helm upgrade to change the value\nhelm upgrade --set service.internalPort=80 helm-rpi kubeplay/kubeplay-arm32v7 Release \u0026quot;helm-rpi\u0026quot; has been upgraded. Happy Helming! LAST DEPLOYED: Sun Jul 15 20:39:17 2018 NAMESPACE: default STATUS: DEPLOYED RESOURCES: ==\u0026gt; v1beta1/Deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE helm-rpi-kubeplay-arm32v7 1 1 0 0 1h ==\u0026gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE helm-rpi-kubeplay-arm32v7-58567c4756-fj968 0/1 Terminating 25 1h helm-rpi-kubeplay-arm32v7-6cb66496c6-9w97m 0/1 Pending 0 0s ==\u0026gt; v1/Service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE helm-rpi-kubeplay-arm32v7 NodePort 10.96.168.184 \u0026lt;none\u0026gt; 8005:31439/TCP 1h  The pod seems to now be running properly.\nkubectl get all -n default NAME READY STATUS RESTARTS AGE pod/helm-rpi-kubeplay-arm32v7-6cb66496c6-9w97m 1/1 Running 0 3m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/helm-rpi-kubeplay-arm32v7 NodePort 10.96.168.184 \u0026lt;none\u0026gt; 8005:31439/TCP 1h service/kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 9d NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/helm-rpi-kubeplay-arm32v7 1 1 1 1 1h NAME DESIRED CURRENT READY AGE replicaset.apps/helm-rpi-kubeplay-arm32v7-58567c4756 0 0 0 1h replicaset.apps/helm-rpi-kubeplay-arm32v7-6cb66496c6 1 1 1 3m  Check the POD\n$ kubectl describe pod/helm-rpi-kubeplay-arm32v7-6cb66496c6-9w97m Name: helm-rpi-kubeplay-arm32v7-6cb66496c6-9w97m Namespace: default Node: nas-pi/192.168.1.93 Start Time: Sun, 15 Jul 2018 20:39:18 +0000 Labels: app=kubeplay-arm32v7 pod-template-hash=2762205272 release=helm-rpi Annotations: \u0026lt;none\u0026gt; Status: Running IP: 10.244.2.6 Controlled By: ReplicaSet/helm-rpi-kubeplay-arm32v7-6cb66496c6 Containers: kubeplay-arm32v7: Container ID: docker://737cd78bebb982c782dae2c07f4604ba71f45bc112e91aa20652e29b25bf5d63 Image: jbrette/kubeplay-arm32v7:0.1.0 Image ID: docker-pullable://jbrette/kubeplay-arm32v7@sha256:86441999035e35514fc647ff9af90bdfc152299636b48b9d3dba9107574f3957 Port: 80/TCP Host Port: 0/TCP State: Running Started: Sun, 15 Jul 2018 20:39:23 +0000 Ready: True Restart Count: 0 Liveness: http-get http://:80/ delay=0s timeout=1s period=10s #success=1 #failure=3 Readiness: http-get http://:80/ delay=0s timeout=1s period=10s #success=1 #failure=3 Environment: \u0026lt;none\u0026gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-c5v7s (ro) Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: default-token-c5v7s: Type: Secret (a volume populated by a Secret) SecretName: default-token-c5v7s Optional: false QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 10m default-scheduler Successfully assigned default/helm-rpi-kubeplay-arm32v7-6cb66496c6-9w97m to nas-pi Normal Pulling 10m kubelet, nas-pi pulling image \u0026quot;jbrette/kubeplay-arm32v7:0.1.0\u0026quot; Normal Pulled 10m kubelet, nas-pi Successfully pulled image \u0026quot;jbrette/kubeplay-arm32v7:0.1.0\u0026quot; Normal Created 10m kubelet, nas-pi Created container Normal Started 10m kubelet, nas-pi Started container  Let\u0026rsquo;s open a browser towards the URL:\nConclusion  Need to cleanup the helm chart and docker image to ensure consistency of the internal Need to improve the NodePort/ClusterIP/LoadBalancer handling.  Reference Links  Usage of remote API  "
},
{
	"uri": "/pi_cluster/docker_kubernetes/children/2018-07-12-a/",
	"title": "Enable docker remote API",
	"tags": ["docker"],
	"description": "",
	"content": " Goal In order to build image for Raspberry PI, it is sometimes usefull to be able to leverate infrastruture from a remote VM. For instance you can cross-build golang executable for ARM32v7 and transfer it to build an image on the remote PI. (used for Tiller docker image)\nGenerating the server certs In the case this Kubernetes cluster, the master is running on master-pi with IP address 192.168.1.95\nas root\nmkdir -p $HOME/dockercerts cd $HOME/dockercerts/ openssl genrsa -aes256 -out ca-key.pem 4096 openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem openssl genrsa -out server-key.pem 4096 export HOST=master-pi openssl req -subj \u0026quot;/CN=$HOST\u0026quot; -sha256 -new -key server-key.pem -out server.csr echo subjectAltName = DNS:$HOST,IP:192.168.1.95,IP:127.0.0.1 \u0026gt;\u0026gt; extfile.cnf echo extendedKeyUsage = serverAuth \u0026gt;\u0026gt; extfile.cnf openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem -CAcreateserial -out server-cert.pem -extfile extfile. rm -v client.csr server.csr chmod -v 0400 ca-key.pem key.pem server-key.pem chmod -v 0444 ca.pem server-cert.pem cert.pem  Installing certs and configuring dockerd service cp $HOME/dockercerts/ca.pem /etc/docker cp $HOME/dockercerts/server-cert.pem /etc/docker/ cp $HOME/dockercerts/server-key.pem /etc/docker/  mkdir -p /etc/systemd/system/docker.service.d vi /etc/systemd/system/docker.service.d/10-tls-verify.conf [Service] ExecStart= ExecStart=/usr/bin/dockerd -H fd:// -H tcp://192.168.1.95:2376 --tlsverify --tlscacert=/etc/docker/ca.pem --tlscert=/etc/docker/server-cert.pem --tlskey=/etc/docker/server-key.pem Environment=\u0026quot;DOCKER_OPTS=--tlsverify --tlscacert=/etc/docker/ca.pem --tlscert=/etc/docker/server-cert.pem --tlskey=/etc/docker/server-key.pem\u0026quot;  Restart the service\nsystemctl daemon-reload systemctl restart docker.service  Installing client side on the PI does not have to be root.\ncp /root/dockercerts/ca.pem $HOME/.docker cp /root/dockercerts/key.pem $HOME/.docker/ cp /root/dockercerts/cert.pem $HOME/.docker/  docker --tlsverify -H tcp://192.168.1.95:2376 --tlscacert=$HOME/.docker/ca.pem --tlscert=$HOME/.docker/cert.pem --tlskey=$HOME/.docker/key.pem images  Installing client side on the remove VM Transfer the key from the master-pi to the local Ubuntu VM\nmkdir -p $HOME/.docker/master-pi cd $HOME/.docker/master-pi/ scp rpiuser@192.168.1.95:/home/rpiuser/.docker/master-pi/* .  Verify that the VM can access the remote PI\ndocker --tlsverify -H tcp://192.168.1.95:2376 --tlscacert=$HOME/.docker/master-pi/ca.pem --tlscert=$HOME/.docker/master-pi/cert.pem --tlskey=$HOME/.docker/master-pi/key.pem version  Use environment variable to simplify the command line\nexport DOCKER_CERT_PATH=~/.docker/master-pi export DOCKER_HOST=tcp://192.168.1.95:2376 export DOCKER_TLS_VERIFY=1 docker ps docker image list  Reference Links  coreos dockerd  "
},
{
	"uri": "/pi_cluster/maintenance/children/2018-07-11-a/",
	"title": "Use github repo as helm chart repository",
	"tags": ["github", "helm", "kubernetes"],
	"description": "",
	"content": " Goal In order to be able use Helm charts the \u0026ldquo;normal\u0026rdquo; way, it is need to buid your own helm repository. The goal of this post is to transform a github repo into a helm repo.\nKey Aspects  Save the helm charts on github mainly for the RPI Kubernetes cluster Figure out a way to access them  Build the chart and upload it to the helm repo For that purpose I used by kubeplay repo where I had helm charts and container ready\ngit clone -b arm32v7 git@github.com:jbrette/kubeplay.git cd kubeplay/ helm package charts/kubeplay-arm32v7/ --app-version 0.1.0 --destination ./helmrepo/ cd helmrepo/ helm repo index . git add . git commit -m \u0026quot;New chart version\u0026quot; git push  Use helm repo and chart Let\u0026rsquo;s access the simple helm repo designed for\nhelm repo add kubeplay 'https://raw.githubusercontent.com/jbrette/kubeplay/arm32v7/helmrepo/'  helm repo list NAME URL stable https://kubernetes-charts.storage.googleapis.com local http://127.0.0.1:8879/charts kubeplay https://raw.githubusercontent.com/jbrette/kubeplay/arm32v7/helmrepo/  helm search kubeplay NAME CHART VERSION APP VERSION DESCRIPTION kubeplay/kubeplay-arm32v7 0.1.0 0.1.0 A Helm chart for Kubernetes  Conclusion  Still has to find how to get Travis-CI to build the chart automatically  Reference Links  From hackernoon  "
},
{
	"uri": "/pi_cluster/docker_kubernetes/children/2018-07-08-a/",
	"title": "Add Persistency Volume to PI Clusters",
	"tags": ["kubernetes", "rpi"],
	"description": "",
	"content": " Goal In order to install OpenHAB, HomeAssistent or even promoteheus using Kubernetes, we need to first create Persistency Volumes\nProcedures  WIP  Results    Reference Links  TBD  "
},
{
	"uri": "/pi_cluster/os_installation/children/cluster_assembly/",
	"title": "Raspberry PI cluster Assembly",
	"tags": ["ansible", "rpi"],
	"description": "",
	"content": " Goal Links  PI Rack PI Heat Sink SD Cards Power Supply Power Supply Power Cable for PI Power Cable for Switch Cat 6 Cables Switch  Reference Links  Video1 Video2  "
},
{
	"uri": "/pi_cluster/os_installation/children/ansible/",
	"title": "Using Ansible to manage Raspberry PI cluster",
	"tags": ["ansible", "rpi"],
	"description": "",
	"content": " Goal Even if the ultimate goal is to manage completly the cluster using Kubernetes, the ability to use Ansible during debug process is very usefull. The goal here is to setup ansible inventory, basic playbooks.\nAnsible Installation on the master node Let\u0026rsquo;s install ansible using apt-get. A lot of python related depedencies are also installed.\nsudo apt-get install ansible Reading package lists... Done Building dependency tree Reading state information... Done The following additional packages will be installed: ieee-data libyaml-0-2 python-cffi-backend python-crypto python-cryptography python-enum34 python-httplib2 python-idna python-ipaddress python-jinja2 python-kerberos python-markupsafe python-netaddr python-paramiko python-pkg-resources python-pyasn1 python-selinux python-setuptools python-six python-xmltodict python-yaml Suggested packages: cowsay sshpass python-crypto-dbg python-crypto-doc python-cryptography-doc python-cryptography-vectors python-enum34-doc python-jinja2-doc ipython python-netaddr-docs python-gssapi doc-base python-setuptools-doc Recommended packages: python-winrm The following NEW packages will be installed: ansible ieee-data libyaml-0-2 python-cffi-backend python-crypto python-cryptography python-enum34 python-httplib2 python-idna python-ipaddress python-jinja2 python-kerberos python-markupsafe python-netaddr python-paramiko python-pkg-resources python-pyasn1 python-selinux python-setuptools python-six python-xmltodict python-yaml 0 upgraded, 22 newly installed, 0 to remove and 6 not upgraded. Need to get 4,556 kB of archives. After this operation, 28.4 MB of additional disk space will be used. Do you want to continue? [Y/n] y  $ ansible --version ansible 2.2.1.0 config file = /etc/ansible/ansible.cfg configured module search path = Default w/o overrides  sudo apt-get install sshpass Reading package lists... Done Building dependency tree Reading state information... Done The following NEW packages will be installed: sshpass 0 upgraded, 1 newly installed, 0 to remove and 6 not upgraded. Need to get 11.2 kB of archives. After this operation, 30.7 kB of additional disk space will be used. Get:1 http://raspbian.mirrors.lucidnetworks.net/raspbian stretch/main armhf sshpass armhf 1.06-1 [11.2 kB] Fetched 11.2 kB in 2s (4,785 B/s) Selecting previously unselected package sshpass. (Reading database ... 26786 files and directories currently installed.) Preparing to unpack .../sshpass_1.06-1_armhf.deb ... Unpacking sshpass (1.06-1) ... Setting up sshpass (1.06-1) ... Processing triggers for man-db (2.7.6.1-2) ...  Configure ansible Create directorties for ansible\nmkdir -p mgt/inventory mkdir -p mgt/playbooks mkdir -p mgt/rooles mkdir -p mgt/roles mkdir -p mgt/group_vars mkdir -p mgt/files mkdir -p mgt/inventory/host_vars  Let\u0026rsquo;s check the internal cluster network\ncat /etc/hosts 192.168.2.1 kubemaster-pi.kubepi kubemaster-pi 192.168.2.101 kube-node01.kubepi kube-node01 192.168.2.102 kube-node02.kubepi kube-node02 192.168.2.103 kube-node03.kubepi kube-node03 192.168.2.104 kube-node04.kubepi kube-node04  Let\u0026rsquo;s create an rsa key for Ansible SSH. Note the cluster is still using the default pirate account created by HypriotOS. Will change is later once ansible is up.\ncd ~/mgt ssh-keygen -t rsa -f mgtkey ssh-copy-id -i mgtkey.pub pirate@kubemaster-pi ssh-copy-id -i mgtkey.pub pirate@kube-node01 ssh-copy-id -i mgtkey.pub pirate@kube-node02 ssh-copy-id -i mgtkey.pub pirate@kube-node03 ssh-copy-id -i mgtkey.pub pirate@kube-node04  Create a first ansible host_var. We will use the mgtkey for ssh/ansible.\ncd ~/mgt/inventory/host_vars cat kubemaster-pi.kubepi ansible_host: 192.168.2.FOOBAR ansible_port: 22 ansible_user: pirate ansible_ssh_private_key_file: mgtkey  for i in kube-node01 kube-node02 kube-node03 kube-node04 do cp kubemaster-pi.kubepi $i.kubepi done  Replace FOOBAR by the proper value\nvi *.kubepi  Create the main inventory file\ncd ~/mgt/inventory cat hosts --- [picluster:children] masters workers [masters] kubemaster-pi.kubepi [workers] kube-node01.kubepi kube-node02.kubepi kube-node03.kubepi kube-node04.kubepi  Use ansible Simple ping ansible picluster -i inventory/ -m ping kube-node01.kubepi | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; } kube-node04.kubepi | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; } kube-node03.kubepi | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; } kubemaster-pi.kubepi | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; } kube-node02.kubepi | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; }  ansible masters -i inventory/ -m ping kubemaster-pi.kubepi | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; }  ansible workers -i inventory/ -m ping kube-node01.kubepi | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; } kube-node03.kubepi | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; } kube-node02.kubepi | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot; } kube-node04.kubepi | SUCCESS =\u0026gt; { \u0026quot;changed\u0026quot;: false, \u0026quot;ping\u0026quot;: \u0026quot;pong\u0026quot;  Retrieve Facts ansible picluster -i inventory/ -m setup  Update all the nodes in the cluster Create a simple playbook\ncat playbooks/aptupdate.yml --- - hosts: picluster tasks: - name: update apt become: true apt: update_cache: yes  Run the simple aptupdate playbook\nansible-playbook -i inventory/ playbooks/aptupdate.yml PLAY [picluster] *************************************************************** TASK [setup] ******************************************************************* ok: [kubemaster-pi.kubepi] ok: [kube-node03.kubepi] ok: [kube-node04.kubepi] ok: [kube-node02.kubepi] ok: [kube-node01.kubepi] TASK [update apt] ************************************************************** changed: [kube-node02.kubepi] changed: [kubemaster-pi.kubepi] changed: [kube-node01.kubepi] changed: [kube-node03.kubepi] changed: [kube-node04.kubepi] PLAY RECAP ********************************************************************* kube-node01.kubepi : ok=2 changed=1 unreachable=0 failed=0 kube-node02.kubepi : ok=2 changed=1 unreachable=0 failed=0 kube-node03.kubepi : ok=2 changed=1 unreachable=0 failed=0 kube-node04.kubepi : ok=2 changed=1 unreachable=0 failed=0 kubemaster-pi.kubepi : ok=2 changed=1 unreachable=0 failed=0  Check the version of kubeadm ansible picluster -i inventory -m shell -a \u0026quot;kubeadm version\u0026quot; kube-node04.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; kubeadm version: \u0026amp;version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;9\u0026quot;, GitVersion:\u0026quot;v1.9.8\u0026quot;, GitCommit:\u0026quot;c138b85178156011dc934c2c9f4837476876fb07\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-05-21T18:53:18Z\u0026quot;, GoVersion:\u0026quot;go1.9.3\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/arm\u0026quot;} kube-node03.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; kubeadm version: \u0026amp;version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;9\u0026quot;, GitVersion:\u0026quot;v1.9.8\u0026quot;, GitCommit:\u0026quot;c138b85178156011dc934c2c9f4837476876fb07\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-05-21T18:53:18Z\u0026quot;, GoVersion:\u0026quot;go1.9.3\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/arm\u0026quot;} kube-node01.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; kubeadm version: \u0026amp;version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;9\u0026quot;, GitVersion:\u0026quot;v1.9.8\u0026quot;, GitCommit:\u0026quot;c138b85178156011dc934c2c9f4837476876fb07\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-05-21T18:53:18Z\u0026quot;, GoVersion:\u0026quot;go1.9.3\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/arm\u0026quot;} kubemaster-pi.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; kubeadm version: \u0026amp;version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;9\u0026quot;, GitVersion:\u0026quot;v1.9.8\u0026quot;, GitCommit:\u0026quot;c138b85178156011dc934c2c9f4837476876fb07\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-05-21T18:53:18Z\u0026quot;, GoVersion:\u0026quot;go1.9.3\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/arm\u0026quot;} kube-node02.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; kubeadm version: \u0026amp;version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;9\u0026quot;, GitVersion:\u0026quot;v1.9.8\u0026quot;, GitCommit:\u0026quot;c138b85178156011dc934c2c9f4837476876fb07\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-05-21T18:53:18Z\u0026quot;, GoVersion:\u0026quot;go1.9.3\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/arm\u0026quot;}  Check the temperature ansible picluster -i inventory -m shell -a \u0026quot;vcgencmd measure_temp\u0026quot; kube-node03.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; temp=36.5'C kubemaster-pi.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; temp=49.4'C kube-node02.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; temp=33.2'C kube-node04.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; temp=34.3'C kube-node01.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; temp=32.2'C  Check the connected devices Check the components of the PI composing the cluster (Those are PI 3B+)\nansible picluster -i inventory -m shell -a \u0026quot;lsusb\u0026quot; kubemaster-pi.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; Bus 001 Device 004: ID 0424:7800 Standard Microsystems Corp. Bus 001 Device 003: ID 0424:2514 Standard Microsystems Corp. USB 2.0 Hub Bus 001 Device 002: ID 0424:2514 Standard Microsystems Corp. USB 2.0 Hub Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub kube-node02.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; Bus 001 Device 004: ID 0424:7800 Standard Microsystems Corp. Bus 001 Device 003: ID 0424:2514 Standard Microsystems Corp. USB 2.0 Hub Bus 001 Device 002: ID 0424:2514 Standard Microsystems Corp. USB 2.0 Hub Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub kube-node01.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; Bus 001 Device 004: ID 0424:7800 Standard Microsystems Corp. Bus 001 Device 003: ID 0424:2514 Standard Microsystems Corp. USB 2.0 Hub Bus 001 Device 002: ID 0424:2514 Standard Microsystems Corp. USB 2.0 Hub Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub kube-node04.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; Bus 001 Device 004: ID 0424:7800 Standard Microsystems Corp. Bus 001 Device 003: ID 0424:2514 Standard Microsystems Corp. USB 2.0 Hub Bus 001 Device 002: ID 0424:2514 Standard Microsystems Corp. USB 2.0 Hub Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub kube-node03.kubepi | SUCCESS | rc=0 \u0026gt;\u0026gt; Bus 001 Device 004: ID 0424:7800 Standard Microsystems Corp. Bus 001 Device 003: ID 0424:2514 Standard Microsystems Corp. USB 2.0 Hub Bus 001 Device 002: ID 0424:2514 Standard Microsystems Corp. USB 2.0 Hub Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub  On the second cluster, some of the nodes are PI 3B instead of PI 3B+. LAN and WLAN are different.\nansible picluster -i inventory -m shell -s -a \u0026quot;lsusb\u0026quot; master-pi.kubedge.cloud | SUCCESS | rc=0 \u0026gt;\u0026gt; Bus 001 Device 004: ID 0424:7800 Standard Microsystems Corp. Bus 001 Device 003: ID 0424:2514 Standard Microsystems Corp. USB 2.0 Hub Bus 001 Device 002: ID 0424:2514 Standard Microsystems Corp. USB 2.0 Hub Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub home-pi.kubedge.cloud | SUCCESS | rc=0 \u0026gt;\u0026gt; Bus 001 Device 004: ID 10c4:8a2a Cygnal Integrated Products, Inc. Bus 001 Device 003: ID 0424:ec00 Standard Microsystems Corp. SMSC9512/9514 Fast Ethernet Adapter Bus 001 Device 002: ID 0424:9514 Standard Microsystems Corp. SMC9514 Hub Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub nas-pi.kubedge.cloud | SUCCESS | rc=0 \u0026gt;\u0026gt; Bus 001 Device 003: ID 0424:ec00 Standard Microsystems Corp. SMSC9512/9514 Fast Ethernet Adapter Bus 001 Device 002: ID 0424:9514 Standard Microsystems Corp. SMC9514 Hub Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub  Other usefull commands ansible picluster -i inventory -m shell -a \u0026quot;lsusb\u0026quot; ansible picluster -i inventory -m shell -a \u0026quot;dmesg\u0026quot; ansible picluster -i inventory -m shell -a \u0026quot;usb-devices\u0026quot; ansible picluster -i inventory -m shell -a \u0026quot;lsblk\u0026quot; ansible picluster -i inventory -m shell -a \u0026quot;blkid\u0026quot; ansible picluster -i inventory -m shell -a \u0026quot;fdisk -l\u0026quot;  Reference Links  TBD  "
},
{
	"uri": "/pi_cluster/docker_kubernetes/children/2018-07-03-a/",
	"title": "Creating a Raspberry 3 B+ Kubernetes Cluster",
	"tags": ["kubernetes", "rpi"],
	"description": "",
	"content": " Goal Also GCE is perfect to learn Kubernetes, building Kubernetes on top of PI Cluster brings another dimension to the learning, from setting up the OS, partitionning the OS, DHCP, NAT, cross compiling for the ARM32V7.\nKey Aspects  Build a Raspberry 3B+ Cluster Deploy Kubernetes on that Cluster  Hardware Reference Links  Video  Procedure  Kind of followed the video Used a premade rack instead. Adapt to Raspberry 3B+ (1Gb card instead of 100Mb card)  Result Cluster 1: 5 nodes cluster Cluster 2: 3 nodes cluster OS Reference Links  Video HypriotOS  Procedure  Use HypriotOS because the quickest to set up. SSH and Docker supported by default Ubuntu Core was not ready for Raspberry 3B + Even if processor is 64bits, OS is still 32bits. (Memory is small anyway). Resion.io OS is not supporting docker anymore but balena instead. It would not work with Kubernetes. Video had a couple of typo in DHCP installation Removed cloud-init once the site was up. TBD  Kubernetes Reference Links  kubeadm1 kubeadm2  Procedure for Cluster 2  Issue at first with 10.04. Kubelet not starting. Downgraded with Kubernetes 1.9.8 (Cluster 1) Issue had been fixed with Kubernetes 1.11 (Cluster 2)  sudo -i curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - echo \u0026quot;deb http://apt.kubernetes.io/ kubernetes-xenial main\u0026quot; \u0026gt; /etc/apt/sources.list.d/kubernetes.list apt-get update \u0026amp;\u0026amp; apt-get install -y kubeadm  # kubeadm init --pod-network-cidr 10.244.0.0/16 --apiserver-advertise-address 192.168.1.95 I0706 00:35:34.429323 14024 feature_gate.go:230] feature gates: \u0026amp;{map[]} [init] using Kubernetes version: v1.11.0 [preflight] running pre-flight checks I0706 00:35:34.656171 14024 kernel_validator.go:81] Validating kernel version I0706 00:35:34.657051 14024 kernel_validator.go:96] Validating kernel config [WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 18.05.0-ce. Max validated version: 17.03 [preflight/images] Pulling images required for setting up a Kubernetes cluster [preflight/images] This might take a minute or two, depending on the speed of your internet connection [preflight/images] You can also perform this action in beforehand using 'kubeadm config images pull' [kubelet] Writing kubelet environment file with flags to file \u0026quot;/var/lib/kubelet/kubeadm-flags.env\u0026quot; [kubelet] Writing kubelet configuration to file \u0026quot;/var/lib/kubelet/config.yaml\u0026quot; [preflight] Activating the kubelet service [certificates] Generated ca certificate and key. [certificates] Generated apiserver certificate and key. [certificates] apiserver serving cert is signed for DNS names [master-pi kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.1.95] [certificates] Generated apiserver-kubelet-client certificate and key. [certificates] Generated sa key and public key. [certificates] Generated front-proxy-ca certificate and key. [certificates] Generated front-proxy-client certificate and key. [certificates] Generated etcd/ca certificate and key. [certificates] Generated etcd/server certificate and key. [certificates] etcd/server serving cert is signed for DNS names [master-pi localhost] and IPs [127.0.0.1 ::1] [certificates] Generated etcd/peer certificate and key. [certificates] etcd/peer serving cert is signed for DNS names [master-pi localhost] and IPs [192.168.1.95 127.0.0.1 ::1] [certificates] Generated etcd/healthcheck-client certificate and key. [certificates] Generated apiserver-etcd-client certificate and key. [certificates] valid certificates and keys now exist in \u0026quot;/etc/kubernetes/pki\u0026quot; [kubeconfig] Wrote KubeConfig file to disk: \u0026quot;/etc/kubernetes/admin.conf\u0026quot; [kubeconfig] Wrote KubeConfig file to disk: \u0026quot;/etc/kubernetes/kubelet.conf\u0026quot; [kubeconfig] Wrote KubeConfig file to disk: \u0026quot;/etc/kubernetes/controller-manager.conf\u0026quot; [kubeconfig] Wrote KubeConfig file to disk: \u0026quot;/etc/kubernetes/scheduler.conf\u0026quot; [controlplane] wrote Static Pod manifest for component kube-apiserver to \u0026quot;/etc/kubernetes/manifests/kube-apiserver.yaml\u0026quot; [controlplane] wrote Static Pod manifest for component kube-controller-manager to \u0026quot;/etc/kubernetes/manifests/kube-controller-manager.yaml\u0026quot; [controlplane] wrote Static Pod manifest for component kube-scheduler to \u0026quot;/etc/kubernetes/manifests/kube-scheduler.yaml\u0026quot; [etcd] Wrote Static Pod manifest for a local etcd instance to \u0026quot;/etc/kubernetes/manifests/etcd.yaml\u0026quot; [init] waiting for the kubelet to boot up the control plane as Static Pods from directory \u0026quot;/etc/kubernetes/manifests\u0026quot; [init] this might take a minute or longer if the control plane images have to be pulled [apiclient] All control plane components are healthy after 77.506994 seconds [uploadconfig] storing the configuration used in ConfigMap \u0026quot;kubeadm-config\u0026quot; in the \u0026quot;kube-system\u0026quot; Namespace [kubelet] Creating a ConfigMap \u0026quot;kubelet-config-1.11\u0026quot; in namespace kube-system with the configuration for the kubelets in the cluster [markmaster] Marking the node master-pi as master by adding the label \u0026quot;node-role.kubernetes.io/master=''\u0026quot; [markmaster] Marking the node master-pi as master by adding the taints [node-role.kubernetes.io/master:NoSchedule] [patchnode] Uploading the CRI Socket information \u0026quot;/var/run/dockershim.sock\u0026quot; to the Node API object \u0026quot;master-pi\u0026quot; as an annotation [bootstraptoken] using token: 120d6b.yyyyyyy [bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstraptoken] creating the \u0026quot;cluster-info\u0026quot; ConfigMap in the \u0026quot;kube-public\u0026quot; namespace [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes master has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \u0026quot;kubectl apply -f [podnetwork].yaml\u0026quot; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ You can now join any number of machines by running the following on each node as root: kubeadm join 192.168.1.95:6443 --token 120d6b.yyyyyyy --discovery-token-ca-cert-hash sha256:xxxxxx  on master\nmkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config kubectl get nodes  curl -sSL https://rawgit.com/coreos/flannel/v0.9.1/Documentation/kube-flannel.yml | sed \u0026quot;s/amd64/arm/g\u0026quot; | kubectl create -f -  on first node\nkubeadm join 192.168.1.95:6443 --token 120d6b.yyyyyyy --discovery-token-ca-cert-hash sha256:xxxxxx  on second node\nkubeadm join 192.168.1.95:6443 --token 120d6b.yyyyyyy --discovery-token-ca-cert-hash sha256:xxxxxx  Kubernetes Cluster 1: 5 node clusters kubectl get nodes NAME STATUS ROLES AGE VERSION kube-node01 Ready \u0026lt;none\u0026gt; 23d v1.9.8 kube-node02 Ready \u0026lt;none\u0026gt; 23d v1.9.8 kube-node03 Ready \u0026lt;none\u0026gt; 23d v1.9.8 kube-node04 Ready \u0026lt;none\u0026gt; 23d v1.9.8 kubemaster-pi Ready master 23d v1.9.8  kubectl get all --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE default pod/hypriot-587768b4f5-7bqpz 1/1 Running 0 23d default pod/hypriot-587768b4f5-b8xjq 1/1 Running 0 23d default pod/hypriot-587768b4f5-s2mzt 1/1 Running 0 23d kube-system pod/etcd-kubemaster-pi 1/1 Running 0 23d kube-system pod/kube-apiserver-kubemaster-pi 1/1 Running 0 23d kube-system pod/kube-controller-manager-kubemaster-pi 1/1 Running 0 23d kube-system pod/kube-dns-7b6ff86f69-l7lf6 3/3 Running 0 23d kube-system pod/kube-flannel-ds-8xbx4 1/1 Running 0 23d kube-system pod/kube-flannel-ds-9cz9f 1/1 Running 0 23d kube-system pod/kube-flannel-ds-rgpcq 1/1 Running 0 23d kube-system pod/kube-flannel-ds-xnjtz 1/1 Running 0 23d kube-system pod/kube-flannel-ds-xxdf6 1/1 Running 0 23d kube-system pod/kube-proxy-5m95q 1/1 Running 0 23d kube-system pod/kube-proxy-7sh7m 1/1 Running 0 23d kube-system pod/kube-proxy-f7t9r 1/1 Running 0 23d kube-system pod/kube-proxy-pkqvd 1/1 Running 0 23d kube-system pod/kube-proxy-shrdr 1/1 Running 0 23d kube-system pod/kube-scheduler-kubemaster-pi 1/1 Running 0 23d kube-system pod/kubernetes-dashboard-7fcc5cb979-8vbmp 1/1 Running 0 23d NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default service/hypriot ClusterIP 10.110.24.241 \u0026lt;none\u0026gt; 80/TCP 23d default service/kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 23d kube-system service/kube-dns ClusterIP 10.96.0.10 \u0026lt;none\u0026gt; 53/UDP,53/TCP 23d kube-system service/kubernetes-dashboard NodePort 10.102.144.189 \u0026lt;none\u0026gt; 443:30383/TCP 23d NAMESPACE NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE kube-system daemonset.extensions/kube-flannel-ds 5 5 5 5 5 beta.kubernetes.io/arch=arm 23d kube-system daemonset.extensions/kube-proxy 5 5 5 5 5 \u0026lt;none\u0026gt; 23d NAMESPACE NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE default deployment.extensions/hypriot 3 3 3 3 23d kube-system deployment.extensions/kube-dns 1 1 1 1 23d kube-system deployment.extensions/kubernetes-dashboard 1 1 1 1 23d NAMESPACE NAME DESIRED CURRENT READY AGE default replicaset.extensions/hypriot-587768b4f5 3 3 3 23d kube-system replicaset.extensions/kube-dns-7b6ff86f69 1 1 1 23d kube-system replicaset.extensions/kubernetes-dashboard-7fcc5cb979 1 1 1 23d NAMESPACE NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE kube-system daemonset.apps/kube-flannel-ds 5 5 5 5 5 beta.kubernetes.io/arch=arm 23d kube-system daemonset.apps/kube-proxy 5 5 5 5 5 \u0026lt;none\u0026gt; 23d NAMESPACE NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE default deployment.apps/hypriot 3 3 3 3 23d kube-system deployment.apps/kube-dns 1 1 1 1 23d kube-system deployment.apps/kubernetes-dashboard 1 1 1 1 23d NAMESPACE NAME DESIRED CURRENT READY AGE default replicaset.apps/hypriot-587768b4f5 3 3 3 23d kube-system replicaset.apps/kube-dns-7b6ff86f69 1 1 1 23d kube-system replicaset.apps/kubernetes-dashboard-7fcc5cb979 1 1 1 23d  Cluster 2: 3 node clusters kubectl get nodes NAME STATUS ROLES AGE VERSION home-pi Ready \u0026lt;none\u0026gt; 56m v1.11.0 master-pi Ready master 1h v1.11.0 nas-pi Ready \u0026lt;none\u0026gt; 5m v1.11.0  kubectl get all --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system pod/coredns-78fcdf6894-cw5p8 1/1 Running 0 59m kube-system pod/coredns-78fcdf6894-czjcj 1/1 Running 0 1h kube-system pod/etcd-master-pi 1/1 Running 0 1h kube-system pod/kube-apiserver-master-pi 1/1 Running 0 59m kube-system pod/kube-controller-manager-master-pi 1/1 Running 12 1h kube-system pod/kube-flannel-ds-bhllh 1/1 Running 2 3m kube-system pod/kube-flannel-ds-q7cp2 1/1 Running 0 22m kube-system pod/kube-flannel-ds-wqxsz 1/1 Running 0 22m kube-system pod/kube-proxy-4chwh 1/1 Running 0 45m kube-system pod/kube-proxy-6r5mn 1/1 Running 0 3m kube-system pod/kube-proxy-vvj6j 1/1 Running 0 1h kube-system pod/kube-scheduler-master-pi 1/1 Running 0 59m NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default service/kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 1h kube-system service/kube-dns ClusterIP 10.96.0.10 \u0026lt;none\u0026gt; 53/UDP,53/TCP 1h NAMESPACE NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE kube-system daemonset.apps/kube-flannel-ds 3 3 3 3 3 beta.kubernetes.io/arch=arm 53m kube-system daemonset.apps/kube-proxy 3 3 3 3 3 beta.kubernetes.io/arch=arm 1h NAMESPACE NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE kube-system deployment.apps/coredns 2 2 2 2 1h NAMESPACE NAME DESIRED CURRENT READY AGE kube-system replicaset.apps/coredns-78fcdf6894 2 2 2 1h  Kubernetes Dashboard Cluster 1: 5 node clusters List of the nodes in Cluster 1\nKubernetes kube-system overview of Cluster 1\nCluster 2: 3 node clusters List of the nodes in Cluster 2\nKubernetes kube-system overview of Cluster 2\nCleanup cleanup\nsudo kubeadm reset sudo docker rm $(sudo docker ps -qa) sudo docker image rm $(sudo docker image list -qa) sudo apt-get upgrade  "
},
{
	"uri": "/pi_cluster/maintenance/children/2018-07-02-a/",
	"title": "Compile and Test SONOBUOY",
	"tags": ["kubernetes", "sonobuoy", "test-infra", "testing"],
	"description": "",
	"content": " Goal Sonobouy, deploys in a Kubernetes cluster and helps to assesse the compliance of that cluster\nKey Aspects  Fork Sonobuoy Compile the tools Test it  Clone and Compile mkdir -p $HOME/src/github.com/heptio cd $HOME/src/github.com/heptio git clone git@github.com:jbrette/sonobuoy.git  export GOPATH=$HOME go version go version go1.10.1 linux/amd64  go get -u -v github.com/heptio/sonobuoy  sonobuoy run sonobuoy status  kubectl get all -n heptio-sonobuoy NAME READY STATUS RESTARTS AGE pod/sonobuoy 1/1 Running 0 14m pod/sonobuoy-e2e-job-5fff584d11364ca1 2/2 Running 0 12m pod/sonobuoy-systemd-logs-daemon-set-1c53f31cf14246ca-mhztp 2/2 Running 0 12m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/sonobuoy-master ClusterIP 10.99.111.192 \u0026lt;none\u0026gt; 8080/TCP 14m NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE daemonset.apps/sonobuoy-systemd-logs-daemon-set-1c53f31cf14246ca 1 1 1 1 1 \u0026lt;none\u0026gt; 12m  sonobuoy logs see end of the file  Usefull Links  Link1  SONOBUOY LOGS namespace=\u0026quot;heptio-sonobuoy\u0026quot; pod=\u0026quot;sonobuoy-e2e-job-5fff584d11364ca1\u0026quot; container=\u0026quot;sonobuoy-worker\u0026quot; time=\u0026quot;2018-07-03T06:01:55Z\u0026quot; level=info msg=\u0026quot;Waiting for waitfile\u0026quot; waitfile=/tmp/results/done namespace=\u0026quot;heptio-sonobuoy\u0026quot; pod=\u0026quot;sonobuoy\u0026quot; container=\u0026quot;kube-sonobuoy\u0026quot; time=\u0026quot;2018-07-03T06:00:23Z\u0026quot; level=info msg=\u0026quot;Scanning plugins in ./plugins.d (pwd: /)\u0026quot; time=\u0026quot;2018-07-03T06:00:23Z\u0026quot; level=info msg=\u0026quot;Scanning plugins in /etc/sonobuoy/plugins.d (pwd: /)\u0026quot; time=\u0026quot;2018-07-03T06:00:23Z\u0026quot; level=info msg=\u0026quot;Directory (/etc/sonobuoy/plugins.d) does not exist\u0026quot; time=\u0026quot;2018-07-03T06:00:23Z\u0026quot; level=info msg=\u0026quot;Scanning plugins in ~/sonobuoy/plugins.d (pwd: /)\u0026quot; time=\u0026quot;2018-07-03T06:00:23Z\u0026quot; level=info msg=\u0026quot;Directory (~/sonobuoy/plugins.d) does not exist\u0026quot; time=\u0026quot;2018-07-03T06:00:23Z\u0026quot; level=info msg=\u0026quot;Filtering namespaces based on the following regex:.*|heptio-sonobuoy\u0026quot; time=\u0026quot;2018-07-03T06:00:23Z\u0026quot; level=info msg=\u0026quot;Namespace default Matched=true\u0026quot; time=\u0026quot;2018-07-03T06:00:23Z\u0026quot; level=info msg=\u0026quot;Namespace heptio-sonobuoy Matched=true\u0026quot; time=\u0026quot;2018-07-03T06:00:23Z\u0026quot; level=info msg=\u0026quot;Namespace kube-public Matched=true\u0026quot; time=\u0026quot;2018-07-03T06:00:23Z\u0026quot; level=info msg=\u0026quot;Namespace kube-system Matched=true\u0026quot; time=\u0026quot;2018-07-03T06:00:23Z\u0026quot; level=info msg=\u0026quot;Starting server Expected Results: [{ e2e} {ubuntuvm systemd_logs}]\u0026quot; time=\u0026quot;2018-07-03T06:00:23Z\u0026quot; level=info msg=\u0026quot;starting aggregation server\u0026quot; address=0.0.0.0 port=8080 time=\u0026quot;2018-07-03T06:00:23Z\u0026quot; level=info msg=\u0026quot;Running plugin\u0026quot; plugin=e2e time=\u0026quot;2018-07-03T06:00:23Z\u0026quot; level=info msg=\u0026quot;Running plugin\u0026quot; plugin=systemd-logs time=\u0026quot;2018-07-03T06:01:53Z\u0026quot; level=info msg=\u0026quot;received aggregator request\u0026quot; client_cert=systemd-logs node=ubuntuvm plugin_name=systemd_logs namespace=\u0026quot;heptio-sonobuoy\u0026quot; pod=\u0026quot;sonobuoy-e2e-job-5fff584d11364ca1\u0026quot; container=\u0026quot;e2e\u0026quot; /usr/local/bin/ginkgo --focus=\\[Conformance\\] --skip=Alpha|Kubectl|\\[(Disruptive|Feature:[^\\]]+|Flaky)\\] --noColor=true --nodes=1 /usr/local/bin/e2e.test -- --disable-log-dump --repo-root=/kubernetes --provider=\u0026quot;local\u0026quot; --report-dir=\u0026quot;/tmp/results\u0026quot; --kubeconfig=\u0026quot;\u0026quot; Jul 3 06:01:53.046: INFO: Overriding default scale value of zero to 1 Jul 3 06:01:53.046: INFO: Overriding default milliseconds value of zero to 5000 I0703 06:01:53.233115 17 test_context.go:382] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-559575868 I0703 06:01:53.233377 17 e2e.go:333] Starting e2e run \u0026quot;954001dd-7e86-11e8-9aa2-c6770944a2e6\u0026quot; on Ginkgo node 1 Running Suite: Kubernetes e2e suite =================================== Random Seed: 1530597712 - Will randomize all specs Will run 144 of 998 specs Jul 3 06:01:53.320: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 Jul 3 06:01:53.322: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable Jul 3 06:01:53.333: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready Jul 3 06:01:53.371: INFO: 11 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed) Jul 3 06:01:53.371: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready. Jul 3 06:01:53.377: INFO: Waiting for pods to enter Success, but no pods in \u0026quot;kube-system\u0026quot; match label map[name:e2e-image-puller] Jul 3 06:01:53.377: INFO: Dumping network health container logs from all nodes to file /tmp/results/nethealth.txt Jul 3 06:01:53.381: INFO: e2e test version: v1.11.0 Jul 3 06:01:53.382: INFO: kube-apiserver version: v1.11.0 SSS ------------------------------ [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-storage] EmptyDir volumes /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:01:53.382: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object Jul 3 06:01:53.446: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled. STEP: Waiting for a default service account to be provisioned in namespace [It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating a pod to test emptydir 0777 on tmpfs Jul 3 06:01:53.458: INFO: Waiting up to 5m0s for pod \u0026quot;pod-958bb7dc-7e86-11e8-9aa2-c6770944a2e6\u0026quot; in namespace \u0026quot;e2e-tests-emptydir-hhx7j\u0026quot; to be \u0026quot;success or failure\u0026quot; Jul 3 06:01:53.462: INFO: Pod \u0026quot;pod-958bb7dc-7e86-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 4.316916ms Jul 3 06:01:55.470: INFO: Pod \u0026quot;pod-958bb7dc-7e86-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 2.012312995s Jul 3 06:01:57.483: INFO: Pod \u0026quot;pod-958bb7dc-7e86-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 4.025109994s Jul 3 06:01:59.488: INFO: Pod \u0026quot;pod-958bb7dc-7e86-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Succeeded\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 6.030152763s STEP: Saw pod success Jul 3 06:01:59.488: INFO: Pod \u0026quot;pod-958bb7dc-7e86-11e8-9aa2-c6770944a2e6\u0026quot; satisfied condition \u0026quot;success or failure\u0026quot; Jul 3 06:01:59.496: INFO: Trying to get logs from node ubuntuvm pod pod-958bb7dc-7e86-11e8-9aa2-c6770944a2e6 container test-container: \u0026lt;nil\u0026gt; STEP: delete the pod Jul 3 06:01:59.570: INFO: Waiting for pod pod-958bb7dc-7e86-11e8-9aa2-c6770944a2e6 to disappear Jul 3 06:01:59.578: INFO: Pod pod-958bb7dc-7e86-11e8-9aa2-c6770944a2e6 no longer exists [AfterEach] [sig-storage] EmptyDir volumes /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:01:59.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-emptydir-hhx7j\u0026quot; for this suite. Jul 3 06:02:05.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:02:05.743: INFO: namespace: e2e-tests-emptydir-hhx7j, resource: bindings, ignored listing per whitelist Jul 3 06:02:05.789: INFO: namespace e2e-tests-emptydir-hhx7j deletion completed in 6.205463311s • [SLOW TEST:12.407 seconds] [sig-storage] EmptyDir volumes /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40 should support (non-root,0777,tmpfs) [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-storage] Secrets /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:02:05.790: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating secret with name secret-test-9cfc3c2a-7e86-11e8-9aa2-c6770944a2e6 STEP: Creating a pod to test consume secrets Jul 3 06:02:05.945: INFO: Waiting up to 5m0s for pod \u0026quot;pod-secrets-9cfd5a21-7e86-11e8-9aa2-c6770944a2e6\u0026quot; in namespace \u0026quot;e2e-tests-secrets-27nw4\u0026quot; to be \u0026quot;success or failure\u0026quot; Jul 3 06:02:05.956: INFO: Pod \u0026quot;pod-secrets-9cfd5a21-7e86-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 11.604319ms Jul 3 06:02:07.962: INFO: Pod \u0026quot;pod-secrets-9cfd5a21-7e86-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 2.017009791s Jul 3 06:02:09.967: INFO: Pod \u0026quot;pod-secrets-9cfd5a21-7e86-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 4.022881248s Jul 3 06:02:11.971: INFO: Pod \u0026quot;pod-secrets-9cfd5a21-7e86-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Succeeded\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 6.026083073s STEP: Saw pod success Jul 3 06:02:11.971: INFO: Pod \u0026quot;pod-secrets-9cfd5a21-7e86-11e8-9aa2-c6770944a2e6\u0026quot; satisfied condition \u0026quot;success or failure\u0026quot; Jul 3 06:02:11.974: INFO: Trying to get logs from node ubuntuvm pod pod-secrets-9cfd5a21-7e86-11e8-9aa2-c6770944a2e6 container secret-volume-test: \u0026lt;nil\u0026gt; STEP: delete the pod Jul 3 06:02:11.999: INFO: Waiting for pod pod-secrets-9cfd5a21-7e86-11e8-9aa2-c6770944a2e6 to disappear Jul 3 06:02:12.003: INFO: Pod pod-secrets-9cfd5a21-7e86-11e8-9aa2-c6770944a2e6 no longer exists [AfterEach] [sig-storage] Secrets /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:02:12.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-secrets-27nw4\u0026quot; for this suite. Jul 3 06:02:18.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:02:18.135: INFO: namespace: e2e-tests-secrets-27nw4, resource: bindings, ignored listing per whitelist Jul 3 06:02:18.225: INFO: namespace e2e-tests-secrets-27nw4 deletion completed in 6.218371459s • [SLOW TEST:12.436 seconds] [sig-storage] namespace=\u0026quot;heptio-sonobuoy\u0026quot; pod=\u0026quot;sonobuoy-systemd-logs-daemon-set-1c53f31cf14246ca-mhztp\u0026quot; container=\u0026quot;sonobuoy-worker\u0026quot; time=\u0026quot;2018-07-03T06:01:52Z\u0026quot; level=info msg=\u0026quot;Waiting for waitfile\u0026quot; waitfile=/tmp/results/done time=\u0026quot;2018-07-03T06:01:53Z\u0026quot; level=info msg=\u0026quot;Detected done file, transmitting result file\u0026quot; resultFile=/tmp/results/systemd_logs namespace=\u0026quot;heptio-sonobuoy\u0026quot; pod=\u0026quot;sonobuoy-e2e-job-5fff584d11364ca1\u0026quot; container=\u0026quot;e2e\u0026quot; Secrets /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33 should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSSSSSSSSSSSSS ------------------------------ [k8s.io] Probing container should have monotonically increasing restart count [Slow][NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [k8s.io] Probing container /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:02:18.233: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [BeforeEach] [k8s.io] Probing container /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48 [It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-vwfbg Jul 3 06:02:24.338: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-vwfbg STEP: checking the pod's current state and verifying that restartCount is present Jul 3 06:02:24.342: INFO: Initial restart count of pod liveness-http is 0 Jul 3 06:02:42.390: INFO: Restart count of pod e2e-tests-container-probe-vwfbg/liveness-http is now 1 (18.04818225s elapsed) Jul 3 06:03:00.450: INFO: Restart count of pod e2e-tests-container-probe-vwfbg/liveness-http is now 2 (36.107665419s elapsed) Jul 3 06:03:20.540: INFO: Restart count of pod e2e-tests-container-probe-vwfbg/liveness-http is now 3 (56.197646321s elapsed) Jul 3 06:03:41.043: INFO: Restart count of pod e2e-tests-container-probe-vwfbg/liveness-http is now 4 (1m16.286139808s elapsed) Jul 3 06:04:51.429: INFO: Restart count of pod e2e-tests-container-probe-vwfbg/liveness-http is now 5 (2m26.671984101s elapsed) STEP: deleting the pod [AfterEach] [k8s.io] Probing container /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:04:51.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-container-probe-vwfbg\u0026quot; for this suite. Jul 3 06:04:57.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:04:57.689: INFO: namespace: e2e-tests-container-probe-vwfbg, resource: bindings, ignored listing per whitelist Jul 3 06:04:57.716: INFO: namespace e2e-tests-container-probe-vwfbg deletion completed in 6.21869089s • [SLOW TEST:159.069 seconds] [k8s.io] Probing container /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679 should have monotonically increasing restart count [Slow][NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSS ------------------------------ [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-storage] ConfigMap /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:04:57.716: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating configMap with name configmap-test-volume-map-03686ea1-7e87-11e8-9aa2-c6770944a2e6 STEP: Creating a pod to test consume configMaps Jul 3 06:04:57.775: INFO: Waiting up to 5m0s for pod \u0026quot;pod-configmaps-0368d2ec-7e87-11e8-9aa2-c6770944a2e6\u0026quot; in namespace \u0026quot;e2e-tests-configmap-5bcbx\u0026quot; to be \u0026quot;success or failure\u0026quot; Jul 3 06:04:57.780: INFO: Pod \u0026quot;pod-configmaps-0368d2ec-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 5.029515ms Jul 3 06:04:59.791: INFO: Pod \u0026quot;pod-configmaps-0368d2ec-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 2.015570127s Jul 3 06:05:01.796: INFO: Pod \u0026quot;pod-configmaps-0368d2ec-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Succeeded\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 4.020671875s STEP: Saw pod success Jul 3 06:05:01.796: INFO: Pod \u0026quot;pod-configmaps-0368d2ec-7e87-11e8-9aa2-c6770944a2e6\u0026quot; satisfied condition \u0026quot;success or failure\u0026quot; Jul 3 06:05:01.798: INFO: Trying to get logs from node ubuntuvm pod pod-configmaps-0368d2ec-7e87-11e8-9aa2-c6770944a2e6 container configmap-volume-test: \u0026lt;nil\u0026gt; STEP: delete the pod Jul 3 06:05:01.824: INFO: Waiting for pod pod-configmaps-0368d2ec-7e87-11e8-9aa2-c6770944a2e6 to disappear Jul 3 06:05:01.828: INFO: Pod pod-configmaps-0368d2ec-7e87-11e8-9aa2-c6770944a2e6 no longer exists [AfterEach] [sig-storage] ConfigMap /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:05:01.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-configmap-5bcbx\u0026quot; for this suite. Jul 3 06:05:07.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:05:07.942: INFO: namespace: e2e-tests-configmap-5bcbx, resource: bindings, ignored listing per whitelist Jul 3 06:05:07.965: INFO: namespace e2e-tests-configmap-5bcbx deletion completed in 6.134761009s • [SLOW TEST:10.249 seconds] [sig-storage] ConfigMap /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32 should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSSSSSS ------------------------------ [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be submitted and removed [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [k8s.io] [sig-node] Pods Extended /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:05:07.965: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [BeforeEach] [k8s.io] Pods Set QOS Class /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:199 [It] should be submitted and removed [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: creating the pod STEP: submitting the pod to kubernetes STEP: verifying QOS class is set on the pod [AfterEach] [k8s.io] [sig-node] Pods Extended /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:05:08.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-pods-fgrwq\u0026quot; for this suite. Jul 3 06:05:30.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:05:30.221: INFO: namespace: e2e-tests-pods-fgrwq, resource: bindings, ignored listing per whitelist Jul 3 06:05:30.286: INFO: namespace e2e-tests-pods-fgrwq deletion completed in 22.188767463s • [SLOW TEST:22.321 seconds] [k8s.io] [sig-node] Pods Extended /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679 [k8s.io] Pods Set QOS Class /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679 should be submitted and removed [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSSSSSSSS ------------------------------ [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-apps] Daemon set [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:05:30.286: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [BeforeEach] [sig-apps] Daemon set [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99 [It] should retry creating failed daemon pods [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating a simple DaemonSet \u0026quot;daemon-set\u0026quot; STEP: Check that daemon pods launch on every node of the cluster. Jul 3 06:05:30.421: INFO: Number of nodes with available pods: 0 Jul 3 06:05:30.421: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:05:31.736: INFO: Number of nodes with available pods: 0 Jul 3 06:05:31.736: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:05:32.438: INFO: Number of nodes with available pods: 0 Jul 3 06:05:32.438: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:05:33.468: INFO: Number of nodes with available pods: 0 Jul 3 06:05:33.468: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:05:34.432: INFO: Number of nodes with available pods: 0 Jul 3 06:05:34.432: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:05:35.429: INFO: Number of nodes with available pods: 0 Jul 3 06:05:35.429: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:05:36.434: INFO: Number of nodes with available pods: 0 Jul 3 06:05:36.434: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:05:37.450: INFO: Number of nodes with available pods: 0 Jul 3 06:05:37.450: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:05:38.428: INFO: Number of nodes with available pods: 0 Jul 3 06:05:38.428: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:05:39.444: INFO: Number of nodes with available pods: 1 Jul 3 06:05:39.444: INFO: Number of running nodes: 1, number of available pods: 1 STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. Jul 3 06:05:39.484: INFO: Number of nodes with available pods: 0 Jul 3 06:05:39.485: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:05:40.496: INFO: Number of nodes with available pods: 0 Jul 3 06:05:40.496: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:05:41.497: INFO: Number of nodes with available pods: 1 Jul 3 06:05:41.498: INFO: Number of running nodes: 1, number of available pods: 1 STEP: Wait for the failed daemon pod to be completely deleted. [AfterEach] [sig-apps] Daemon set [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65 STEP: Deleting DaemonSet \u0026quot;daemon-set\u0026quot; STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-tl4wf, will wait for the garbage collector to delete the pods Jul 3 06:05:41.590: INFO: Deleting {extensions DaemonSet} daemon-set took: 31.578878ms Jul 3 06:05:41.693: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 102.749663ms Jul 3 06:05:49.499: INFO: Number of nodes with available pods: 0 Jul 3 06:05:49.499: INFO: Number of running nodes: 0, number of available pods: 0 Jul 3 06:05:49.505: INFO: daemonset: {\u0026quot;kind\u0026quot;:\u0026quot;DaemonSetList\u0026quot;,\u0026quot;apiVersion\u0026quot;:\u0026quot;apps/v1\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;selfLink\u0026quot;:\u0026quot;/apis/apps/v1/namespaces/e2e-tests-daemonsets-tl4wf/daemonsets\u0026quot;,\u0026quot;resourceVersion\u0026quot;:\u0026quot;142028\u0026quot;},\u0026quot;items\u0026quot;:null} Jul 3 06:05:49.507: INFO: pods: {\u0026quot;kind\u0026quot;:\u0026quot;PodList\u0026quot;,\u0026quot;apiVersion\u0026quot;:\u0026quot;v1\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;selfLink\u0026quot;:\u0026quot;/api/v1/namespaces/e2e-tests-daemonsets-tl4wf/pods\u0026quot;,\u0026quot;resourceVersion\u0026quot;:\u0026quot;142028\u0026quot;},\u0026quot;items\u0026quot;:null} [AfterEach] [sig-apps] Daemon set [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:05:49.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-daemonsets-tl4wf\u0026quot; for this suite. Jul 3 06:05:55.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:05:55.576: INFO: namespace: e2e-tests-daemonsets-tl4wf, resource: bindings, ignored listing per whitelist Jul 3 06:05:55.647: INFO: namespace e2e-tests-daemonsets-tl4wf deletion completed in 6.132212024s • [SLOW TEST:25.362 seconds] [sig-apps] Daemon set [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22 should retry creating failed daemon pods [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSSSSS ------------------------------ [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-api-machinery] Watchers /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:05:55.648: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [It] should be able to start watching from a specific resource version [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: creating a new configmap STEP: modifying the configmap once STEP: modifying the configmap a second time STEP: deleting the configmap STEP: creating a watch on configmaps from the resource version returned by the first update STEP: Expecting to observe notifications for all changes to the configmap after the first update Jul 3 06:05:55.725: INFO: Got : MODIFIED \u0026amp;ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-975cf,SelfLink:/api/v1/namespaces/e2e-tests-watch-975cf/configmaps/e2e-watch-test-resource-version,UID:25f18e8f-7e87-11e8-afec-0800272e6982,ResourceVersion:142061,Generation:0,CreationTimestamp:2018-07-03 06:05:55 +0000 UTC,DeletionTimestamp:\u0026lt;nil\u0026gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},} Jul 3 06:05:55.725: INFO: Got : DELETED \u0026amp;ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-975cf,SelfLink:/api/v1/namespaces/e2e-tests-watch-975cf/configmaps/e2e-watch-test-resource-version,UID:25f18e8f-7e87-11e8-afec-0800272e6982,ResourceVersion:142062,Generation:0,CreationTimestamp:2018-07-03 06:05:55 +0000 UTC,DeletionTimestamp:\u0026lt;nil\u0026gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},} [AfterEach] [sig-api-machinery] Watchers /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:05:55.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-watch-975cf\u0026quot; for this suite. Jul 3 06:06:01.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:06:01.845: INFO: namespace: e2e-tests-watch-975cf, resource: bindings, ignored listing per whitelist Jul 3 06:06:01.897: INFO: namespace e2e-tests-watch-975cf deletion completed in 6.169150968s • [SLOW TEST:6.250 seconds] [sig-api-machinery] Watchers /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22 should be able to start watching from a specific resource version [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSSSSSSSSSSSSS ------------------------------ [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-network] Networking /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:06:01.898: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [It] should function for node-pod communication: udp [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-gsz2s STEP: creating a selector STEP: Creating the service pods in kubernetes Jul 3 06:06:01.970: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable STEP: Creating test pods Jul 3 06:06:32.080: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.196.147 8081 | grep -v '^\\s*$'] Namespace:e2e-tests-pod-network-test-gsz2s PodName:host-test-container-pod ContainerName:hostexec Stdin:\u0026lt;nil\u0026gt; CaptureStdout:true CaptureStderr:true PreserveWhitespace:false} Jul 3 06:06:32.080: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 Jul 3 06:06:33.341: INFO: Found all expected endpoints: [netserver-0] [AfterEach] [sig-network] Networking /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:06:33.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-pod-network-test-gsz2s\u0026quot; for this suite. Jul 3 06:06:57.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:06:57.453: INFO: namespace: e2e-tests-pod-network-test-gsz2s, resource: bindings, ignored listing per whitelist Jul 3 06:06:57.569: INFO: namespace e2e-tests-pod-network-test-gsz2s deletion completed in 24.222268521s • [SLOW TEST:55.671 seconds] [sig-network] Networking /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25 Granular Checks: Pods /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28 should function for node-pod communication: udp [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSS ------------------------------ [sig-network] Services should serve multiport endpoints from pods [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-network] Services /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:06:57.569: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [BeforeEach] [sig-network] Services /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83 [It] should serve multiport endpoints from pods [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: creating service multi-endpoint-test in namespace e2e-tests-services-ndg9v STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ndg9v to expose endpoints map[] Jul 3 06:06:57.684: INFO: Get endpoints failed (9.21395ms elapsed, ignoring for 5s): endpoints \u0026quot;multi-endpoint-test\u0026quot; not found Jul 3 06:06:58.688: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ndg9v exposes endpoints map[] (1.01352677s elapsed) STEP: Creating pod pod1 in namespace e2e-tests-services-ndg9v STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ndg9v to expose endpoints map[pod1:[100]] Jul 3 06:07:01.824: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ndg9v exposes endpoints map[pod1:[100]] (3.12548547s elapsed) STEP: Creating pod pod2 in namespace e2e-tests-services-ndg9v STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ndg9v to expose endpoints map[pod2:[101] pod1:[100]] Jul 3 06:07:04.994: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ndg9v exposes endpoints map[pod1:[100] pod2:[101]] (3.156212674s elapsed) STEP: Deleting pod pod1 in namespace e2e-tests-services-ndg9v STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ndg9v to expose endpoints map[pod2:[101]] Jul 3 06:07:06.045: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ndg9v exposes endpoints map[pod2:[101]] (1.037349952s elapsed) STEP: Deleting pod pod2 in namespace e2e-tests-services-ndg9v STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ndg9v to expose endpoints map[] Jul 3 06:07:06.073: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ndg9v exposes endpoints map[] (8.460255ms elapsed) [AfterEach] [sig-network] Services /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:07:06.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-services-ndg9v\u0026quot; for this suite. Jul 3 06:07:28.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:07:28.268: INFO: namespace: e2e-tests-services-ndg9v, resource: bindings, ignored listing per whitelist Jul 3 06:07:28.280: INFO: namespace e2e-tests-services-ndg9v deletion completed in 22.170933437s [AfterEach] [sig-network] Services /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88 • [SLOW TEST:30.711 seconds] [sig-network] Services /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22 should serve multiport endpoints from pods [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ [sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] version v1 /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:07:28.280: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [It] should proxy through a service and a pod [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: starting an echo server on multiple ports STEP: creating replication controller proxy-service-24n8l in namespace e2e-tests-proxy-2d6tn I0703 06:07:28.400922 17 runners.go:177] Created replication controller with name: proxy-service-24n8l, namespace: e2e-tests-proxy-2d6tn, replica count: 1 I0703 06:07:29.458438 17 runners.go:177] proxy-service-24n8l Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady I0703 06:07:30.458708 17 runners.go:177] proxy-service-24n8l Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady I0703 06:07:31.459561 17 runners.go:177] proxy-service-24n8l Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady I0703 06:07:32.462091 17 runners.go:177] proxy-service-24n8l Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady I0703 06:07:33.462439 17 runners.go:177] proxy-service-24n8l Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady I0703 06:07:34.463500 17 runners.go:177] proxy-service-24n8l Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady I0703 06:07:35.464181 17 runners.go:177] proxy-service-24n8l Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady I0703 06:07:36.464839 17 runners.go:177] proxy-service-24n8l Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady I0703 06:07:37.467414 17 runners.go:177] proxy-service-24n8l Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady I0703 06:07:38.468453 17 runners.go:177] proxy-service-24n8l Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady I0703 06:07:39.469525 17 runners.go:177] proxy-service-24n8l Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady Jul 3 06:07:39.480: INFO: setup took 11.110959762s, starting test cases STEP: running 16 cases, 20 attempts per case, 320 total attempts Jul 3 06:07:39.505: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 22.984351ms) Jul 3 06:07:39.506: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 23.941675ms) Jul 3 06:07:39.507: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 24.686163ms) Jul 3 06:07:39.508: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 25.541054ms) Jul 3 06:07:39.508: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 26.104103ms) Jul 3 06:07:39.508: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 25.809024ms) Jul 3 06:07:39.510: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 27.843628ms) Jul 3 06:07:39.514: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 31.815332ms) Jul 3 06:07:39.514: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 32.024406ms) Jul 3 06:07:39.522: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 40.252476ms) Jul 3 06:07:39.526: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 43.116815ms) Jul 3 06:07:39.526: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 44.071781ms) Jul 3 06:07:39.530: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 48.139042ms) Jul 3 06:07:39.531: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 49.398749ms) Jul 3 06:07:39.533: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 51.469648ms) Jul 3 06:07:39.536: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 53.40901ms) Jul 3 06:07:39.540: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 4.093323ms) Jul 3 06:07:39.546: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 9.210369ms) Jul 3 06:07:39.546: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 9.713037ms) Jul 3 06:07:39.547: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 9.718204ms) Jul 3 06:07:39.547: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 10.382863ms) Jul 3 06:07:39.553: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 16.479995ms) Jul 3 06:07:39.554: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 16.889733ms) Jul 3 06:07:39.554: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 16.893044ms) Jul 3 06:07:39.554: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 16.943884ms) Jul 3 06:07:39.558: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 21.311901ms) Jul 3 06:07:39.558: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 21.148017ms) Jul 3 06:07:39.558: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 21.105103ms) Jul 3 06:07:39.558: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 21.174644ms) Jul 3 06:07:39.559: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 21.825229ms) Jul 3 06:07:39.559: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 22.406455ms) Jul 3 06:07:39.560: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 23.590981ms) Jul 3 06:07:39.573: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 12.636295ms) Jul 3 06:07:39.573: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 12.124205ms) Jul 3 06:07:39.574: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 12.93577ms) Jul 3 06:07:39.574: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 13.271759ms) Jul 3 06:07:39.576: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 15.487461ms) Jul 3 06:07:39.576: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 15.203026ms) Jul 3 06:07:39.577: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 15.620689ms) Jul 3 06:07:39.578: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 16.58259ms) Jul 3 06:07:39.578: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 16.64646ms) Jul 3 06:07:39.578: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 16.788563ms) Jul 3 06:07:39.578: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 16.926443ms) Jul 3 06:07:39.578: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 16.935266ms) Jul 3 06:07:39.578: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 16.806309ms) Jul 3 06:07:39.578: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 16.770624ms) Jul 3 06:07:39.579: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 17.369824ms) Jul 3 06:07:39.579: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 17.84942ms) Jul 3 06:07:39.588: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 9.387169ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 9.749045ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 9.636944ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 9.560885ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 9.555833ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 9.908539ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 9.861313ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 9.806847ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 9.741395ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 10.0292ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 9.918786ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 9.754599ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 9.915328ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 9.816536ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 9.924633ms) Jul 3 06:07:39.589: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 9.837021ms) Jul 3 06:07:39.596: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 6.820563ms) Jul 3 06:07:39.596: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 7.183957ms) Jul 3 06:07:39.597: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 8.189952ms) Jul 3 06:07:39.597: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 7.875646ms) Jul 3 06:07:39.597: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 7.926349ms) Jul 3 06:07:39.597: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 8.070557ms) Jul 3 06:07:39.597: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 7.944024ms) Jul 3 06:07:39.597: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 8.26913ms) Jul 3 06:07:39.598: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 8.600459ms) Jul 3 06:07:39.598: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 8.958053ms) Jul 3 06:07:39.601: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 12.289458ms) Jul 3 06:07:39.602: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 12.520927ms) Jul 3 06:07:39.603: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 13.80259ms) Jul 3 06:07:39.603: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 13.938307ms) Jul 3 06:07:39.603: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 13.798029ms) Jul 3 06:07:39.603: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 14.035034ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 8.461128ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 8.598935ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 8.474331ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 8.53614ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 8.883358ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 8.784084ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 8.655623ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 8.55204ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 8.967046ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 8.628987ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 8.675398ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 8.737646ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 8.715562ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 8.658073ms) Jul 3 06:07:39.612: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 8.684735ms) Jul 3 06:07:39.615: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 11.408713ms) Jul 3 06:07:39.622: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 6.303757ms) Jul 3 06:07:39.622: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 6.231001ms) Jul 3 06:07:39.622: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 6.215339ms) Jul 3 06:07:39.622: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 6.256391ms) Jul 3 06:07:39.622: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 6.255782ms) Jul 3 06:07:39.622: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 6.331148ms) Jul 3 06:07:39.622: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 6.244161ms) Jul 3 06:07:39.623: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 6.875476ms) Jul 3 06:07:39.623: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 7.871699ms) Jul 3 06:07:39.623: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 7.501482ms) Jul 3 06:07:39.624: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 8.340597ms) Jul 3 06:07:39.626: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 9.737824ms) Jul 3 06:07:39.626: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 10.23094ms) Jul 3 06:07:39.627: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 11.440538ms) Jul 3 06:07:39.628: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 12.671053ms) Jul 3 06:07:39.628: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 12.640137ms) Jul 3 06:07:39.634: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 5.355297ms) Jul 3 06:07:39.634: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 5.14686ms) Jul 3 06:07:39.634: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 5.532388ms) Jul 3 06:07:39.635: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 5.666625ms) Jul 3 06:07:39.635: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 6.029568ms) Jul 3 06:07:39.635: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 5.795261ms) Jul 3 06:07:39.635: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 5.675582ms) Jul 3 06:07:39.637: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 7.198059ms) Jul 3 06:07:39.637: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 8.775757ms) Jul 3 06:07:39.639: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 9.026406ms) Jul 3 06:07:39.639: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 10.491945ms) Jul 3 06:07:39.640: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 10.257608ms) Jul 3 06:07:39.640: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 11.047619ms) Jul 3 06:07:39.640: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 11.081534ms) Jul 3 06:07:39.641: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 11.6419ms) Jul 3 06:07:39.641: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 11.542745ms) Jul 3 06:07:39.649: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 6.703966ms) Jul 3 06:07:39.651: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 8.75293ms) Jul 3 06:07:39.651: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 8.6867ms) Jul 3 06:07:39.651: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 8.909901ms) Jul 3 06:07:39.651: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 8.675271ms) Jul 3 06:07:39.652: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 9.681117ms) Jul 3 06:07:39.652: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 9.795024ms) Jul 3 06:07:39.653: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 10.724903ms) Jul 3 06:07:39.654: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 11.100304ms) Jul 3 06:07:39.655: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 13.017776ms) Jul 3 06:07:39.655: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 12.075244ms) Jul 3 06:07:39.655: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 13.178331ms) Jul 3 06:07:39.655: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 12.246035ms) Jul 3 06:07:39.655: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 12.706858ms) Jul 3 06:07:39.655: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 12.642589ms) Jul 3 06:07:39.656: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 14.20149ms) Jul 3 06:07:39.665: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 8.341409ms) Jul 3 06:07:39.665: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 7.82984ms) Jul 3 06:07:39.668: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 11.113905ms) Jul 3 06:07:39.669: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 11.8164ms) Jul 3 06:07:39.669: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 11.993539ms) Jul 3 06:07:39.669: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 12.063037ms) Jul 3 06:07:39.669: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 11.62943ms) Jul 3 06:07:39.669: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 11.994793ms) Jul 3 06:07:39.670: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 13.021585ms) Jul 3 06:07:39.670: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 12.795193ms) Jul 3 06:07:39.670: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 12.90527ms) Jul 3 06:07:39.670: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 13.401155ms) Jul 3 06:07:39.671: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 13.758112ms) Jul 3 06:07:39.672: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 14.68876ms) Jul 3 06:07:39.672: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 14.707223ms) Jul 3 06:07:39.672: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 14.719786ms) Jul 3 06:07:39.680: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 7.570336ms) Jul 3 06:07:39.680: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 7.626954ms) Jul 3 06:07:39.680: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 8.072456ms) Jul 3 06:07:39.681: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 8.276817ms) Jul 3 06:07:39.681: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 8.69902ms) Jul 3 06:07:39.682: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 9.244248ms) Jul 3 06:07:39.682: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 9.578596ms) Jul 3 06:07:39.683: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 10.467993ms) Jul 3 06:07:39.682: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 9.630068ms) Jul 3 06:07:39.682: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 9.655504ms) Jul 3 06:07:39.682: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 9.639837ms) Jul 3 06:07:39.682: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 9.798602ms) Jul 3 06:07:39.682: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 10.221717ms) Jul 3 06:07:39.683: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 10.912476ms) Jul 3 06:07:39.685: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 12.368545ms) Jul 3 06:07:39.686: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 13.706676ms) Jul 3 06:07:39.690: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 3.70745ms) Jul 3 06:07:39.690: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 3.701704ms) Jul 3 06:07:39.691: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 3.83924ms) Jul 3 06:07:39.695: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 7.9486ms) Jul 3 06:07:39.695: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 8.292899ms) Jul 3 06:07:39.695: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 8.22671ms) Jul 3 06:07:39.695: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 8.145833ms) Jul 3 06:07:39.697: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 9.445816ms) Jul 3 06:07:39.697: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 9.513803ms) Jul 3 06:07:39.697: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 9.608955ms) Jul 3 06:07:39.697: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 9.564723ms) Jul 3 06:07:39.698: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 11.345681ms) Jul 3 06:07:39.698: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 11.329885ms) Jul 3 06:07:39.698: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 11.28516ms) Jul 3 06:07:39.699: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 11.862803ms) Jul 3 06:07:39.700: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 12.641143ms) Jul 3 06:07:39.705: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 5.328836ms) Jul 3 06:07:39.705: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 5.512445ms) Jul 3 06:07:39.705: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 5.466995ms) Jul 3 06:07:39.705: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 5.65714ms) Jul 3 06:07:39.706: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 5.743735ms) Jul 3 06:07:39.706: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 5.82226ms) Jul 3 06:07:39.710: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 10.434795ms) Jul 3 06:07:39.711: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 10.698721ms) Jul 3 06:07:39.711: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 11.01204ms) Jul 3 06:07:39.711: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 10.767322ms) Jul 3 06:07:39.711: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 11.191239ms) Jul 3 06:07:39.711: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 11.547994ms) Jul 3 06:07:39.712: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 11.803176ms) Jul 3 06:07:39.713: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 13.341002ms) Jul 3 06:07:39.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 13.620961ms) Jul 3 06:07:39.714: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 14.058587ms) Jul 3 06:07:39.721: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 6.424664ms) Jul 3 06:07:39.721: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 6.732971ms) Jul 3 06:07:39.721: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 6.528326ms) Jul 3 06:07:39.724: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 10.162831ms) Jul 3 06:07:39.725: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 10.199442ms) Jul 3 06:07:39.725: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 10.184131ms) Jul 3 06:07:39.725: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 10.113374ms) Jul 3 06:07:39.725: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 10.311161ms) Jul 3 06:07:39.725: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 10.212956ms) Jul 3 06:07:39.725: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 10.170489ms) Jul 3 06:07:39.725: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 10.218579ms) Jul 3 06:07:39.725: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 10.234843ms) Jul 3 06:07:39.725: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 10.350547ms) Jul 3 06:07:39.725: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 10.310824ms) Jul 3 06:07:39.725: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 10.418044ms) Jul 3 06:07:39.725: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 10.558637ms) Jul 3 06:07:39.731: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 5.861544ms) Jul 3 06:07:39.731: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 6.24859ms) Jul 3 06:07:39.731: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 6.145305ms) Jul 3 06:07:39.731: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 6.30522ms) Jul 3 06:07:39.735: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 9.548633ms) Jul 3 06:07:39.735: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 9.725206ms) Jul 3 06:07:39.735: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 9.695757ms) Jul 3 06:07:39.735: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 9.592566ms) Jul 3 06:07:39.735: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 9.739772ms) Jul 3 06:07:39.735: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 9.605244ms) Jul 3 06:07:39.735: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 9.644933ms) Jul 3 06:07:39.735: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 9.790708ms) Jul 3 06:07:39.735: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 9.603307ms) Jul 3 06:07:39.735: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 9.581454ms) Jul 3 06:07:39.735: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 9.640984ms) Jul 3 06:07:39.735: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 9.779968ms) Jul 3 06:07:39.742: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 6.455086ms) Jul 3 06:07:39.742: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 6.782064ms) Jul 3 06:07:39.742: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 6.747632ms) Jul 3 06:07:39.746: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 10.785384ms) Jul 3 06:07:39.746: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 10.93803ms) Jul 3 06:07:39.748: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 12.250607ms) Jul 3 06:07:39.748: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 12.166366ms) Jul 3 06:07:39.748: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 12.247814ms) Jul 3 06:07:39.748: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 12.110371ms) Jul 3 06:07:39.748: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 12.327679ms) Jul 3 06:07:39.746: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 11.036002ms) Jul 3 06:07:39.747: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 11.662474ms) Jul 3 06:07:39.747: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 11.277015ms) Jul 3 06:07:39.748: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 12.998036ms) Jul 3 06:07:39.749: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 13.208001ms) Jul 3 06:07:39.749: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 13.737721ms) Jul 3 06:07:39.754: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 4.358522ms) Jul 3 06:07:39.756: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 6.104772ms) Jul 3 06:07:39.756: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 6.422685ms) Jul 3 06:07:39.758: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 7.919086ms) Jul 3 06:07:39.758: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 7.634486ms) Jul 3 06:07:39.758: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 7.990733ms) Jul 3 06:07:39.759: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 8.268858ms) Jul 3 06:07:39.759: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 9.35517ms) Jul 3 06:07:39.759: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 8.830292ms) Jul 3 06:07:39.760: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 9.816839ms) Jul 3 06:07:39.760: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 9.810505ms) Jul 3 06:07:39.760: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 10.193995ms) Jul 3 06:07:39.760: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 9.776765ms) Jul 3 06:07:39.762: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 10.961793ms) Jul 3 06:07:39.762: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 11.54841ms) Jul 3 06:07:39.763: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 12.641653ms) Jul 3 06:07:39.768: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 4.299456ms) Jul 3 06:07:39.768: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 4.739242ms) Jul 3 06:07:39.769: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 5.472944ms) Jul 3 06:07:39.772: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 8.407085ms) Jul 3 06:07:39.772: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 8.519286ms) Jul 3 06:07:39.772: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 8.534537ms) Jul 3 06:07:39.772: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 8.113633ms) Jul 3 06:07:39.772: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 8.43944ms) Jul 3 06:07:39.772: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 8.222509ms) Jul 3 06:07:39.773: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 9.509357ms) Jul 3 06:07:39.775: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 11.17629ms) Jul 3 06:07:39.775: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 11.463021ms) Jul 3 06:07:39.776: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 11.811409ms) Jul 3 06:07:39.776: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 12.431881ms) Jul 3 06:07:39.776: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 12.664851ms) Jul 3 06:07:39.778: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 13.881855ms) Jul 3 06:07:39.785: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 6.595958ms) Jul 3 06:07:39.785: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 6.626811ms) Jul 3 06:07:39.785: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 6.936054ms) Jul 3 06:07:39.785: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 6.663949ms) Jul 3 06:07:39.785: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 6.88998ms) Jul 3 06:07:39.785: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 6.722557ms) Jul 3 06:07:39.786: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 7.331539ms) Jul 3 06:07:39.788: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 9.9549ms) Jul 3 06:07:39.788: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 10.735268ms) Jul 3 06:07:39.789: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 9.872255ms) Jul 3 06:07:39.789: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 10.530949ms) Jul 3 06:07:39.790: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 11.578224ms) Jul 3 06:07:39.791: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 12.322089ms) Jul 3 06:07:39.792: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 13.214314ms) Jul 3 06:07:39.792: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 13.466455ms) Jul 3 06:07:39.793: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 14.087847ms) Jul 3 06:07:39.802: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 8.516847ms) Jul 3 06:07:39.802: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:443/proxy/... (200; 7.986127ms) Jul 3 06:07:39.802: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 8.050382ms) Jul 3 06:07:39.802: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:462/proxy/: tls qux (200; 8.296865ms) Jul 3 06:07:39.802: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:1080/proxy/rewri... (200; 8.457665ms) Jul 3 06:07:39.802: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:160/proxy/: foo (200; 8.847864ms) Jul 3 06:07:39.802: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/http:proxy-service-24n8l-qqhrc:1080/proxy/... (200; 8.533851ms) Jul 3 06:07:39.803: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname1/proxy/: tls baz (200; 8.482214ms) Jul 3 06:07:39.803: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname2/proxy/: bar (200; 8.778312ms) Jul 3 06:07:39.803: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/https:proxy-service-24n8l-qqhrc:460/proxy/: tls baz (200; 8.967689ms) Jul 3 06:07:39.803: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc:162/proxy/: bar (200; 8.669839ms) Jul 3 06:07:39.803: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/: \u0026lt;a href=\u0026quot;/api/v1/namespaces/e2e-tests-proxy-2d6tn/pods/proxy-service-24n8l-qqhrc/proxy/rewriteme\u0026quot;... (200; 9.392164ms) Jul 3 06:07:39.803: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname1/proxy/: foo (200; 9.888833ms) Jul 3 06:07:39.803: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/proxy-service-24n8l:portname2/proxy/: bar (200; 9.632785ms) Jul 3 06:07:39.804: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/http:proxy-service-24n8l:portname1/proxy/: foo (200; 10.481342ms) Jul 3 06:07:39.806: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-2d6tn/services/https:proxy-service-24n8l:tlsportname2/proxy/: tls qux (200; 11.660339ms) STEP: deleting { ReplicationController} proxy-service-24n8l in namespace e2e-tests-proxy-2d6tn, will wait for the garbage collector to delete the pods Jul 3 06:07:39.885: INFO: Deleting { ReplicationController} proxy-service-24n8l took: 24.687435ms Jul 3 06:07:39.986: INFO: Terminating { ReplicationController} proxy-service-24n8l pods took: 101.657967ms [AfterEach] version v1 /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:07:49.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-proxy-2d6tn\u0026quot; for this suite. Jul 3 06:07:55.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:07:55.580: INFO: namespace: e2e-tests-proxy-2d6tn, resource: bindings, ignored listing per whitelist Jul 3 06:07:55.644: INFO: namespace e2e-tests-proxy-2d6tn deletion completed in 6.149415761s • [SLOW TEST:27.364 seconds] [sig-network] Proxy /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22 version v1 /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56 should proxy through a service and a pod [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ [sig-storage] Projected should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-storage] Projected /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:07:55.647: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [BeforeEach] [sig-storage] Projected /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858 [It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating projection with secret that has name projected-secret-test-map-6d7ebdb8-7e87-11e8-9aa2-c6770944a2e6 STEP: Creating a pod to test consume secrets Jul 3 06:07:55.763: INFO: Waiting up to 5m0s for pod \u0026quot;pod-projected-secrets-6d7f63bd-7e87-11e8-9aa2-c6770944a2e6\u0026quot; in namespace \u0026quot;e2e-tests-projected-k8m2l\u0026quot; to be \u0026quot;success or failure\u0026quot; Jul 3 06:07:55.778: INFO: Pod \u0026quot;pod-projected-secrets-6d7f63bd-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 15.231796ms Jul 3 06:07:57.786: INFO: Pod \u0026quot;pod-projected-secrets-6d7f63bd-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 2.02288338s Jul 3 06:07:59.790: INFO: Pod \u0026quot;pod-projected-secrets-6d7f63bd-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Succeeded\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 4.026687063s STEP: Saw pod success Jul 3 06:07:59.790: INFO: Pod \u0026quot;pod-projected-secrets-6d7f63bd-7e87-11e8-9aa2-c6770944a2e6\u0026quot; satisfied condition \u0026quot;success or failure\u0026quot; Jul 3 06:07:59.792: INFO: Trying to get logs from node ubuntuvm pod pod-projected-secrets-6d7f63bd-7e87-11e8-9aa2-c6770944a2e6 container projected-secret-volume-test: \u0026lt;nil\u0026gt; STEP: delete the pod Jul 3 06:07:59.813: INFO: Waiting for pod pod-projected-secrets-6d7f63bd-7e87-11e8-9aa2-c6770944a2e6 to disappear Jul 3 06:07:59.814: INFO: Pod pod-projected-secrets-6d7f63bd-7e87-11e8-9aa2-c6770944a2e6 no longer exists [AfterEach] [sig-storage] Projected /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:07:59.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-projected-k8m2l\u0026quot; for this suite. Jul 3 06:08:05.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:08:05.925: INFO: namespace: e2e-tests-projected-k8m2l, resource: bindings, ignored listing per whitelist Jul 3 06:08:05.991: INFO: namespace e2e-tests-projected-k8m2l deletion completed in 6.175208514s • [SLOW TEST:10.345 seconds] [sig-storage] Projected /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34 should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSSSSSSS ------------------------------ [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-api-machinery] Garbage collector /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:08:05.996: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: create the rc1 STEP: create the rc2 STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well STEP: delete the rc simpletest-rc-to-be-deleted STEP: wait for the rc to be deleted STEP: Gathering metrics W0703 06:08:16.225194 17 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled. Jul 3 06:08:16.225: INFO: For apiserver_request_count: For apiserver_request_latencies_summary: For etcd_helper_cache_entry_count: For etcd_helper_cache_hit_count: For etcd_helper_cache_miss_count: For etcd_request_cache_add_latencies_summary: For etcd_request_cache_get_latencies_summary: For etcd_request_latencies_summary: For garbage_collector_attempt_to_delete_queue_latency: For garbage_collector_attempt_to_delete_work_duration: For garbage_collector_attempt_to_orphan_queue_latency: For garbage_collector_attempt_to_orphan_work_duration: For garbage_collector_dirty_processing_latency_microseconds: For garbage_collector_event_processing_latency_microseconds: For garbage_collector_graph_changes_queue_latency: For garbage_collector_graph_changes_work_duration: For garbage_collector_orphan_processing_latency_microseconds: For namespace_queue_latency: For namespace_queue_latency_sum: For namespace_queue_latency_count: For namespace_retries: For namespace_work_duration: For namespace_work_duration_sum: For namespace_work_duration_count: For function_duration_seconds: For errors_total: For evicted_pods_total: [AfterEach] [sig-api-machinery] Garbage collector /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:08:16.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-gc-x2qjc\u0026quot; for this suite. Jul 3 06:08:22.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:08:22.361: INFO: namespace: e2e-tests-gc-x2qjc, resource: bindings, ignored listing per whitelist Jul 3 06:08:22.433: INFO: namespace e2e-tests-gc-x2qjc deletion completed in 6.18451645s • [SLOW TEST:16.437 seconds] [sig-api-machinery] Garbage collector /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22 should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ S ------------------------------ [sig-network] Proxy version v1 should proxy logs on node using proxy subresource [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] version v1 /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:08:22.433: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [It] should proxy logs on node using proxy subresource [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 Jul 3 06:08:22.521: INFO: (0) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 6.888637ms) Jul 3 06:08:22.526: INFO: (1) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 4.483475ms) Jul 3 06:08:22.530: INFO: (2) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 4.032924ms) Jul 3 06:08:22.535: INFO: (3) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 4.970921ms) Jul 3 06:08:22.542: INFO: (4) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 6.702057ms) Jul 3 06:08:22.547: INFO: (5) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 4.620394ms) Jul 3 06:08:22.564: INFO: (6) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 17.443485ms) Jul 3 06:08:22.576: INFO: (7) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 9.188638ms) Jul 3 06:08:22.593: INFO: (8) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 17.254712ms) Jul 3 06:08:22.599: INFO: (9) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 5.990922ms) Jul 3 06:08:22.609: INFO: (10) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 9.945971ms) Jul 3 06:08:22.618: INFO: (11) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 6.843684ms) Jul 3 06:08:22.627: INFO: (12) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 8.030184ms) Jul 3 06:08:22.654: INFO: (13) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 27.455682ms) Jul 3 06:08:22.661: INFO: (14) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 6.839686ms) Jul 3 06:08:22.670: INFO: (15) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 8.531996ms) Jul 3 06:08:22.675: INFO: (16) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 5.599557ms) Jul 3 06:08:22.685: INFO: (17) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 10.221834ms) Jul 3 06:08:22.710: INFO: (18) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 20.052405ms) Jul 3 06:08:22.716: INFO: (19) /api/v1/nodes/ubuntuvm/proxy/logs/: \u0026lt;pre\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log\u0026quot;\u0026gt;Xorg.0.log\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;Xorg.0.log.old\u0026quot;\u0026gt;Xorg.0.log.old\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;al... (200; 5.632301ms) [AfterEach] version v1 /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:08:22.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-proxy-62wvl\u0026quot; for this suite. Jul 3 06:08:28.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:08:28.795: INFO: namespace: e2e-tests-proxy-62wvl, resource: bindings, ignored listing per whitelist Jul 3 06:08:28.850: INFO: namespace e2e-tests-proxy-62wvl deletion completed in 6.127164652s • [SLOW TEST:6.417 seconds] [sig-network] Proxy /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22 version v1 /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56 should proxy logs on node using proxy subresource [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSSSSSS ------------------------------ [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-storage] EmptyDir volumes /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:08:28.851: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [It] volume on default medium should have the correct mode [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating a pod to test emptydir volume type on node default medium Jul 3 06:08:28.932: INFO: Waiting up to 5m0s for pod \u0026quot;pod-81443822-7e87-11e8-9aa2-c6770944a2e6\u0026quot; in namespace \u0026quot;e2e-tests-emptydir-2qs2r\u0026quot; to be \u0026quot;success or failure\u0026quot; Jul 3 06:08:28.947: INFO: Pod \u0026quot;pod-81443822-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 15.043415ms Jul 3 06:08:30.957: INFO: Pod \u0026quot;pod-81443822-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 2.02443708s Jul 3 06:08:32.988: INFO: Pod \u0026quot;pod-81443822-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Succeeded\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 4.056026943s STEP: Saw pod success Jul 3 06:08:32.988: INFO: Pod \u0026quot;pod-81443822-7e87-11e8-9aa2-c6770944a2e6\u0026quot; satisfied condition \u0026quot;success or failure\u0026quot; Jul 3 06:08:32.994: INFO: Trying to get logs from node ubuntuvm pod pod-81443822-7e87-11e8-9aa2-c6770944a2e6 container test-container: \u0026lt;nil\u0026gt; STEP: delete the pod Jul 3 06:08:33.067: INFO: Waiting for pod pod-81443822-7e87-11e8-9aa2-c6770944a2e6 to disappear Jul 3 06:08:33.103: INFO: Pod pod-81443822-7e87-11e8-9aa2-c6770944a2e6 no longer exists [AfterEach] [sig-storage] EmptyDir volumes /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:08:33.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-emptydir-2qs2r\u0026quot; for this suite. Jul 3 06:08:39.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:08:39.311: INFO: namespace: e2e-tests-emptydir-2qs2r, resource: bindings, ignored listing per whitelist Jul 3 06:08:39.351: INFO: namespace e2e-tests-emptydir-2qs2r deletion completed in 6.242001093s • [SLOW TEST:10.500 seconds] [sig-storage] EmptyDir volumes /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40 volume on default medium should have the correct mode [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ S ------------------------------ [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:08:39.351: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79 Jul 3 06:08:39.469: INFO: Waiting up to 1m0s for all nodes to be ready Jul 3 06:09:39.502: INFO: Waiting for terminating namespaces to be deleted... Jul 3 06:09:39.511: INFO: Waiting up to 5m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready Jul 3 06:09:39.525: INFO: 11 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed) Jul 3 06:09:39.525: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready. Jul 3 06:09:39.530: INFO: Waiting for pods to enter Success, but no pods in \u0026quot;kube-system\u0026quot; match label map[name:e2e-image-puller] Jul 3 06:09:39.530: INFO: Logging pods the kubelet thinks is on node ubuntuvm before test Jul 3 06:09:39.556: INFO: calico-node-8j695 from kube-system started at 2018-06-30 19:28:15 +0000 UTC (2 container statuses recorded) Jul 3 06:09:39.556: INFO: Container calico-node ready: true, restart count 5 Jul 3 06:09:39.556: INFO: Container install-cni ready: true, restart count 4 Jul 3 06:09:39.557: INFO: calico-kube-controllers-84fd4db7cd-m6hld from kube-system started at 2018-06-30 19:29:23 +0000 UTC (1 container statuses recorded) Jul 3 06:09:39.557: INFO: Container calico-kube-controllers ready: true, restart count 4 Jul 3 06:09:39.557: INFO: coredns-78fcdf6894-85qtr from kube-system started at 2018-06-30 19:29:23 +0000 UTC (1 container statuses recorded) Jul 3 06:09:39.557: INFO: Container coredns ready: true, restart count 4 Jul 3 06:09:39.557: INFO: tiller-deploy-759cb9df9-cdqkj from kube-system started at 2018-06-30 19:47:09 +0000 UTC (1 container statuses recorded) Jul 3 06:09:39.557: INFO: Container tiller ready: true, restart count 4 Jul 3 06:09:39.557: INFO: virtuous-quail-kubeplay-679d96fd55-cjhbx from default started at 2018-06-30 20:16:04 +0000 UTC (1 container statuses recorded) Jul 3 06:09:39.557: INFO: Container kubeplay ready: true, restart count 4 Jul 3 06:09:39.557: INFO: sonobuoy-e2e-job-5fff584d11364ca1 from heptio-sonobuoy started at 2018-07-03 06:00:23 +0000 UTC (2 container statuses recorded) Jul 3 06:09:39.557: INFO: Container e2e ready: true, restart count 0 Jul 3 06:09:39.558: INFO: Container sonobuoy-worker ready: true, restart count 0 Jul 3 06:09:39.558: INFO: kube-apiserver-ubuntuvm from kube-system started at \u0026lt;nil\u0026gt; (0 container statuses recorded) Jul 3 06:09:39.558: INFO: coredns-78fcdf6894-4qwq6 from kube-system started at 2018-06-30 19:29:23 +0000 UTC (1 container statuses recorded) Jul 3 06:09:39.558: INFO: Container coredns ready: true, restart count 4 Jul 3 06:09:39.558: INFO: kube-proxy-mjsc2 from kube-system started at 2018-06-30 19:26:56 +0000 UTC (1 container statuses recorded) Jul 3 06:09:39.558: INFO: Container kube-proxy ready: true, restart count 4 Jul 3 06:09:39.558: INFO: calico-etcd-gctks from kube-system started at 2018-06-30 19:28:14 +0000 UTC (1 container statuses recorded) Jul 3 06:09:39.558: INFO: Container calico-etcd ready: true, restart count 4 Jul 3 06:09:39.558: INFO: sonobuoy from heptio-sonobuoy started at 2018-07-03 05:59:09 +0000 UTC (1 container statuses recorded) Jul 3 06:09:39.558: INFO: Container kube-sonobuoy ready: true, restart count 0 Jul 3 06:09:39.558: INFO: sonobuoy-systemd-logs-daemon-set-1c53f31cf14246ca-mhztp from heptio-sonobuoy started at 2018-07-03 06:00:23 +0000 UTC (2 container statuses recorded) Jul 3 06:09:39.558: INFO: Container sonobuoy-systemd-logs-config ready: true, restart count 0 Jul 3 06:09:39.558: INFO: Container sonobuoy-worker ready: true, restart count 0 Jul 3 06:09:39.558: INFO: kube-controller-manager-ubuntuvm from kube-system started at \u0026lt;nil\u0026gt; (0 container statuses recorded) Jul 3 06:09:39.558: INFO: kube-scheduler-ubuntuvm from kube-system started at \u0026lt;nil\u0026gt; (0 container statuses recorded) Jul 3 06:09:39.558: INFO: etcd-ubuntuvm from kube-system started at \u0026lt;nil\u0026gt; (0 container statuses recorded) [It] validates that NodeSelector is respected if not matching [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Trying to schedule Pod with nonempty NodeSelector. STEP: Considering event: Type = [Warning], Name = [restricted-pod.153dc6ef571069ad], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 node(s) didn't match node selector.] [AfterEach] [sig-scheduling] SchedulerPredicates [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:09:40.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-sched-pred-8n5wv\u0026quot; for this suite. Jul 3 06:10:02.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:10:02.799: INFO: namespace: e2e-tests-sched-pred-8n5wv, resource: bindings, ignored listing per whitelist Jul 3 06:10:02.856: INFO: namespace e2e-tests-sched-pred-8n5wv deletion completed in 22.200268317s [AfterEach] [sig-scheduling] SchedulerPredicates [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70 • [SLOW TEST:83.506 seconds] [sig-scheduling] SchedulerPredicates [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22 validates that NodeSelector is respected if not matching [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSSSSSSSSSSSSSSSSSSSSSSSS ------------------------------ [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-apps] Daemon set [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:10:02.862: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [BeforeEach] [sig-apps] Daemon set [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99 [It] should run and stop simple daemon [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating simple DaemonSet \u0026quot;daemon-set\u0026quot; STEP: Check that daemon pods launch on every node of the cluster. Jul 3 06:10:02.990: INFO: Number of nodes with available pods: 0 Jul 3 06:10:02.990: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:10:03.996: INFO: Number of nodes with available pods: 0 Jul 3 06:10:03.996: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:10:05.001: INFO: Number of nodes with available pods: 1 Jul 3 06:10:05.001: INFO: Number of running nodes: 1, number of available pods: 1 STEP: Stop a daemon pod, check that the daemon pod is revived. Jul 3 06:10:05.035: INFO: Number of nodes with available pods: 0 Jul 3 06:10:05.035: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:10:06.058: INFO: Number of nodes with available pods: 0 Jul 3 06:10:06.059: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:10:07.050: INFO: Number of nodes with available pods: 0 Jul 3 06:10:07.050: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:10:08.052: INFO: Number of nodes with available pods: 0 Jul 3 06:10:08.052: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:10:09.043: INFO: Number of nodes with available pods: 0 Jul 3 06:10:09.043: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:10:10.059: INFO: Number of nodes with available pods: 0 Jul 3 06:10:10.060: INFO: Node ubuntuvm is running more than one daemon pod Jul 3 06:10:11.054: INFO: Number of nodes with available pods: 1 Jul 3 06:10:11.055: INFO: Number of running nodes: 1, number of available pods: 1 [AfterEach] [sig-apps] Daemon set [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:65 STEP: Deleting DaemonSet \u0026quot;daemon-set\u0026quot; STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-xnztd, will wait for the garbage collector to delete the pods Jul 3 06:10:11.157: INFO: Deleting {extensions DaemonSet} daemon-set took: 30.388855ms Jul 3 06:10:11.259: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 101.655658ms Jul 3 06:10:19.876: INFO: Number of nodes with available pods: 0 Jul 3 06:10:19.876: INFO: Number of running nodes: 0, number of available pods: 0 Jul 3 06:10:19.878: INFO: daemonset: {\u0026quot;kind\u0026quot;:\u0026quot;DaemonSetList\u0026quot;,\u0026quot;apiVersion\u0026quot;:\u0026quot;apps/v1\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;selfLink\u0026quot;:\u0026quot;/apis/apps/v1/namespaces/e2e-tests-daemonsets-xnztd/daemonsets\u0026quot;,\u0026quot;resourceVersion\u0026quot;:\u0026quot;142861\u0026quot;},\u0026quot;items\u0026quot;:null} Jul 3 06:10:19.881: INFO: pods: {\u0026quot;kind\u0026quot;:\u0026quot;PodList\u0026quot;,\u0026quot;apiVersion\u0026quot;:\u0026quot;v1\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;selfLink\u0026quot;:\u0026quot;/api/v1/namespaces/e2e-tests-daemonsets-xnztd/pods\u0026quot;,\u0026quot;resourceVersion\u0026quot;:\u0026quot;142861\u0026quot;},\u0026quot;items\u0026quot;:null} [AfterEach] [sig-apps] Daemon set [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:10:19.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-daemonsets-xnztd\u0026quot; for this suite. Jul 3 06:10:25.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:10:25.921: INFO: namespace: e2e-tests-daemonsets-xnztd, resource: bindings, ignored listing per whitelist Jul 3 06:10:26.002: INFO: namespace e2e-tests-daemonsets-xnztd deletion completed in 6.112351584s • [SLOW TEST:22.727 seconds] [sig-apps] Daemon set [Serial] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22 should run and stop simple daemon [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ [sig-api-machinery] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-api-machinery] Downward API /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:10:26.003: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating a pod to test downward api env vars Jul 3 06:10:26.099: INFO: Waiting up to 5m0s for pod \u0026quot;downward-api-c71ad49f-7e87-11e8-9aa2-c6770944a2e6\u0026quot; in namespace \u0026quot;e2e-tests-downward-api-mj4ht\u0026quot; to be \u0026quot;success or failure\u0026quot; Jul 3 06:10:26.109: INFO: Pod \u0026quot;downward-api-c71ad49f-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 9.782819ms Jul 3 06:10:28.113: INFO: Pod \u0026quot;downward-api-c71ad49f-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 2.01420854s Jul 3 06:10:30.120: INFO: Pod \u0026quot;downward-api-c71ad49f-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 4.021268684s Jul 3 06:10:32.128: INFO: Pod \u0026quot;downward-api-c71ad49f-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 6.028757065s Jul 3 06:10:34.136: INFO: Pod \u0026quot;downward-api-c71ad49f-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Succeeded\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 8.036636044s STEP: Saw pod success Jul 3 06:10:34.136: INFO: Pod \u0026quot;downward-api-c71ad49f-7e87-11e8-9aa2-c6770944a2e6\u0026quot; satisfied condition \u0026quot;success or failure\u0026quot; Jul 3 06:10:34.140: INFO: Trying to get logs from node ubuntuvm pod downward-api-c71ad49f-7e87-11e8-9aa2-c6770944a2e6 container dapi-container: \u0026lt;nil\u0026gt; STEP: delete the pod Jul 3 06:10:34.190: INFO: Waiting for pod downward-api-c71ad49f-7e87-11e8-9aa2-c6770944a2e6 to disappear Jul 3 06:10:34.194: INFO: Pod downward-api-c71ad49f-7e87-11e8-9aa2-c6770944a2e6 no longer exists [AfterEach] [sig-api-machinery] Downward API /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:10:34.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-downward-api-mj4ht\u0026quot; for this suite. Jul 3 06:10:40.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:10:40.296: INFO: namespace: e2e-tests-downward-api-mj4ht, resource: bindings, ignored listing per whitelist Jul 3 06:10:40.383: INFO: namespace e2e-tests-downward-api-mj4ht deletion completed in 6.177052302s • [SLOW TEST:14.379 seconds] [sig-api-machinery] Downward API /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:37 should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [k8s.io] Docker Containers /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:10:40.383: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating a pod to test override all Jul 3 06:10:40.503: INFO: Waiting up to 5m0s for pod \u0026quot;client-containers-cfb0845a-7e87-11e8-9aa2-c6770944a2e6\u0026quot; in namespace \u0026quot;e2e-tests-containers-4d7qg\u0026quot; to be \u0026quot;success or failure\u0026quot; Jul 3 06:10:40.510: INFO: Pod \u0026quot;client-containers-cfb0845a-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 7.185996ms Jul 3 06:10:42.520: INFO: Pod \u0026quot;client-containers-cfb0845a-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 2.016708124s Jul 3 06:10:44.525: INFO: Pod \u0026quot;client-containers-cfb0845a-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 4.022154595s Jul 3 06:10:46.529: INFO: Pod \u0026quot;client-containers-cfb0845a-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Succeeded\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 6.025953515s STEP: Saw pod success Jul 3 06:10:46.529: INFO: Pod \u0026quot;client-containers-cfb0845a-7e87-11e8-9aa2-c6770944a2e6\u0026quot; satisfied condition \u0026quot;success or failure\u0026quot; Jul 3 06:10:46.532: INFO: Trying to get logs from node ubuntuvm pod client-containers-cfb0845a-7e87-11e8-9aa2-c6770944a2e6 container test-container: \u0026lt;nil\u0026gt; STEP: delete the pod Jul 3 06:10:46.567: INFO: Waiting for pod client-containers-cfb0845a-7e87-11e8-9aa2-c6770944a2e6 to disappear Jul 3 06:10:46.589: INFO: Pod client-containers-cfb0845a-7e87-11e8-9aa2-c6770944a2e6 no longer exists [AfterEach] [k8s.io] Docker Containers /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:10:46.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-containers-4d7qg\u0026quot; for this suite. Jul 3 06:10:52.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:10:52.757: INFO: namespace: e2e-tests-containers-4d7qg, resource: bindings, ignored listing per whitelist Jul 3 06:10:52.784: INFO: namespace e2e-tests-containers-4d7qg deletion completed in 6.190371691s • [SLOW TEST:12.401 seconds] [k8s.io] Docker Containers /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679 should be able to override the image's default command and arguments [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSS ------------------------------ [k8s.io] [sig-node] PreStop should call prestop when killing a pod [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [k8s.io] [sig-node] PreStop /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:10:52.787: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [It] should call prestop when killing a pod [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating server pod server in namespace e2e-tests-prestop-bjnd8 STEP: Waiting for pods to come up. STEP: Creating tester pod tester in namespace e2e-tests-prestop-bjnd8 STEP: Deleting pre-stop pod Jul 3 06:11:11.921: INFO: Saw: { \u0026quot;Hostname\u0026quot;: \u0026quot;server\u0026quot;, \u0026quot;Sent\u0026quot;: null, \u0026quot;Received\u0026quot;: { \u0026quot;prestop\u0026quot;: 1 }, \u0026quot;Errors\u0026quot;: null, \u0026quot;Log\u0026quot;: [ \u0026quot;default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.\u0026quot;, \u0026quot;default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.\u0026quot;, \u0026quot;default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.\u0026quot; ], \u0026quot;StillContactingPeers\u0026quot;: true } STEP: Deleting the server pod [AfterEach] [k8s.io] [sig-node] PreStop /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:11:11.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-prestop-bjnd8\u0026quot; for this suite. Jul 3 06:11:49.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:11:49.991: INFO: namespace: e2e-tests-prestop-bjnd8, resource: bindings, ignored listing per whitelist Jul 3 06:11:50.081: INFO: namespace e2e-tests-prestop-bjnd8 deletion completed in 38.147106656s • [SLOW TEST:57.295 seconds] [k8s.io] [sig-node] PreStop /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679 should call prestop when killing a pod [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SS ------------------------------ [sig-storage] Projected should provide container's memory limit [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-storage] Projected /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:11:50.083: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [BeforeEach] [sig-storage] Projected /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858 [It] should provide container's memory limit [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating a pod to test downward API volume plugin Jul 3 06:11:50.158: INFO: Waiting up to 5m0s for pod \u0026quot;downwardapi-volume-f935879b-7e87-11e8-9aa2-c6770944a2e6\u0026quot; in namespace \u0026quot;e2e-tests-projected-4pdz5\u0026quot; to be \u0026quot;success or failure\u0026quot; Jul 3 06:11:50.162: INFO: Pod \u0026quot;downwardapi-volume-f935879b-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 3.921209ms Jul 3 06:11:52.164: INFO: Pod \u0026quot;downwardapi-volume-f935879b-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 2.006433292s Jul 3 06:11:54.168: INFO: Pod \u0026quot;downwardapi-volume-f935879b-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Succeeded\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 4.010529015s STEP: Saw pod success Jul 3 06:11:54.169: INFO: Pod \u0026quot;downwardapi-volume-f935879b-7e87-11e8-9aa2-c6770944a2e6\u0026quot; satisfied condition \u0026quot;success or failure\u0026quot; Jul 3 06:11:54.172: INFO: Trying to get logs from node ubuntuvm pod downwardapi-volume-f935879b-7e87-11e8-9aa2-c6770944a2e6 container client-container: \u0026lt;nil\u0026gt; STEP: delete the pod Jul 3 06:11:54.197: INFO: Waiting for pod downwardapi-volume-f935879b-7e87-11e8-9aa2-c6770944a2e6 to disappear Jul 3 06:11:54.199: INFO: Pod downwardapi-volume-f935879b-7e87-11e8-9aa2-c6770944a2e6 no longer exists [AfterEach] [sig-storage] Projected /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:11:54.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-projected-4pdz5\u0026quot; for this suite. Jul 3 06:12:00.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:12:00.251: INFO: namespace: e2e-tests-projected-4pdz5, resource: bindings, ignored listing per whitelist Jul 3 06:12:00.404: INFO: namespace e2e-tests-projected-4pdz5 deletion completed in 6.2014029s • [SLOW TEST:10.322 seconds] [sig-storage] Projected /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:34 should provide container's memory limit [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-storage] Downward API volume /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:12:00.405: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [BeforeEach] [sig-storage] Downward API volume /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:38 [It] should provide container's cpu limit [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating a pod to test downward API volume plugin Jul 3 06:12:00.562: INFO: Waiting up to 5m0s for pod \u0026quot;downwardapi-volume-ff663e88-7e87-11e8-9aa2-c6770944a2e6\u0026quot; in namespace \u0026quot;e2e-tests-downward-api-98rjf\u0026quot; to be \u0026quot;success or failure\u0026quot; Jul 3 06:12:00.577: INFO: Pod \u0026quot;downwardapi-volume-ff663e88-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 14.56459ms Jul 3 06:12:02.589: INFO: Pod \u0026quot;downwardapi-volume-ff663e88-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 2.026525202s Jul 3 06:12:04.604: INFO: Pod \u0026quot;downwardapi-volume-ff663e88-7e87-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Succeeded\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 4.041917935s STEP: Saw pod success Jul 3 06:12:04.605: INFO: Pod \u0026quot;downwardapi-volume-ff663e88-7e87-11e8-9aa2-c6770944a2e6\u0026quot; satisfied condition \u0026quot;success or failure\u0026quot; Jul 3 06:12:04.612: INFO: Trying to get logs from node ubuntuvm pod downwardapi-volume-ff663e88-7e87-11e8-9aa2-c6770944a2e6 container client-container: \u0026lt;nil\u0026gt; STEP: delete the pod Jul 3 06:12:04.680: INFO: Waiting for pod downwardapi-volume-ff663e88-7e87-11e8-9aa2-c6770944a2e6 to disappear Jul 3 06:12:04.684: INFO: Pod downwardapi-volume-ff663e88-7e87-11e8-9aa2-c6770944a2e6 no longer exists [AfterEach] [sig-storage] Downward API volume /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:12:04.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-downward-api-98rjf\u0026quot; for this suite. Jul 3 06:12:10.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:12:10.846: INFO: namespace: e2e-tests-downward-api-98rjf, resource: bindings, ignored listing per whitelist Jul 3 06:12:10.852: INFO: namespace e2e-tests-downward-api-98rjf deletion completed in 6.163639204s • [SLOW TEST:10.447 seconds] [sig-storage] Downward API volume /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:33 should provide container's cpu limit [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SS ------------------------------ [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-api-machinery] Watchers /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:12:10.852: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: creating a watch on configmaps with a certain label STEP: creating a new configmap STEP: modifying the configmap once STEP: changing the label value of the configmap STEP: Expecting to observe a delete notification for the watched object Jul 3 06:12:10.933: INFO: Got : ADDED \u0026amp;ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q7f6p,SelfLink:/api/v1/namespaces/e2e-tests-watch-q7f6p/configmaps/e2e-watch-test-label-changed,UID:0595b33e-7e88-11e8-afec-0800272e6982,ResourceVersion:143167,Generation:0,CreationTimestamp:2018-07-03 06:12:10 +0000 UTC,DeletionTimestamp:\u0026lt;nil\u0026gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},} Jul 3 06:12:10.933: INFO: Got : MODIFIED \u0026amp;ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q7f6p,SelfLink:/api/v1/namespaces/e2e-tests-watch-q7f6p/configmaps/e2e-watch-test-label-changed,UID:0595b33e-7e88-11e8-afec-0800272e6982,ResourceVersion:143168,Generation:0,CreationTimestamp:2018-07-03 06:12:10 +0000 UTC,DeletionTimestamp:\u0026lt;nil\u0026gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},} Jul 3 06:12:10.934: INFO: Got : DELETED \u0026amp;ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q7f6p,SelfLink:/api/v1/namespaces/e2e-tests-watch-q7f6p/configmaps/e2e-watch-test-label-changed,UID:0595b33e-7e88-11e8-afec-0800272e6982,ResourceVersion:143169,Generation:0,CreationTimestamp:2018-07-03 06:12:10 +0000 UTC,DeletionTimestamp:\u0026lt;nil\u0026gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},} STEP: modifying the configmap a second time STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements STEP: changing the label value of the configmap back STEP: modifying the configmap a third time STEP: deleting the configmap STEP: Expecting to observe an add notification for the watched object when the label value was restored Jul 3 06:12:20.976: INFO: Got : ADDED \u0026amp;ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q7f6p,SelfLink:/api/v1/namespaces/e2e-tests-watch-q7f6p/configmaps/e2e-watch-test-label-changed,UID:0595b33e-7e88-11e8-afec-0800272e6982,ResourceVersion:143183,Generation:0,CreationTimestamp:2018-07-03 06:12:10 +0000 UTC,DeletionTimestamp:\u0026lt;nil\u0026gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},} Jul 3 06:12:20.982: INFO: Got : MODIFIED \u0026amp;ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q7f6p,SelfLink:/api/v1/namespaces/e2e-tests-watch-q7f6p/configmaps/e2e-watch-test-label-changed,UID:0595b33e-7e88-11e8-afec-0800272e6982,ResourceVersion:143184,Generation:0,CreationTimestamp:2018-07-03 06:12:10 +0000 UTC,DeletionTimestamp:\u0026lt;nil\u0026gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},} Jul 3 06:12:20.985: INFO: Got : DELETED \u0026amp;ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-q7f6p,SelfLink:/api/v1/namespaces/e2e-tests-watch-q7f6p/configmaps/e2e-watch-test-label-changed,UID:0595b33e-7e88-11e8-afec-0800272e6982,ResourceVersion:143185,Generation:0,CreationTimestamp:2018-07-03 06:12:10 +0000 UTC,DeletionTimestamp:\u0026lt;nil\u0026gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},} [AfterEach] [sig-api-machinery] Watchers /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:12:20.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-watch-q7f6p\u0026quot; for this suite. Jul 3 06:12:27.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:12:27.117: INFO: namespace: e2e-tests-watch-q7f6p, resource: bindings, ignored listing per whitelist Jul 3 06:12:27.192: INFO: namespace e2e-tests-watch-q7f6p deletion completed in 6.198067444s • [SLOW TEST:16.340 seconds] [sig-api-machinery] Watchers /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22 should observe an object deletion if it stops meeting the requirements of the selector [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSSSSS ------------------------------ [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [k8s.io] Probing container /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:12:27.193: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [BeforeEach] [k8s.io] Probing container /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48 [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-t89js Jul 3 06:12:31.325: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-t89js STEP: checking the pod's current state and verifying that restartCount is present Jul 3 06:12:31.331: INFO: Initial restart count of pod liveness-http is 0 Jul 3 06:12:51.443: INFO: Restart count of pod e2e-tests-container-probe-t89js/liveness-http is now 1 (20.111946656s elapsed) STEP: deleting the pod [AfterEach] [k8s.io] Probing container /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:12:51.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-container-probe-t89js\u0026quot; for this suite. Jul 3 06:12:57.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:12:57.637: INFO: namespace: e2e-tests-container-probe-t89js, resource: bindings, ignored listing per whitelist Jul 3 06:12:57.654: INFO: namespace e2e-tests-container-probe-t89js deletion completed in 6.151550499s • [SLOW TEST:30.462 seconds] [k8s.io] Probing container /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:679 should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSSSSSSSSSSSSSSS ------------------------------ [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-api-machinery] Watchers /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:12:57.658: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: creating a watch on configmaps STEP: creating a new configmap STEP: modifying the configmap once STEP: closing the watch once it receives two notifications Jul 3 06:12:57.744: INFO: Got : ADDED \u0026amp;ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xb2xg,SelfLink:/api/v1/namespaces/e2e-tests-watch-xb2xg/configmaps/e2e-watch-test-watch-closed,UID:217d94bb-7e88-11e8-afec-0800272e6982,ResourceVersion:143270,Generation:0,CreationTimestamp:2018-07-03 06:12:57 +0000 UTC,DeletionTimestamp:\u0026lt;nil\u0026gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},} Jul 3 06:12:57.745: INFO: Got : MODIFIED \u0026amp;ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xb2xg,SelfLink:/api/v1/namespaces/e2e-tests-watch-xb2xg/configmaps/e2e-watch-test-watch-closed,UID:217d94bb-7e88-11e8-afec-0800272e6982,ResourceVersion:143271,Generation:0,CreationTimestamp:2018-07-03 06:12:57 +0000 UTC,DeletionTimestamp:\u0026lt;nil\u0026gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},} STEP: modifying the configmap a second time, while the watch is closed STEP: creating a new watch on configmaps from the last resource version observed by the first watch STEP: deleting the configmap STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed Jul 3 06:12:57.762: INFO: Got : MODIFIED \u0026amp;ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xb2xg,SelfLink:/api/v1/namespaces/e2e-tests-watch-xb2xg/configmaps/e2e-watch-test-watch-closed,UID:217d94bb-7e88-11e8-afec-0800272e6982,ResourceVersion:143272,Generation:0,CreationTimestamp:2018-07-03 06:12:57 +0000 UTC,DeletionTimestamp:\u0026lt;nil\u0026gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},} Jul 3 06:12:57.762: INFO: Got : DELETED \u0026amp;ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-xb2xg,SelfLink:/api/v1/namespaces/e2e-tests-watch-xb2xg/configmaps/e2e-watch-test-watch-closed,UID:217d94bb-7e88-11e8-afec-0800272e6982,ResourceVersion:143273,Generation:0,CreationTimestamp:2018-07-03 06:12:57 +0000 UTC,DeletionTimestamp:\u0026lt;nil\u0026gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},} [AfterEach] [sig-api-machinery] Watchers /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:12:57.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-watch-xb2xg\u0026quot; for this suite. Jul 3 06:13:03.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:13:03.920: INFO: namespace: e2e-tests-watch-xb2xg, resource: bindings, ignored listing per whitelist Jul 3 06:13:04.011: INFO: namespace e2e-tests-watch-xb2xg deletion completed in 6.245271295s • [SLOW TEST:6.353 seconds] [sig-api-machinery] Watchers /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22 should be able to restart watching from the last resource version observed by the previous watch [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSSSSSSSSSSSSSSSS ------------------------------ [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-storage] ConfigMap /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:13:04.011: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating configMap with name configmap-test-volume-2541dc76-7e88-11e8-9aa2-c6770944a2e6 STEP: Creating a pod to test consume configMaps Jul 3 06:13:04.062: INFO: Waiting up to 5m0s for pod \u0026quot;pod-configmaps-25425d98-7e88-11e8-9aa2-c6770944a2e6\u0026quot; in namespace \u0026quot;e2e-tests-configmap-nw9xh\u0026quot; to be \u0026quot;success or failure\u0026quot; Jul 3 06:13:04.068: INFO: Pod \u0026quot;pod-configmaps-25425d98-7e88-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 5.263313ms Jul 3 06:13:06.086: INFO: Pod \u0026quot;pod-configmaps-25425d98-7e88-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Pending\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 2.023042273s Jul 3 06:13:08.093: INFO: Pod \u0026quot;pod-configmaps-25425d98-7e88-11e8-9aa2-c6770944a2e6\u0026quot;: Phase=\u0026quot;Succeeded\u0026quot;, Reason=\u0026quot;\u0026quot;, readiness=false. Elapsed: 4.030624253s STEP: Saw pod success Jul 3 06:13:08.094: INFO: Pod \u0026quot;pod-configmaps-25425d98-7e88-11e8-9aa2-c6770944a2e6\u0026quot; satisfied condition \u0026quot;success or failure\u0026quot; Jul 3 06:13:08.099: INFO: Trying to get logs from node ubuntuvm pod pod-configmaps-25425d98-7e88-11e8-9aa2-c6770944a2e6 container configmap-volume-test: \u0026lt;nil\u0026gt; STEP: delete the pod Jul 3 06:13:08.133: INFO: Waiting for pod pod-configmaps-25425d98-7e88-11e8-9aa2-c6770944a2e6 to disappear Jul 3 06:13:08.136: INFO: Pod pod-configmaps-25425d98-7e88-11e8-9aa2-c6770944a2e6 no longer exists [AfterEach] [sig-storage] ConfigMap /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:142 Jul 3 06:13:08.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready STEP: Destroying namespace \u0026quot;e2e-tests-configmap-nw9xh\u0026quot; for this suite. Jul 3 06:13:14.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered Jul 3 06:13:14.309: INFO: namespace: e2e-tests-configmap-nw9xh, resource: bindings, ignored listing per whitelist Jul 3 06:13:14.340: INFO: namespace e2e-tests-configmap-nw9xh deletion completed in 6.201346759s • [SLOW TEST:10.329 seconds] [sig-storage] ConfigMap /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32 should be consumable from pods in volume as non-root [NodeConformance] [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 ------------------------------ SSSSSSS ------------------------------ [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 [BeforeEach] [sig-apps] StatefulSet /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:141 STEP: Creating a kubernetes client Jul 3 06:13:14.340: INFO: \u0026gt;\u0026gt;\u0026gt; kubeConfig: /tmp/kubeconfig-559575868 STEP: Building a namespace api object STEP: Waiting for a default service account to be provisioned in namespace [BeforeEach] [sig-apps] StatefulSet /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:57 [BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:72 STEP: Creating service test in namespace e2e-tests-statefulset-kntgb [It] should perform rolling updates and roll backs of template modifications [Conformance] /workspace/anago-v1.11.0-rc.3.3+91e7b4fd31fcd3/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:684 STEP: Creating a new StatefulSet Jul 3 06:13:14.444: INFO: Found 0 stateful pods, waiting for 3 Jul 3 06:13:24.450: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true Jul 3 06:13:24.450: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true Jul 3 06:13:24.450: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true Jul 3 06:13:24.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-559575868 exec --namespace=e2e-tests-statefulset-kntgb ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true' Jul 3 06:13:24.728: INFO: stderr: \u0026quot;\u0026quot; Jul 3 06:13:24.728: INFO: stdout: \u0026quot;'/usr/share/nginx/html/index.html' -\u0026gt; '/tmp/index.html'\\n\u0026quot; Jul 3 06:13:24.728: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -\u0026gt; '/tmp/index.html' STEP: Updating StatefulSet template: update image from k8s.gcr.io/nginx-slim-amd64:0.20 to k8s.gcr.io/nginx-slim-amd64:0.21 Jul 3 06:13:34.779: INFO: Updating stateful set ss2 STEP: Creating a new revision STEP: Updating Pods in reverse ordinal order Jul 3 06:13:44.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-559575868 exec --namespace=e2e-tests-statefulset-kntgb ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true' Jul 3 06:13:45.165: INFO: stderr: \u0026quot;\u0026quot; Jul 3 06:13:45.165: INFO: stdout: \u0026quot;'/tmp/index.html' -\u0026gt; '/usr/share/nginx/html/index.html'\\n\u0026quot; Jul 3 06:13:45.165: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -\u0026gt; '/usr/share/nginx/html/index.html' Jul 3 06:13:55.183: INFO: Waiting for StatefulSet e2e-tests-statefulset-kntgb/ss2 to complete update Jul 3 06:13:55.183: INFO: Waiting for Pod e2e-tests-statefulset-kntgb/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff Jul 3 06:13:55.183: INFO: Waiting for Pod e2e-tests-statefulset-kntgb/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff Jul 3 06:14:05.194: INFO: Waiting for StatefulSet e2e-tests-statefulset-kntgb/ss2 to complete update Jul 3 06:14:05.194: INFO: Waiting for Pod e2e-tests-statefulset-kntgb/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff Jul 3 06:14:05.194: INFO: Waiting for Pod e2e-tests-statefulset-kntgb/ss2-1 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff Jul 3 06:14:15.197: INFO: Waiting for StatefulSet e2e-tests-statefulset-kntgb/ss2 to complete update Jul 3 06:14:15.197: INFO: Waiting for Pod e2e-tests-statefulset-kntgb/ss2-0 to have revision ss2-56dd5fb9c4 update revision ss2-76cb68b6ff STEP: Rolling back to a previous revision Jul 3 06:14:25.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-559575868 exec --namespace=e2e-tests-statefulset-kntgb ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true' Jul 3 06:14:25.478: INFO: stderr: \u0026quot;\u0026quot; Jul 3 06:14:25.478: INFO: stdout: \u0026quot;'/usr/share/nginx/html/index.html' -\u0026gt; '/tmp/index.html'\\n\u0026quot; Jul 3 06:14:25.478: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -\u0026gt; '/tmp/index.html' Jul 3 06:14:35.535: INFO: Updating stateful set ss2  "
},
{
	"uri": "/pi_cluster/microservices/children/2018-07-01-a/",
	"title": "Creating simple Python server container",
	"tags": ["python"],
	"description": "",
	"content": " Goal As we did for Go and Java, where is was possible to create an Dockerfile starting from \u0026ldquo;scratch\u0026rdquo;, the goal of this post is to create a python base server container with a minimum about of packages (debian and python) to reduce the security exposure of the container as well as the image size.\nKey Aspects  Use SCRATCH has base image to keep size minimum Simple HelloWorld Python web server Create associated HELM chart for Kubernetes deployment Provide deployment for both amd64 and arm32v7  Simple Python Server The pythonhttpserver repo showcases: - How to create a simple Python3 server - How to leverage Travis to compile for amd64 and arm32v7. - Branch amd64 is for normal PC and HP server. - Branch arm32v7 produces software usable on Raspberry PI 3B+\nUsefull Links TBD\n"
},
{
	"uri": "/devops/advanced/children/2018-06-30-a/",
	"title": "Update Kubernetes to 1.11 on Ubuntu",
	"tags": ["kubernetes"],
	"description": "",
	"content": " Goal Kubeadm is coming with an upgrade option. The goal of this study is to leverage the option.\nInitial set up Kubernetes 1.10.4 is installed\ncat /etc/apt/sources.list.d/kubernetes.list deb http://apt.kubernetes.io/ kubernetes-xenial main  sudo dpkg -l kubeadm Desired=Unknown/Install/Remove/Purge/Hold | Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend |/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad) ||/ Name Version Architecture Description +++-======================================-========================-========================-================================================================================= ii kubeadm 1.10.4-00 amd64 Kubernetes Cluster Bootstrapping Tool  sudo dpkg -l kubelet Desired=Unknown/Install/Remove/Purge/Hold | Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend |/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad) ||/ Name Version Architecture Description +++-======================================-========================-========================-================================================================================= ii kubelet 1.10.4-00 amd64 Kubernetes Node Agent  sudo dpkg -l kubectl Desired=Unknown/Install/Remove/Purge/Hold | Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend |/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad) ||/ Name Version Architecture Description +++-======================================-========================-========================-================================================================================= ii kubectl 1.10.4-00 amd64 Kubernetes Command Line Tool  kubectl version Client Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;10\u0026quot;, GitVersion:\u0026quot;v1.10.4\u0026quot;, GitCommit:\u0026quot;5ca598b4ba5abb89bb773071ce452e33fb66339d\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-06-06T08:13:03Z\u0026quot;, GoVersion:\u0026quot;go1.9.3\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;} Server Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;10\u0026quot;, GitVersion:\u0026quot;v1.10.4\u0026quot;, GitCommit:\u0026quot;5ca598b4ba5abb89bb773071ce452e33fb66339d\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-06-06T08:00:59Z\u0026quot;, GoVersion:\u0026quot;go1.9.3\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;}  Update kubelet and kubectl Update aptitude\nsudo apt-get update Hit:2 http://ppa.launchpad.net/longsleep/golang-backports/ubuntu xenial InRelease Get:3 http://security.ubuntu.com/ubuntu xenial-security InRelease [107 kB] Get:4 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [511 kB] Get:5 http://security.ubuntu.com/ubuntu xenial-security/main i386 Packages [452 kB] Get:6 http://security.ubuntu.com/ubuntu xenial-security/main amd64 DEP-11 Metadata [67.7 kB] Get:7 http://security.ubuntu.com/ubuntu xenial-security/main DEP-11 64x64 Icons [68.0 kB] Get:8 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [355 kB] Get:9 http://security.ubuntu.com/ubuntu xenial-security/universe i386 Packages [303 kB] Get:10 http://security.ubuntu.com/ubuntu xenial-security/universe Translation-en [133 kB] Get:11 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 DEP-11 Metadata [107 kB] Get:12 http://security.ubuntu.com/ubuntu xenial-security/universe DEP-11 64x64 Icons [147 kB] Hit:13 http://us.archive.ubuntu.com/ubuntu xenial InRelease Get:14 http://us.archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB] Get:15 http://us.archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB] Get:16 http://us.archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [796 kB] Get:17 http://us.archive.ubuntu.com/ubuntu xenial-updates/main i386 Packages [728 kB] Get:18 http://us.archive.ubuntu.com/ubuntu xenial-updates/main Translation-en [329 kB] Get:19 http://us.archive.ubuntu.com/ubuntu xenial-updates/main amd64 DEP-11 Metadata [318 kB] Get:20 http://us.archive.ubuntu.com/ubuntu xenial-updates/main DEP-11 64x64 Icons [228 kB] Get:21 http://us.archive.ubuntu.com/ubuntu xenial-updates/universe amd64 Packages [640 kB] Get:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease [8,993 B] Get:22 http://us.archive.ubuntu.com/ubuntu xenial-updates/universe i386 Packages [585 kB] Get:23 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 Packages [17.9 kB] Get:24 http://us.archive.ubuntu.com/ubuntu xenial-updates/universe Translation-en [257 kB] Get:25 http://us.archive.ubuntu.com/ubuntu xenial-updates/universe amd64 DEP-11 Metadata [246 kB] Get:26 http://us.archive.ubuntu.com/ubuntu xenial-updates/universe DEP-11 64x64 Icons [331 kB] Get:27 http://us.archive.ubuntu.com/ubuntu xenial-updates/multiverse amd64 DEP-11 Metadata [5,964 B] Get:28 http://us.archive.ubuntu.com/ubuntu xenial-backports/main amd64 Packages [6,740 B] Get:29 http://us.archive.ubuntu.com/ubuntu xenial-backports/main i386 Packages [6,732 B] Get:30 http://us.archive.ubuntu.com/ubuntu xenial-backports/main Translation-en [4,180 B] Get:31 http://us.archive.ubuntu.com/ubuntu xenial-backports/main amd64 DEP-11 Metadata [3,328 B] Get:32 http://us.archive.ubuntu.com/ubuntu xenial-backports/universe amd64 Packages [7,412 B] Get:33 http://us.archive.ubuntu.com/ubuntu xenial-backports/universe i386 Packages [7,104 B] Get:34 http://us.archive.ubuntu.com/ubuntu xenial-backports/universe amd64 DEP-11 Metadata [5,100 B] Get:35 http://us.archive.ubuntu.com/ubuntu xenial-backports/universe DEP-11 64x64 Icons [1,789 B] Fetched 7,000 kB in 9s (757 kB/s)  Run the apt-get upgrade command. Notice how the kubeadm is \u0026ldquo;kept back\u0026rdquo;\nsudo apt-get upgrade Reading package lists... Done Building dependency tree Reading state information... Done Calculating upgrade... Done The following packages were automatically installed and are no longer required: linux-headers-4.13.0-26 linux-headers-4.13.0-26-generic linux-image-4.13.0-26-generic linux-image-extra-4.13.0-26-generic Use 'sudo apt autoremove' to remove them. The following packages have been kept back: kubeadm The following packages will be upgraded: amd64-microcode console-setup console-setup-linux cpp-5 desktop-file-utils ebtables g++-5 gcc-5 gcc-5-base gir1.2-javascriptcoregtk-4.0 gir1.2-webkit2-4.0 gnome-software gnome-software-common keyboard-configuration kubectl kubelet libasan2 libatomic1 libcc1-0 libcilkrts5 libgcc-5-dev libgcrypt20 libgomp1 libitm1 libjasper1 libjavascriptcoregtk-4.0-18 libldap-2.4-2 liblsan0 libmpx0 libplymouth4 libquadmath0 libssl-dev libssl1.0.0 libstdc++-5-dev libstdc++6 libtsan0 libubsan0 libwebkit2gtk-4.0-37 libwebkit2gtk-4.0-37-gtk2 linux-firmware openssl plymouth plymouth-label plymouth-theme-ubuntu-logo plymouth-theme-ubuntu-text rfkill snapd ubuntu-core-launcher ubuntu-software update-notifier update-notifier-common wireless-regdb 52 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.  sudo apt-get upgrade  sudo apt-get autoremove  sudo reboot  sudo dpkg -l kubectl Desired=Unknown/Install/Remove/Purge/Hold | Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend |/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad) ||/ Name Version Architecture Description +++-======================================-========================-========================-================================================================================= ii kubectl 1.11.0-00 amd64 Kubernetes Command Line Tool  sudo dpkg -l kubeadm Desired=Unknown/Install/Remove/Purge/Hold | Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend |/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad) ||/ Name Version Architecture Description +++-======================================-========================-========================-================================================================================= ii kubeadm 1.10.4-00 amd64 Kubernetes Cluster Bootstrapping Tool  sudo dpkg -l kubelet Desired=Unknown/Install/Remove/Purge/Hold | Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend |/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad) ||/ Name Version Architecture Description +++-======================================-========================-========================-================================================================================= ii kubelet 1.11.0-00 amd64 Kubernetes Node Agent  kubectl version Client Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;11\u0026quot;, GitVersion:\u0026quot;v1.11.0\u0026quot;, GitCommit:\u0026quot;91e7b4fd31fcd3d5f436da26c980becec37ceefe\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-06-27T20:17:28Z\u0026quot;, GoVersion:\u0026quot;go1.10.2\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;} Server Version: version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;10\u0026quot;, GitVersion:\u0026quot;v1.10.4\u0026quot;, GitCommit:\u0026quot;5ca598b4ba5abb89bb773071ce452e33fb66339d\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-06-06T08:00:59Z\u0026quot;, GoVersion:\u0026quot;go1.9.3\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;}  Upgrading kubeadm Install new kubeadm and associated new cri-tools\nsudo apt-get install kubeadm Reading package lists... Done Building dependency tree Reading state information... Done The following additional packages will be installed: cri-tools The following NEW packages will be installed: cri-tools The following packages will be upgraded: kubeadm 1 upgraded, 1 newly installed, 0 to remove and 0 not upgraded. Need to get 14.7 MB of archives. After this operation, 70.9 MB disk space will be freed. Do you want to continue? [Y/n] y Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 cri-tools amd64 1.11.0-00 [5,309 kB] Get:2 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.11.0-00 [9,422 kB] Fetched 14.7 MB in 5s (2,780 kB/s) Selecting previously unselected package cri-tools. (Reading database ... 225649 files and directories currently installed.) Preparing to unpack .../cri-tools_1.11.0-00_amd64.deb ... Unpacking cri-tools (1.11.0-00) ... Preparing to unpack .../kubeadm_1.11.0-00_amd64.deb ... Unpacking kubeadm (1.11.0-00) over (1.10.4-00) ... Setting up cri-tools (1.11.0-00) ... Setting up kubeadm (1.11.0-00) ... Installing new version of config file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf ...  kubeadm version kubeadm version: \u0026amp;version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;11\u0026quot;, GitVersion:\u0026quot;v1.11.0\u0026quot;, GitCommit:\u0026quot;91e7b4fd31fcd3d5f436da26c980becec37ceefe\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-06-27T20:14:41Z\u0026quot;, GoVersion:\u0026quot;go1.10.2\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;}  Upgrading your Kubernetes cluster Cluster does not seems be in such a great shape\nNAME READY STATUS RESTARTS AGE pod/calico-etcd-j8zqp 1/1 Running 22 11d pod/calico-kube-controllers-679568f47c-wgz7n 1/1 Running 27 11d pod/calico-node-knstj 2/2 Running 39 11d pod/etcd-xxxxxxx 0/1 Pending 0 1h pod/kube-apiserver-xxxxxxx 0/1 Pending 0 1h pod/kube-controller-manager-xxxxxxx 0/1 Pending 0 1h pod/kube-dns-86f4d74b45-fs7bq 3/3 Running 66 11d pod/kube-proxy-mpbf7 1/1 Running 22 11d pod/kube-scheduler-xxxxxxx 0/1 Pending 0 1h pod/tiller-deploy-5c688d5f9b-6cl5n 1/1 Running 23 11d NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/calico-etcd ClusterIP 10.96.232.136 \u0026lt;none\u0026gt; 6666/TCP 11d service/kube-dns ClusterIP 10.96.0.10 \u0026lt;none\u0026gt; 53/UDP,53/TCP 11d service/tiller-deploy ClusterIP 10.97.44.240 \u0026lt;none\u0026gt; 44134/TCP 11d NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE daemonset.apps/calico-etcd 1 1 0 1 0 node-role.kubernetes.io/master= 11d daemonset.apps/calico-node 1 1 0 1 0 \u0026lt;none\u0026gt; 11d daemonset.apps/kube-proxy 1 1 0 1 0 \u0026lt;none\u0026gt; 11d NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/calico-kube-controllers 1 1 1 0 11d deployment.apps/kube-dns 1 1 1 0 11d deployment.apps/tiller-deploy 1 1 1 0 11d NAME DESIRED CURRENT READY AGE replicaset.apps/calico-kube-controllers-679568f47c 1 1 0 11d replicaset.apps/kube-dns-86f4d74b45 1 1 0 11d replicaset.apps/tiller-deploy-5c688d5f9b 1 1 0 11d  sudo kubeadm upgrade apply --dry-run 1.11.0 \u0026gt; /tmp/traces [upgrade/health] FATAL: [preflight] Some fatal errors occurred: [ERROR MasterNodesReady]: there are NotReady masters in the cluster: [xxxxxxx] [preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`  Usefull Links TBD\n"
},
{
	"uri": "/pi_cluster/microservices/children/2018-06-29-a/",
	"title": "Creating simple GO server container",
	"tags": ["golang"],
	"description": "",
	"content": " Goal  Use SCRATCH has base image to keep size minimum Simple HelloWorld GO web server Create associated HELM chart for Kubernetes deployment Provide deployment for both amd64 and arm32v7  Simple GO Server compilation The gohttpserver repo showcases: - How to compile a GO process - How to leverage Travis to compile for amd64 and arm32v7. - Branch amd64 is for normal PC and HP server. - Branch arm32v7 produces software usable on Raspberry PI 3B+\nKubeplay Github repo The kubeplay repo describes: - How to compile a GO server and - How to create a Helm chart to easily deploy on - How to use Travis-CI to compile and publish the image on Docker.io with the proper tags. - The amd64 branch is kind of complete - The arm32v7 produces software deployable on Raspberry PI 3B+\nUsefull Links TBD\n"
},
{
	"uri": "/pi_cluster/microservices/children/2018-06-28-a/",
	"title": "Creating simple Java 10 server container",
	"tags": ["java"],
	"description": "",
	"content": " Goal Very often people associated Java to quite bulky and difficult to use in the microservice context, unless you have very large image containing the JRE. But since Java 9, Java did kind of catchup with golang on the subject. Where you can obtain a standalone executable when we running go build, java is now proposing jlink which always you to acheive a very similar result. The goal of this post is to build a container image as small as possible running Java.\nKey Aspects  Use SCRATCH has base image to keep size minimum Simple HelloWorld Java 10 web server Create associated HELM chart for Kubernetes deployment Provide deployment for both amd64 and arm32v7  Install Java 10 on dev machine sudo add-apt-repository ppa:linuxuprising/java Oracle Java 10 installer Java binaries are not hosted in this PPA due to licensing. The packages in this PPA download and install Oracle Java 10 (JDK 10), so a working Internet connection is required. PPA for https://www.linuxuprising.com/ For feedback, see https://www.linuxuprising.com/2018/04/install-oracle-java-10-in-ubuntu-or.html More info: https://launchpad.net/~linuxuprising/+archive/ubuntu/java Press [ENTER] to continue or ctrl-c to cancel adding it gpg: keyring `/tmp/tmpf0lejdsg/secring.gpg' created gpg: keyring `/tmp/tmpf0lejdsg/pubring.gpg' created gpg: requesting key 73C3DB2A from hkp server keyserver.ubuntu.com gpg: /tmp/tmpf0lejdsg/trustdb.gpg: trustdb created gpg: key 73C3DB2A: public key \u0026quot;Launchpad PPA for Linux Uprising\u0026quot; imported gpg: Total number processed: 1 gpg: imported: 1 (RSA: 1) OK  sudo apt-get update Hit:1 http://ppa.launchpad.net/gophers/archive/ubuntu xenial InRelease Hit:2 https://download.docker.com/linux/ubuntu xenial InRelease Hit:3 https://deb.nodesource.com/node_10.x xenial InRelease Get:4 http://ppa.launchpad.net/linuxuprising/java/ubuntu xenial InRelease [18.0 kB] Get:6 http://security.ubuntu.com/ubuntu xenial-security InRelease [107 kB] Hit:7 http://us.archive.ubuntu.com/ubuntu xenial InRelease Get:8 http://us.archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB] Hit:9 http://ppa.launchpad.net/longsleep/golang-backports/ubuntu xenial InRelease Get:10 http://us.archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB] Get:11 http://us.archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [796 kB] Hit:12 http://ppa.launchpad.net/masterminds/glide/ubuntu xenial InRelease Get:13 http://us.archive.ubuntu.com/ubuntu xenial-updates/main i386 Packages [728 kB] Get:14 http://security.ubuntu.com/ubuntu xenial-security/main amd64 DEP-11 Metadata [67.7 kB] Get:15 http://ppa.launchpad.net/linuxuprising/java/ubuntu xenial/main amd64 Packages [1,956 B] Get:16 http://us.archive.ubuntu.com/ubuntu xenial-updates/main amd64 DEP-11 Metadata [318 kB] Get:17 http://security.ubuntu.com/ubuntu xenial-security/main DEP-11 64x64 Icons [72.6 kB] Hit:5 https://packages.cloud.google.com/apt kubernetes-xenial InRelease Get:18 http://us.archive.ubuntu.com/ubuntu xenial-updates/main DEP-11 64x64 Icons [232 kB] Get:19 http://ppa.launchpad.net/linuxuprising/java/ubuntu xenial/main Translation-en [1,004 B] Get:20 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 DEP-11 Metadata [107 kB] Get:21 http://us.archive.ubuntu.com/ubuntu xenial-updates/universe amd64 Packages [640 kB] Get:22 http://security.ubuntu.com/ubuntu xenial-security/universe DEP-11 64x64 Icons [142 kB] Get:23 http://us.archive.ubuntu.com/ubuntu xenial-updates/universe i386 Packages [585 kB] Get:24 http://us.archive.ubuntu.com/ubuntu xenial-updates/universe amd64 DEP-11 Metadata [246 kB] Get:25 http://us.archive.ubuntu.com/ubuntu xenial-updates/universe DEP-11 64x64 Icons [338 kB] Get:26 http://us.archive.ubuntu.com/ubuntu xenial-updates/multiverse amd64 DEP-11 Metadata [5,964 B] Get:27 http://us.archive.ubuntu.com/ubuntu xenial-backports/main amd64 DEP-11 Metadata [3,324 B] Get:28 http://us.archive.ubuntu.com/ubuntu xenial-backports/universe amd64 DEP-11 Metadata [5,100 B] Fetched 4,630 kB in 3s (1,333 kB/s) Reading package lists... Done  Download the package and install it. Note the download speed was at time really slow. Could not figure where the source of the issue was.\nsudo apt-get install oracle-java10-installer Reading package lists... Done Building dependency tree Reading state information... Done The following additional packages will be installed: gsfonts-x11 java-common oracle-java10-set-default Suggested packages: binfmt-support visualvm ttf-baekmuk | ttf-unfonts | ttf-unfonts-core ttf-kochi-gothic | ttf-sazanami-gothic ttf-kochi-mincho | ttf-sazanami-mincho ttf-arphic-uming The following NEW packages will be installed: gsfonts-x11 java-common oracle-java10-installer oracle-java10-set-default 0 upgraded, 4 newly installed, 0 to remove and 0 not upgraded. Need to get 46.6 kB of archives. After this operation, 265 kB of additional disk space will be used. Do you want to continue? [Y/n] y Get:1 http://us.archive.ubuntu.com/ubuntu xenial/main amd64 java-common all 0.56ubuntu2 [7,742 B] Get:2 http://us.archive.ubuntu.com/ubuntu xenial/universe amd64 gsfonts-x11 all 0.24 [7,314 B] Get:3 http://ppa.launchpad.net/linuxuprising/java/ubuntu xenial/main amd64 oracle-java10-installer amd64 10.0.1-1~linuxuprising+1 [29.0 kB] Get:4 http://ppa.launchpad.net/linuxuprising/java/ubuntu xenial/main amd64 oracle-java10-set-default amd64 10.0.1-1~linuxuprising+1 [2,464 B] Fetched 46.6 kB in 0s (55.0 kB/s) Preconfiguring packages ... Selecting previously unselected package java-common. (Reading database ... 239646 files and directories currently installed.) Preparing to unpack .../java-common_0.56ubuntu2_all.deb ... Unpacking java-common (0.56ubuntu2) ... Selecting previously unselected package oracle-java10-installer. Preparing to unpack .../oracle-java10-installer_10.0.1-1~linuxuprising+1_amd64.deb ... Unpacking oracle-java10-installer (10.0.1-1~linuxuprising+1) ... Processing triggers for man-db (2.7.5-1) ... Processing triggers for desktop-file-utils (0.22-1ubuntu5.2) ... Processing triggers for bamfdaemon (0.5.3~bzr0+16.04.20180209-0ubuntu1) ... Rebuilding /usr/share/applications/bamf-2.index... Processing triggers for gnome-menus (3.13.3-6ubuntu3.1) ... Processing triggers for mime-support (3.59ubuntu1) ... Processing triggers for hicolor-icon-theme (0.15-0ubuntu1) ... Processing triggers for shared-mime-info (1.5-2ubuntu0.1) ... Setting up java-common (0.56ubuntu2) ... Setting up oracle-java10-installer (10.0.1-1~linuxuprising+1) ... No /var/cache/oracle-jdk10-installer/wgetrc file found. Creating /var/cache/oracle-jdk10-installer/wgetrc and using default oracle-java10-installer wgetrc settings for it. Downloading Oracle Java 10... --2018-07-01 11:04:19-- http://download.oracle.com/otn-pub/java/jdk/10.0.1+10/fb4372174a714e6b8c52526dc134031e/jdk-10.0.1_linux-x64_bin.tar.gz Resolving download.oracle.com (download.oracle.com)... 23.45.132.164 Connecting to download.oracle.com (download.oracle.com)|23.45.132.164|:80... connected. HTTP request sent, awaiting response... 302 Moved Temporarily Location: https://edelivery.oracle.com/otn-pub/java/jdk/10.0.1+10/fb4372174a714e6b8c52526dc134031e/jdk-10.0.1_linux-x64_bin.tar.gz [following] --2018-07-01 11:04:19-- https://edelivery.oracle.com/otn-pub/java/jdk/10.0.1+10/fb4372174a714e6b8c52526dc134031e/jdk-10.0.1_linux-x64_bin.tar.gz Resolving edelivery.oracle.com (edelivery.oracle.com)... 23.72.169.50 Connecting to edelivery.oracle.com (edelivery.oracle.com)|23.72.169.50|:443... connected. HTTP request sent, awaiting response... 302 Moved Temporarily Location: http://download.oracle.com/otn-pub/java/jdk/10.0.1+10/fb4372174a714e6b8c52526dc134031e/jdk-10.0.1_linux-x64_bin.tar.gz?AuthParam=1530461180_a5ea3c7d2dd9864c93b5a0d9d202ba07 [following] --2018-07-01 11:04:20-- http://download.oracle.com/otn-pub/java/jdk/10.0.1+10/fb4372174a714e6b8c52526dc134031e/jdk-10.0.1_linux-x64_bin.tar.gz?AuthParam=1530461180_a5ea3c7d2dd9864c93b5a0d9d202ba07 Connecting to download.oracle.com (download.oracle.com)|23.45.132.164|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 354846158 (338M) [application/x-gzip] Saving to: ‘jdk-10.0.1_linux-x64_bin.tar.gz’ 0K ........ ........ ........ ........ ........ ........ 0% 169K 33m55s 3072K ........ ........ ........ ........ ........ ........ 1% 131K 38m29s 6144K ........ ........ ........ ........ ........ ........ 2% 28.2K 91m46s 9216K ........ ........ ........ ........ ........ ........ 3% 263K 73m30s 12288K ........ ........ ........ ........ ........ ........ 4% 142K 66m2s 15360K ........ ........ ........ ........ ........ ........ 5% 2.31M 54m54s 18432K ........ ........ ........ ........ ........ ........ 6% 2.06M 46m59s 21504K ........ ........ ........ ........ ........ ........ 7% 1.26M 41m15s 24576K ........ ........ ........ ........ ........ ........ 7% 1.71M 36m39s 27648K ........ ........ ........ ........ ........ ........ 8% 1.35M 33m3s 30720K ........ ........ ........ ........ ........ ........ 9% 1.73M 30m1s 33792K ........ ........ ........ ........ ........ ........ 10% 2.27M 27m26s 36864K ........ ........ ........ ........ ........ ........ 11% 1.61M 25m19s 39936K ........ ........ ........ ........ ........ ........ 12% 2.42M 23m25s 43008K ........ ........ ........ ........ ........ ........ 13% 1.50M 21m51s 46080K ........ ........ ........ ........ ........ ........ 14% 2.26M 20m24s 49152K ........ ........ ........ ........ ........ ........ 15% 2.33M 19m8s 52224K ........ ........ ........ ........ ........ ........ 15% 2.21M 18m0s 55296K ........ ........ ........ ........ ........ ........ 16% 1.58M 17m2s 58368K ........ ........ ........ ........ ........ ........ 17% 1.84M 16m8s 61440K ........ ........ ........ ........ ........ ........ 18% 1.61M 15m20s 64512K ........ ........ ........ ........ ........ ........ 19% 3.04M 14m33s 67584K ........ ........ ........ ........ ........ ........ 20% 2.91M 13m49s 70656K ........ ........ ........ ........ ........ ........ 21% 3.17M 13m9s 73728K ........ ........ ........ ........ ........ ........ 22% 1.36M 12m37s 76800K ........ ........ ........ ........ ........ ........ 23% 1.75M 12m5s 79872K ........ ........ ........ ........ ........ ........ 23% 2.08M 11m35s 82944K ........ ........ ........ ........ ........ ........ 24% 2.50M 11m6s 86016K ........ ........ ........ ........ ........ ........ 25% 1.78M 10m40s 89088K ........ ........ ........ ........ ........ ........ 26% 2.14M 10m16s 92160K ........ ........ ........ ........ ........ ........ 27% 1.56M 9m54s 95232K ........ ........ ........ ........ ........ ........ 28% 2.20M 9m31s 98304K ........ ........ ........ ........ ........ ........ 29% 1.98M 9m11s 101376K ........ ........ ........ ........ ........ ........ 30% 2.28M 8m51s 104448K ........ ........ ........ ........ ........ ........ 31% 2.91M 8m32s 107520K ........ ........ ........ ........ ........ ........ 31% 2.12M 8m14s 110592K ........ ........ ........ ........ ........ ........ 32% 1.76M 7m58s 113664K ........ ........ ........ ........ ........ ........ 33% 2.02M 7m42s 116736K ........ ........ ........ ........ ........ ........ 34% 1.21M 7m29s 119808K ........ ........ ........ ........ ........ ........ 35% 1.12M 7m17s 122880K ........ ........ ........ ........ ........ ........ 36% 1.18M 7m5s 125952K ........ ........ ........ ........ ........ ........ 37% 70.0K 8m3s 129024K ........ ........ ........ ........ ........ ........ 38% 1.40M 7m48s 132096K ........ ........ ........ ........ ........ ........ 39% 84.1K 8m28s 135168K ........ ........ ........ ........ ........ ........ 39% 804K 8m15s 138240K ........ ........ ........ ........ ........ ........ 40% 2.67M 7m59s 141312K ........ ........ ........ ........ ........ ........ 41% 2.88M 7m43s 144384K ........ ........ ........ ........ ........ ........ 42% 2.77M 7m28s 147456K ........ ........ ........ ........ ........ ........ 43% 1.88M 7m14s 150528K ........ ........ ........ ........ ........ ........ 44% 2.53M 7m1s 153600K ........ ........ ........ ........ ........ ........ 45% 2.48M 6m47s 156672K ........ ........ ........ ........ ........ ........ 46% 4.11M 6m34s 159744K ........ ........ ........ ........ ........ ........ 46% 3.75M 6m21s 162816K ........ ........ ........ ........ ........ ........ 47% 4.39M 6m8s 165888K ........ ........ ........ ........ ........ ........ 48% 3.77M 5m56s 168960K ........ ........ ........ ........ ........ ........ 49% 4.56M 5m45s 172032K ........ ........ ........ ........ ........ ........ 50% 3.32M 5m33s 175104K ........ ........ ........ ........ ........ ........ 51% 2.91M 5m23s 178176K ........ ........ ........ ........ ........ ........ 52% 2.38M 5m13s 181248K ........ ........ ........ ........ ........ ........ 53% 3.56M 5m3s 184320K ........ ........ ........ ........ ........ ........ 54% 3.06M 4m53s 187392K ........ ........ ........ ........ ........ ........ 54% 2.72M 4m43s 190464K ........ ........ ........ ........ ........ ........ 55% 2.38M 4m34s 193536K ........ ........ ........ ........ ........ ........ 56% 3.57M 4m25s 196608K ........ ........ ........ ........ ........ ........ 57% 3.46M 4m17s 199680K ........ ........ ........ ........ ........ ........ 58% 3.41M 4m8s 202752K ........ ........ ........ ........ ........ ........ 59% 2.67M 4m0s 205824K ........ ........ ........ ........ ........ ........ 60% 2.92M 3m52s 208896K ........ ........ ........ ........ ........ ........ 61% 2.62M 3m44s 211968K ........ ........ ........ ........ ........ ........ 62% 2.77M 3m37s 215040K ........ ........ ........ ........ ........ ........ 62% 2.68M 3m29s 218112K ........ ........ ........ ........ ........ ........ 63% 3.41M 3m22s 221184K ........ ........ ........ ........ ........ ........ 64% 2.99M 3m15s 224256K ........ ........ ........ ........ ........ ........ 65% 3.98M 3m8s 227328K ........ ........ ........ ........ ........ ........ 66% 3.04M 3m1s 230400K ........ ........ ........ ........ ........ ........ 67% 3.69M 2m54s 233472K ........ ........ ........ ........ ........ ........ 68% 2.00M 2m48s 236544K ........ ........ ........ ........ ........ ........ 69% 2.92M 2m42s 239616K ........ ........ ........ ........ ........ ........ 70% 2.35M 2m36s 242688K ........ ........ ........ ........ ........ ........ 70% 2.55M 2m30s 245760K ........ ........ ........ ........ ........ ........ 71% 2.74M 2m24s 248832K ........ ........ ........ ........ ........ ........ 72% 3.33M 2m18s 251904K ........ ........ ........ ........ ........ ........ 73% 3.94M 2m12s 254976K ........ ........ ........ ........ ........ ........ 74% 2.82M 2m6s 258048K ........ ........ ........ ........ ........ ........ 75% 2.62M 2m1s 261120K ........ ........ ........ ........ ........ ........ 76% 2.76M 1m56s 264192K ........ ........ ........ ........ ........ ........ 77% 3.01M 1m50s 267264K ........ ........ ........ ........ ........ ........ 78% 2.75M 1m45s 270336K ........ ........ ........ ........ ........ ........ 78% 3.23M 1m40s 273408K ........ ........ ........ ........ ........ ........ 79% 3.05M 95s 276480K ........ ........ ........ ........ ........ ........ 80% 3.66M 90s 279552K ........ ........ ........ ........ ........ ........ 81% 2.99M 85s 282624K ........ ........ ........ ........ ........ ........ 82% 2.43M 80s 285696K ........ ........ ........ ........ ........ ........ 83% 2.48M 76s 288768K ........ ........ ........ ........ ........ ........ 84% 2.71M 71s 291840K ........ ........ ........ ........ ........ ........ 85% 2.44M 67s 294912K ........ ........ ........ ........ ........ ........ 85% 2.95M 62s 297984K ........ ........ ........ ........ ........ ........ 86% 2.66M 58s 301056K ........ ........ ........ ........ ........ ........ 87% 2.43M 54s 304128K ........ ........ ........ ........ ........ ........ 88% 2.92M 49s 307200K ........ ........ ........ ........ ........ ........ 89% 2.59M 45s 310272K ........ ........ ........ ........ ........ ........ 90% 3.23M 41s 313344K ........ ........ ........ ........ ........ ........ 91% 2.75M 37s 316416K ........ ........ ........ ........ ........ ........ 92% 3.07M 33s 319488K ........ ........ ........ ........ ........ ........ 93% 2.51M 29s 322560K ........ ........ ........ ........ ........ ........ 93% 2.80M 25s 325632K ........ ........ ........ ........ ........ ........ 94% 2.11M 21s 328704K ........ ........ ........ ........ ........ ........ 95% 2.87M 18s 331776K ........ ........ ........ ........ ........ ........ 96% 2.51M 14s 334848K ........ ........ ........ ........ ........ ........ 97% 2.77M 10s 337920K ........ ........ ........ ........ ........ ........ 98% 3.05M 6s 340992K ........ ........ ........ ........ ........ ........ 99% 3.22M 3s 344064K ........ ........ ........ ........ ...... 100% 2.89M=6m40s 2018-07-01 11:11:00 (867 KB/s) - ‘jdk-10.0.1_linux-x64_bin.tar.gz’ saved [354846158/354846158] Download done. Removing outdated cached downloads... update-alternatives: error: no alternatives for java update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jaotc to provide /usr/bin/jaotc (jaotc) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jar to provide /usr/bin/jar (jar) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/java to provide /usr/bin/java (java) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/javac to provide /usr/bin/javac (javac) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/javap to provide /usr/bin/javap (javap) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/javapackager to provide /usr/bin/javapackager (javapackager) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/javaws to provide /usr/bin/javaws (javaws) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jcontrol to provide /usr/bin/jcontrol (jcontrol) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jmc to provide /usr/bin/jmc (jmc) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jps to provide /usr/bin/jps (jps) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/jweblauncher to provide /usr/bin/jweblauncher (jweblauncher) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode update-alternatives: using /usr/lib/jvm/java-10-oracle/bin/javaws.real to provide /usr/bin/javaws.real (javaws.real) in auto mode Oracle JDK 10 installed #####Important######## To set Oracle jdk10 as default, install the \u0026quot;oracle-java10-set-default\u0026quot; package. E.g.: sudo apt install oracle-java10-set-default. Selecting previously unselected package oracle-java10-set-default. (Reading database ... 239682 files and directories currently installed.) Preparing to unpack .../oracle-java10-set-default_10.0.1-1~linuxuprising+1_amd64.deb ... Unpacking oracle-java10-set-default (10.0.1-1~linuxuprising+1) ... Selecting previously unselected package gsfonts-x11. Preparing to unpack .../gsfonts-x11_0.24_all.deb ... Unpacking gsfonts-x11 (0.24) ... Processing triggers for fontconfig (2.11.94-0ubuntu1.1) ... Setting up oracle-java10-set-default (10.0.1-1~linuxuprising+1) ... Setting up gsfonts-x11 (0.24) ...  sudo apt-get install oracle-java10-set-default Reading package lists... Done Building dependency tree Reading state information... Done oracle-java10-set-default is already the newest version (10.0.1-1~linuxuprising+1). oracle-java10-set-default set to manually installed. 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.  java --version java 10.0.1 2018-04-17 Java(TM) SE Runtime Environment 18.3 (build 10.0.1+10) Java HotSpot(TM) 64-Bit Server VM 18.3 (build 10.0.1+10, mixed mode)  javac --version javac 10.0.1  Create a micro service on the host Details on how to use the new java 10 to create the service are given in the following repo\nUsefull Links  Link1 Link2  "
},
{
	"uri": "/devops/advanced/children/2018-06-26-a/",
	"title": "Zuul",
	"tags": ["zuul"],
	"description": "",
	"content": " Goal OpenStack project are using Zuul for CI/CD process. Zuul itself is based on Ansible to perform the tasks. This post is the collection of notes and tips used during the couple of update I did to some openstack projects.\nUnderstanding Zuul  WIP  Usefull Links  WIP  "
},
{
	"uri": "/devops/git_gerrit/children/2018-06-25-a/",
	"title": "Setup github/gerrit behind a corporate http proxy",
	"tags": ["github"],
	"description": "",
	"content": " Goal This is a post of the small set of notes taken to setup gerrit review behind corporate proxy.\nAccess GitHub/Gerrit from behind a corporate http proxy TBD\nLinks TBD\n"
},
{
	"uri": "/pi_cluster/docker_kubernetes/children/2018-06-24-a/",
	"title": "docker.io versus docker-ce",
	"tags": ["docker"],
	"description": "",
	"content": " Goal Wondering why you have a strange error such as \u0026lsquo;from \u0026hellip;\u0026rsquo; when running docker build. The reason is linked to an older version of docker installed.\nRemove the current docker.io You need to remove the current docker.io.\nsudo apt-cache policy docker.io curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \u0026quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\u0026quot; sudo apt-get update sudo apt-cache policy docker-ce sudo apt-get remove docker docker-engine docker.io sudo apt-get install docker-ce  Forced to run \u0026ldquo;sudo docker\u0026rdquo; instead of docker Run the following command:\nsudo usermod -a -G docker \u0026lt;yourusername\u0026gt;  If you still have issue running docker instead of sudo docker, try to reboot. Worked for me.\nRelated documentation  Link1 Link2  "
},
{
	"uri": "/devops/git_gerrit/children/2018-06-23-a/",
	"title": "Setup multiple GitHub account on a single machine",
	"tags": ["github"],
	"description": "",
	"content": " Goal In orderer to manage your personal GitHub projects or an your compagny projects, it is usefull to be able to conigure your .ssh directory.\nSetup multiple GitHub account TBD\nUsefull Links  Link1  "
},
{
	"uri": "/pi_cluster/microservices/children/2018-06-22-a/",
	"title": "Setup your GOLANG environment",
	"tags": ["golang"],
	"description": "",
	"content": " Goal A lot of the opensource projects evolvoving around Kubernetes are written in go. It is very usefull to be able to rebuild so projects using go get or go build.\nInstalling the right version of GO If you have strange errors, when running go get \u0026hellip;., chances are that your version of GO is old. On Ubuntu, it is actually quite simple to address the issue.\nIf you are still running Ubuntu 16.04 LTS\nsudo add-apt-repository ppa:longsleep/golang-backports sudo apt-get update sudo apt-get install golang-go  How to setup your GOPATH A lot of things seems to work much better if you edit your .bashrc to set GOPATH=$HOME. The advantage of such a setup is that future \u0026ldquo;go get xxx\u0026rdquo; calls, will compile the go file into $HOME/bin which means that new executable will be available without changing your PATH.\nReferences  Link1  "
},
{
	"uri": "/devops/kubedgesdk/children/2018-06-21-a/",
	"title": "Setup SingleNode Kubernetes Cluster using kubeadm",
	"tags": ["kubernetes", "kubeadm"],
	"description": "",
	"content": " Goal Setup simple kubernetes cluster for test purposes.\nAdd Kubernetes APT Repo If you are still running Ubuntu 16.04 LTS\nsudo xxx sudo apt-get update sudo apt-get install kubeadm kubelet kubectl  sudo docker version Client: Version: 1.13.1 API version: 1.26 Go version: go1.6.2 Git commit: 092cba3 Built: Thu Nov 2 20:40:23 2017 OS/Arch: linux/amd64 Server: Version: 1.13.1 API version: 1.26 (minimum version 1.12) Go version: go1.6.2 Git commit: 092cba3 Built: Thu Nov 2 20:40:23 2017 OS/Arch: linux/amd64 Experimental: false  sudo kubeadm version kubeadm version: \u0026amp;version.Info{Major:\u0026quot;1\u0026quot;, Minor:\u0026quot;11\u0026quot;, GitVersion:\u0026quot;v1.11.0\u0026quot;, GitCommit:\u0026quot;91e7b4fd31fcd3d5f436da26c980becec37ceefe\u0026quot;, GitTreeState:\u0026quot;clean\u0026quot;, BuildDate:\u0026quot;2018-06-27T20:14:41Z\u0026quot;, GoVersion:\u0026quot;go1.10.2\u0026quot;, Compiler:\u0026quot;gc\u0026quot;, Platform:\u0026quot;linux/amd64\u0026quot;}  Run Kubeadm First command needs to use sudo\nsudo kubeadm config images pull sudo kubeadm init  Let copy the .kube config into current user home directoru\nmkdir -p $HOME/.kube sudo cp /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config kubectl get all --all-namespaces  From that point don\u0026rsquo;t really need sudo anymore\nAdd Calico At that point most of the node will stay in mode \u0026ldquo;NotReady\u0026rdquo;\nkubectl get nodes NAME STATUS ROLES AGE VERSION allinone NotReady master 1m v1.11.0  To install Calico\nkubectl apply -f https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/kubeadm/1.7/calico.yaml configmap/calico-config created daemonset.extensions/calico-etcd created service/calico-etcd created daemonset.extensions/calico-node created deployment.extensions/calico-kube-controllers created clusterrolebinding.rbac.authorization.k8s.io/calico-cni-plugin created clusterrole.rbac.authorization.k8s.io/calico-cni-plugin created serviceaccount/calico-cni-plugin created clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created serviceaccount/calico-kube-controllers created  Check again\nkubectl get nodes NAME STATUS ROLES AGE VERSION allinone Ready master 2m v1.11.0  Allow payload on master node kubectl get all --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system pod/calico-etcd-d6gn7 1/1 Running 0 1m kube-system pod/calico-kube-controllers-84fd4db7cd-ctctz 1/1 Running 0 1m kube-system pod/calico-node-bg4w8 2/2 Running 0 1m kube-system pod/coredns-78fcdf6894-7d5mf 1/1 Running 0 2m kube-system pod/coredns-78fcdf6894-xv9lm 1/1 Running 0 2m kube-system pod/etcd-allinone 1/1 Running 0 1m kube-system pod/kube-apiserver-allinone 1/1 Running 0 1m kube-system pod/kube-controller-manager-allinone 1/1 Running 0 1m kube-system pod/kube-proxy-zz9t9 1/1 Running 0 2m kube-system pod/kube-scheduler-allinone 1/1 Running 0 1m NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default service/kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 2m kube-system service/calico-etcd ClusterIP 10.96.232.136 \u0026lt;none\u0026gt; 6666/TCP 1m kube-system service/kube-dns ClusterIP 10.96.0.10 \u0026lt;none\u0026gt; 53/UDP,53/TCP 2m NAMESPACE NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE kube-system daemonset.apps/calico-etcd 1 1 1 1 1 node-role.kubernetes.io/master= 1m kube-system daemonset.apps/calico-node 1 1 1 1 1 \u0026lt;none\u0026gt; 1m kube-system daemonset.apps/kube-proxy 1 1 1 1 1 beta.kubernetes.io/arch=amd64 2m NAMESPACE NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE kube-system deployment.apps/calico-kube-controllers 1 1 1 1 1m kube-system deployment.apps/coredns 2 2 2 2 2m NAMESPACE NAME DESIRED CURRENT READY AGE kube-system replicaset.apps/calico-kube-controllers-84fd4db7cd 1 1 1 1m kube-system replicaset.apps/coredns-78fcdf6894  To remove the taint:\nkubectl taint node allinone node-role.kubernetes.io/master:NoSchedule-  Install Helm Create the service account\nkubectl create serviceaccount tiller --namespace kube-system serviceaccount/tiller created  kubectl replace -f rbac-config.yaml serviceaccount/tiller replaced clusterrolebinding.rbac.authorization.k8s.io/tiller replaced  Init Tiller\nhelm init --service-account tiller Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster  kubectl get all -n kube-system NAME READY STATUS RESTARTS AGE pod/calico-etcd-d6gn7 1/1 Running 0 4m pod/calico-kube-controllers-84fd4db7cd-ctctz 1/1 Running 0 4m pod/calico-node-bg4w8 2/2 Running 0 4m pod/coredns-78fcdf6894-7d5mf 1/1 Running 0 5m pod/coredns-78fcdf6894-xv9lm 1/1 Running 0 5m pod/etcd-allinone 1/1 Running 0 5m pod/kube-apiserver-allinone 1/1 Running 0 4m pod/kube-controller-manager-allinone 1/1 Running 0 5m pod/kube-proxy-zz9t9 1/1 Running 0 5m pod/kube-scheduler-allinone 1/1 Running 0 4m pod/tiller-deploy-759cb9df9-wrznl 1/1 Running 0 46s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/calico-etcd ClusterIP 10.96.232.136 \u0026lt;none\u0026gt; 6666/TCP 4m service/kube-dns ClusterIP 10.96.0.10 \u0026lt;none\u0026gt; 53/UDP,53/TCP 6m service/tiller-deploy ClusterIP 10.103.151.9 \u0026lt;none\u0026gt; 44134/TCP 46s NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE daemonset.apps/calico-etcd 1 1 1 1 1 node-role.kubernetes.io/master= 4m daemonset.apps/calico-node 1 1 1 1 1 \u0026lt;none\u0026gt; 4m daemonset.apps/kube-proxy 1 1 1 1 1 beta.kubernetes.io/arch=amd64 6m NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/calico-kube-controllers 1 1 1 1 4m deployment.apps/coredns 2 2 2 2 6m deployment.apps/tiller-deploy 1 1 1 1 46s NAME DESIRED CURRENT READY AGE replicaset.apps/calico-kube-controllers-84fd4db7cd 1 1 1 4m replicaset.apps/coredns-78fcdf6894 2 2 2 5m replicaset.apps/tiller-deploy-759cb9df9 1 1 1 46s  Update the repo\nhelm repo add stable https://kubernetes-charts.storage.googleapis.com \u0026quot;stable\u0026quot; has been added to your repositories  Install and remove nginx\nhelm install stable/nginx-ingress NAME: messy-snake LAST DEPLOYED: Sat Jun 30 18:05:58 2018 NAMESPACE: default STATUS: DEPLOYED RESOURCES: ==\u0026gt; v1beta1/ClusterRoleBinding NAME AGE messy-snake-nginx-ingress 1s ==\u0026gt; v1beta1/Role NAME AGE messy-snake-nginx-ingress 1s ==\u0026gt; v1/ServiceAccount NAME SECRETS AGE messy-snake-nginx-ingress 1 1s ==\u0026gt; v1beta1/ClusterRole NAME AGE messy-snake-nginx-ingress 1s ==\u0026gt; v1/Service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE messy-snake-nginx-ingress-controller LoadBalancer 10.98.107.113 \u0026lt;pending\u0026gt; 80:31098/TCP,443:32158/TCP 1s messy-snake-nginx-ingress-default-backend ClusterIP 10.105.239.60 \u0026lt;none\u0026gt; 80/TCP 1s ==\u0026gt; v1beta1/Deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE messy-snake-nginx-ingress-controller 1 1 1 0 1s messy-snake-nginx-ingress-default-backend 1 1 1 0 1s ==\u0026gt; v1beta1/PodDisruptionBudget NAME MIN AVAILABLE MAX UNAVAILABLE ALLOWED DISRUPTIONS AGE messy-snake-nginx-ingress-controller 1 N/A 0 1s messy-snake-nginx-ingress-default-backend 1 N/A 0 1s ==\u0026gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE messy-snake-nginx-ingress-controller-5db5f96774-ql6nf 0/1 ContainerCreating 0 1s messy-snake-nginx-ingress-default-backend-7f877996b6-zzp82 0/1 ContainerCreating 0 1s ==\u0026gt; v1/ConfigMap NAME DATA AGE messy-snake-nginx-ingress-controller 1 1s ==\u0026gt; v1beta1/RoleBinding NAME AGE messy-snake-nginx-ingress 1s NOTES: The nginx-ingress controller has been installed. It may take a few minutes for the LoadBalancer IP to be available. You can watch the status by running 'kubectl --namespace default get services -o wide -w messy-snake-nginx-ingress-controller' An example Ingress that makes use of the controller: apiVersion: extensions/v1beta1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: nginx name: example namespace: foo spec: rules: - host: www.example.com http: paths: - backend: serviceName: exampleService servicePort: 80 path: / # This section is only required if TLS is to be enabled for the Ingress tls: - hosts: - www.example.com secretName: example-tls If TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided: apiVersion: v1 kind: Secret metadata: name: example-tls namespace: foo data: tls.crt: \u0026lt;base64 encoded cert\u0026gt; tls.key: \u0026lt;base64 encoded key\u0026gt; type: kubernetes.io/tls  helm ls NAME REVISION UPDATED STATUS CHART NAMESPACE messy-snake 1 Sat Jun 30 18:05:58 2018 DEPLOYED nginx-ingress-0.22.0 default  kubectl get all NAME READY STATUS RESTARTS AGE pod/messy-snake-nginx-ingress-controller-5db5f96774-ql6nf 1/1 Running 0 1m pod/messy-snake-nginx-ingress-default-backend-7f877996b6-zzp82 1/1 Running 0 1m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 9m service/messy-snake-nginx-ingress-controller LoadBalancer 10.98.107.113 \u0026lt;pending\u0026gt; 80:31098/TCP,443:32158/TCP 1m service/messy-snake-nginx-ingress-default-backend ClusterIP 10.105.239.60 \u0026lt;none\u0026gt; 80/TCP 1m NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/messy-snake-nginx-ingress-controller 1 1 1 1 1m deployment.apps/messy-snake-nginx-ingress-default-backend 1 1 1 1 1m NAME DESIRED CURRENT READY AGE replicaset.apps/messy-snake-nginx-ingress-controller-5db5f96774 1 1 1 1m replicaset.apps/messy-snake-nginx-ingress-default-backend-7f877996b6 1 1 1 1m  Remove the test chart\nhelm delete messy-snake release \u0026quot;messy-snake\u0026quot; deleted  Use kubeadm to remove everything sudo kubeadm reset sudo docker rm $(sudo docker ps -qa) sudo docker image rm -f $(sudo docker image list -qa)  References  TBD  "
},
{
	"uri": "/pi_cluster/os_installation/children/dongle/",
	"title": "Create a Rapsberry PI Rescue Dongle",
	"tags": ["rpi"],
	"description": "",
	"content": " Goal I encountered multiple issues trying to repartition my SD on my PI. Because the / directory is mounted, it never really worked safely for me to use fdisk. Morevoer some of the powerfull tools such as gparted need X11 installed, which I don\u0026rsquo;t have by default.\nHopefully the new PI3 B and B+ are able to boot from USB, hence the idea of creating a Rescue Dongle\nConsideration regarding USB boot. It seems that all new PI 3B+ have OTP for USB boot mode setup by default. For the PC 3B, you have to activate using the /boot/config.txt\nmaster-pi is a 3B+, nas-pi and home-pi are 3B:\nLet\u0026rsquo;s check the /boot/config.txt\nansible picluster -i inventory/ -m shell -a \u0026quot;grep program_usb_boot_mode /boot/config.txt\u0026quot; master-pi.kubedge.cloud | FAILED | rc=1 \u0026gt;\u0026gt; nas-pi.kubedge.cloud | SUCCESS | rc=0 \u0026gt;\u0026gt; program_usb_boot_mode=1 home-pi.kubedge.cloud | FAILED | rc=1 \u0026gt;\u0026gt;  The flag for OTP USB flag is set on the 3B+ (by default on master-pi) and on the 3B where I did add the entry to the config.txt (nas-pi)\nansible picluster -i inventory/ -m shell -a \u0026quot;vcgencmd otp_dump | grep 17:\u0026quot; master-pi.kubedge.cloud | SUCCESS | rc=0 \u0026gt;\u0026gt; 17:3020000a nas-pi.kubedge.cloud | SUCCESS | rc=0 \u0026gt;\u0026gt; 17:3020000a home-pi.kubedge.cloud | SUCCESS | rc=0 \u0026gt;\u0026gt; 17:1020000a  Creation of the Rescue Dongle  Flash Raspbian on the Dongle using the normal procedure (Wind32DiskImager,..) Remove the SD card from the PI3. Plug keyboard, mouse, screen \u0026hellip; onto the PI Boot the PI3 on the Dongle by removing the SD card Take the time to setup the Raspbian:  Enable VNC Enable SSH Setup default hostname Setup password for Pi account Setup resolution (for VNC later) Install tools such as gparted  Shutdown the PI and put back the normal SD card.  Usage The idea is to boot a PI from the Dongle and then apply the fixes to the SD card.\n Shutdown the PI. Remove the SD card. Insert the Dongle into USB port of PI Reboot the PI. Connect to the PI using the VNC or SSH. The PI has started from the OS installed on the Dongle. Insert the SD card into the PI. You will most likely have a popup and the filesystem from the SD card is automatically mounted. Start to use the tools to fix your SD card. For instance:  Shutdown and reboot. The PI will restart from the SD card.  Application: Change SD card partition First step is to reboot a PI without SD card from the Dongle and connect VNC Viewer to it.\nFirst insert the SD and close the popups In a terminal run, sudo gparted\nsudo gparted unmount the mmc root partition  Resize the current partition (down to 16G), create an extended one and 7*2G logical partition in that 14G partition)  Apply the changes  Shutdown or Reboot. The PI should restart from the SD anyway.  Reference Links  TBD  "
},
{
	"uri": "/pi_cluster/docker_kubernetes/children/2018-06-19-a/",
	"title": "Add Raspberry PI node to Kubernetes Cluster in 10 min",
	"tags": ["kubernetes", "rpi"],
	"description": "",
	"content": " Goal During some of the manipulation of the partition table of my SD card, I ended up screwing up both my SD card and my backup Win32DiskImage backup. Moreover if your SD card is 32G, it takes around 30 minute to restore from backup. Hence the idea to come up with a way to build more resiliency in the cluster. Recreating a node from scratch should not take more than 10 mn. The propose procedure is still rather long because I did not push enough yet what the HypriotOS team, aka build a default SD image where cloud-init does 100% of the initialization work.\nBase OS Flash HypriotOS to SD and reboot Pi.\nFlash the SD Card with HypriotOS Connect Pi through LAN (temporary). Look for black-perl machine in DHCP  Connect to PI through LAN ssh 192.168.1.xxx -l rpiuser ls -lt docker ps  Enable LAN or WLAN. Check the IP address. Depending on PI3B or PI3B+, the WLAN network may be different.\nip a iwconfig sudo ip link set wlan0 up sudo iwlist scan | grep ES sudo iwlist scan | grep ED wpa_passphrase \u0026lt;sommessid\u0026gt; sudo vi sudo vi /etc/network/interfaces.d/wlan0 sudo ifup wlan0  Freeze your configuration Cloud init is perfect for the first boot. Once the node is up, it can be challenging not to preserve the fine tuning done to the OS.\nsudo apt-get remove --purge cloud-init sudo apt-get autoremove  Update your Pi name as root\nsudo -i vi /etc/hosts vi /etc/hostname  I useally don\u0026rsquo;t touch the file. Domain most likely coming from your Internet router. I actually updated the settings on the router to have consistent naming on my PI networks.\nvi /etc/resolv.conf  Install kubeadm Firt access the kubemaster node and regenerate a token:\nkubeadm token create  Back on the new node, as root\ncurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - echo \u0026quot;deb http://apt.kubernetes.io/ kubernetes-xenial main\u0026quot; \u0026gt; /etc/apt/sources.list.d/kubernetes.list apt-get update apt-get install -y kubeadm kubeadm join 192.168.1.95:6443 --token yyyyyy.xxxxxxxxxxxxxxxx --discovery-token-ca-cert-hash sha256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx  Conclusion  Will have to come back later and use cloud-init, create a clean \u0026amp; small SD image for Win32DiskImage Will have to create more advanced partition on the SD card.  "
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/",
	"title": "Shortcodes",
	"tags": [],
	"description": "",
	"content": "Hugo uses Markdown for its simple content format. However, there are a lot of things that Markdown doesn’t support well. You could use pure HTML to expand possibilities.\nBut this happens to be a bad idea. Everyone uses Markdown because it\u0026rsquo;s pure and simple to read even non-rendered. You should avoid HTML to keep it as simple as possible.\nTo avoid this limitations, Hugo created shortcodes. A shortcode is a simple snippet inside a page.\nHugo-theme-learn provides multiple shortcodes on top of existing ones.\n Attachments  The Attachments shortcode displays a list of files attached to a page.\n Button  Nice buttons on your page.\n Children  List the child pages of a page\n Expand  Displays an expandable/collapsible section of text on your page\n Mermaid  Generation of diagram and flowchart from text in a similar manner as markdown\n Notice  Disclaimers to help you structure your page\n Site param  Get value of site params variables in your page.\n "
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/attachments/",
	"title": "Attachments",
	"tags": [],
	"description": "The Attachments shortcode displays a list of files attached to a page.",
	"content": " The Attachments shortcode displays a list of files attached to a page.\n  Attachments   BachGavotteShort.mp3  (357 ko)   Carroll_AliceAuPaysDesMerveilles.pdf  (175 ko)   adivorciarsetoca00cape.pdf  (361 ko)   hugo.png  (17 ko)   movieselectricsheep-flock-244-32500-2.mp4  (340 ko)    Usage The shortcurt lists files found in a specific folder. Currently, it support two implementations for pages\n If your page is a markdown file, attachements must be place in a folder named like your page and ending with .files.\n  content  _index.md page.files  attachment.pdf  page.md    If your page is a folder, attachements must be place in a nested \u0026lsquo;files\u0026rsquo; folder.\n  content  _index.md page  index.md files  attachment.pdf       Be aware that if you use a multilingual website, you will need to have as many folders as languages.\nThat\u0026rsquo;s all !\nParameters    Parameter Default Description     title \u0026ldquo;Attachments\u0026rdquo; List\u0026rsquo;s title   style \u0026rdquo;\u0026rdquo; Choose between \u0026ldquo;orange\u0026rdquo;, \u0026ldquo;grey\u0026rdquo;, \u0026ldquo;blue\u0026rdquo; and \u0026ldquo;green\u0026rdquo; for nice style   pattern \u0026rdquo;.*\u0026rdquo; A regular expressions, used to filter the attachments by file name. The pattern parameter value must be regular expressions.    For example:\n To match a file suffix of \u0026lsquo;jpg\u0026rsquo;, use .*jpg (not *.jpg). To match file names ending in \u0026lsquo;jpg\u0026rsquo; or \u0026lsquo;png\u0026rsquo;, use .*(jpg|png)  Examples List of attachments ending in pdf or mp4 {{%attachments title=\u0026quot;Related files\u0026quot; pattern=\u0026quot;.*(pdf|mp4)\u0026quot;/%}}  renders as\n  Related files   Carroll_AliceAuPaysDesMerveilles.pdf  (175 ko)   adivorciarsetoca00cape.pdf  (361 ko)   movieselectricsheep-flock-244-32500-2.mp4  (340 ko)    Colored styled box {{%attachments style=\u0026quot;orange\u0026quot; /%}}  renders as\n  Attachments   BachGavotteShort.mp3  (357 ko)   Carroll_AliceAuPaysDesMerveilles.pdf  (175 ko)   adivorciarsetoca00cape.pdf  (361 ko)   hugo.png  (17 ko)   movieselectricsheep-flock-244-32500-2.mp4  (340 ko)    {{%attachments style=\u0026quot;grey\u0026quot; /%}}  renders as\n  Attachments   BachGavotteShort.mp3  (357 ko)   Carroll_AliceAuPaysDesMerveilles.pdf  (175 ko)   adivorciarsetoca00cape.pdf  (361 ko)   hugo.png  (17 ko)   movieselectricsheep-flock-244-32500-2.mp4  (340 ko)    {{%attachments style=\u0026quot;blue\u0026quot; /%}}  renders as\n  Attachments   BachGavotteShort.mp3  (357 ko)   Carroll_AliceAuPaysDesMerveilles.pdf  (175 ko)   adivorciarsetoca00cape.pdf  (361 ko)   hugo.png  (17 ko)   movieselectricsheep-flock-244-32500-2.mp4  (340 ko)    {{%attachments style=\u0026quot;green\u0026quot; /%}}  renders as\n  Attachments   BachGavotteShort.mp3  (357 ko)   Carroll_AliceAuPaysDesMerveilles.pdf  (175 ko)   adivorciarsetoca00cape.pdf  (361 ko)   hugo.png  (17 ko)   movieselectricsheep-flock-244-32500-2.mp4  (340 ko)    "
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/button/",
	"title": "Button",
	"tags": [],
	"description": "Nice buttons on your page.",
	"content": "A button is a just a clickable button with optional icon.\n{{% button href=\u0026quot;https://getgrav.org/\u0026quot; %}}Get Grav{{% /button %}} {{% button href=\u0026quot;https://getgrav.org/\u0026quot; icon=\u0026quot;fas fa-download\u0026quot; %}}Get Grav with icon{{% /button %}} {{% button href=\u0026quot;https://getgrav.org/\u0026quot; icon=\u0026quot;fas fa-download\u0026quot; icon-position=\u0026quot;right\u0026quot; %}}Get Grav with icon right{{% /button %}}  Get Grav   Get Grav with icon  Get Grav with icon right   "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/children/",
	"title": "Children",
	"tags": [],
	"description": "List the child pages of a page",
	"content": " Use the children shortcode to list the child pages of a page and the further descendants (children\u0026rsquo;s children). By default, the shortcode displays links to the child pages.\nUsage    Parameter Default Description     page current Specify the page name (section name) to display children for   style \u0026ldquo;li\u0026rdquo; Choose the style used to display descendants. It could be any HTML tag name   showhidden \u0026ldquo;false\u0026rdquo; When true, child pages hidden from the menu will be displayed   description \u0026ldquo;false\u0026rdquo; Allows you to include a short text under each page in the list.when no description exists for the page, children shortcode takes the first 70 words of your content. read more info about summaries on gohugo.io   depth 1 Enter a number to specify the depth of descendants to display. For example, if the value is 2, the shortcode will display 2 levels of child pages.  Tips: set 999 to get all descendants   sort none Sort Children By\nWeight - to sort on menu orderName - to sort alphabetically on menu labelIdentifier - to sort alphabetically on identifier set in frontmatterURL - URL    Demo {{% children %}}   page 1   page 2   page 3   page test   {{% children description=\u0026quot;true\u0026quot; %}}   page 1  This is a demo child page\n page 2  Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n page 3  This is a demo child page\n page test  This is a page test\n {{% children depth=\u0026quot;3\u0026quot; showhidden=\u0026quot;true\u0026quot; %}}   page 1     page 2 \n   page 3 \n   page 4 \n   page test \n  \n{{% children style=\u0026quot;h2\u0026quot; depth=\u0026quot;3\u0026quot; description=\u0026quot;true\u0026quot; %}}   page 1  This is a demo child page\n page 2  Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n page 3  This is a demo child page\n page test  This is a page test\n {{% children style=\u0026quot;div\u0026quot; depth=\u0026quot;999\u0026quot; %}}   page 1   page 2   page 3   page test   "
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/expand/",
	"title": "Expand",
	"tags": [],
	"description": "Displays an expandable/collapsible section of text on your page",
	"content": " The Expand shortcode displays an expandable/collapsible section of text on your page. Here is an example\n  Expand me...   Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n  Usage this shortcode takes exactly one optional parameter to define the text that appears next to the expand/collapse icon. (default is \u0026ldquo;Expand me\u0026hellip;\u0026rdquo;)\n{{%expand \u0026quot;Is this learn theme rocks ?\u0026quot; %}}Yes !.{{% /expand%}}    Is this learn theme rocks ?   Yes !   Demo {{%expand%}} Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. {{% /expand%}}    Expand me...   Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n  "
},
{
	"uri": "/",
	"title": "Kubedge",
	"tags": [],
	"description": "",
	"content": " Kubedge Note: This page and web site is still work in progress.\nPersonal, Portable Edge Network and Lab. Kubedge is personal and portable edge cloud. The key concept is to leverage the three network interfaces available on each PI:\n 1 GB Ethernet Wifi Bluetooth.  The PI are interconnected together using the local switch. The top/master PI is acting as a NAT/Router for the rest of the PI. This main advantage that when you move your lab from home to work, all the IPs of the cluster stay identical.\nDevOps Training Since each PI acts a cloud node, you need to be able to install, manage, test and share the software. Kubedge leverages GitHub and GerritHub to share and review code, Travis-CI for continuous integration. One key aspect is to be able to build executables and docker image that can run on the broadcom processor of the PI. The docker images are available to download on dockerhub.\nIn order to build the present website, we had to understand how to use github pages and well as for instance the Hugo framework to convert the markdown documents into HTML.\nFinally some of the operations are easier to run on your laptop, for instance the development of the software. Kubedge team did create an Ubuntu base virtual machine using an SDK.\nKubernetes Training Lab The assembly of the cluster itself brings its set of lessons. What to be carreful of when you purchase your power supply, the length of your ethernet cables or power supply cables. Differences between the PI 3B+ vs PI 3B (1Gb ethernet instead of 100Mb) have to be accounted when you pick up your switch. Account for having 1 additonal port available on your switch to be able to plug your PC to cluster using Ethernet.\nNext step is to install the OS. Immediatly you will realize that it is unpracticle to plug each node one after the other to an HDMI screen, USB mouse and keyboard in order to perform the first initalization. Some of the OS such HyperiotOS have the great idea to preconfigure the node with SSH enabled, docker. This makes every plug and play: Flush your SD card, connect the PI to your home router and voila you just have to SSH.\nThen you will have to learn how to create a NAT and DHCP server on your master node.\nThe bigger your cluster the quicker you will realize that some of the operations are repetitiv, hence the need for automation. The easiet one to learn is ansible. Put if you install everything on the OS directly, then start the issue of maintaining the OS. Because HyperiotOS comes by default with docker, which brings us back to lesson 1: Have everything has a container.\nThe defacto tools to manage a multi node docker cluster is currently kubernetes. By using kubeadm the installation is quite simple as long as you pay attention that the images pulled by kubernetes are actually the one for PI and not the one for your usual cloud.\nFor people with Kubernetes experience (for instance on GCP), this is where the real lessons start: - A lot of the software is not available by default on PI. How do you recompile calico, tiller\u0026hellip;for the PI. - It is much easier to install components using the Kubernetes HELM but a lot of the helm charts are pulling the AMD64 version of the ARM image. - Finally, how do you create your own helm chart repository using github so that you can run a clean helm add repo and helm install commands.\nAnd mainly, you will started to appreciate go and the new Java 9 modules to actually create true microservices Because both langugage have the ability to create standalone executables, which in turn allow to create containers starting from \u0026ldquo;scratch\u0026rdquo;. Compare it with a python container and you will understand very quickly why it is beneficial. The PI only has 1G of RAM\u0026hellip;which helps to understand the interest of having slim true microservices.\nLTE and 5G Simulator  The upstream wifi network from the master PI acts as the core network. You connect to the internet. The master PI is running the LTE EPC and the 5G CORE components. Some of those of components such as SGW Gateway are running on the Master PI. Some secondary PIs are used to simulate the LTE eNODEb and 5G NR nodes. 5G NR nodes (leveraging the Wifi spectrum). The Ethernet cables act as the backhaul network between the EPC and eNodeB/5G NR. a PI enabling its WIFI access point acts 5G NR nodes and spectrum. a PI enabling its Bluetooth as an Personal Area Network acts an LTE or eLTE eNodeB (and spectrum)  NFV/SDN Network Slicing Simulator Finally currently when the traffic is following through WIFI to ETH0 on the 5G NR node and from ETH0 to WIFI on the EPC node, the routing of the traffic is done using Linux Kernel mainly. The goal here is to build an NFV able to throttle for instance the traffic wifi network (simulating 5G) in order to create a simulation of network slicing. At that point the traffic on the 5G NR node will not go through the kernel but will go from WIFI through the NFV back to ETH0.\nWIP.\nAssociated GIT Repos master branch is mainly used for dev. arm32v7 branch contains stable code for Rasberry PI. amd64 branch contains stable code for AMD64 cluster\nSIMULATOR REPOS:\n kubesim_base kubesim_5gc kubesim_elte kubesim_epc kubesim_lte kubesim_nr  TUTORIAL REPOS:\n kubedge kubeplay  Infrastructure Repos INFRASTRUCTURE REPOS:\n kube-rpi ansible-kube-rpi  Docker imagesi for PI SIMULATOR DOCKER IMAGES FOR PI:\n kubesim_base kubesim_5gc kubesim_elte kubesim_epc kubesim_lte kubesim_nr  TUTORIAL REPOS FOR PI:\n kubedge kubeplay  Docker images for AMD64 SIMULATOR DOCKER IMAGES FOR AMD64:\n kubesim_base kubesim_5gc kubesim_elte kubesim_epc kubesim_lte kubesim_nr  TUTORIAL REPOS FOR AMD64:\n kubedge kubeplay  HELM REPOS  helmrepos  Gerrit Review SIMULATOR REPOS:\n kubesim_base kubesim_5gc kubesim_elte kubesim_epc kubesim_lte kubesim_nr  TUTORIAL REPOS:\n kubedge kubeplay  Automatic Build Review SIMULATOR REPOS:\n kubesim_base kubesim_5gc kubesim_elte kubesim_epc kubesim_lte kubesim_nr  TUTORIAL REPOS:\n kubedge kubeplay  "
},
{
	"uri": "/devops/hugo_githubpages/hugo/",
	"title": "Learn Theme for Hugo",
	"tags": [],
	"description": "",
	"content": " Hugo learn theme Hugo-theme-learn is a theme for Hugo, a fast and modern static website engine written in Go. Where Hugo is often used for blogs, this multilingual-ready theme is fully designed for documentation.\nThis theme is a partial porting of the Learn theme of Grav, a modern flat-file CMS written in PHP.\nLearn theme works with a page tree structure to organize content : All contents are pages, which belong to other pages. [read more about this]()\n Main features  Automatic Search Multilingual mode Unlimited menu levels Automatic next/prev buttons to navigate through menu entries Image resizing, shadow\u0026hellip; Attachments files List child pages Mermaid diagram (flowchart, sequence, gantt) Customizable look and feel and themes variants Buttons, Tip/Note/Info/Warning boxes, Expand  Contribute to this documentation Feel free to update this content, just click the Edit this page link displayed on top right of each page, and pullrequest it\nYour modification will be deployed automatically when merged.\n Documentation website This current documentation has been statically generated with Hugo with a simple command : hugo -t hugo-theme-learn \u0026ndash; source code is available here at GitHub\nAutomatically published and hosted thanks to Netlify. Read more about Automated HUGO deployments with Netlify\n "
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/mermaid/",
	"title": "Mermaid",
	"tags": [],
	"description": "Generation of diagram and flowchart from text in a similar manner as markdown",
	"content": " Mermaid is a library helping you to generate diagram and flowcharts from text, in a similar manner as Markdown.\nJust insert your mermaid code in the mermaid shortcode and that\u0026rsquo;s it.\nFlowchart example {{\u0026lt;mermaid align=\u0026quot;left\u0026quot;\u0026gt;}} graph LR; A[Hard edge] --\u0026gt;|Link text| B(Round edge) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result one] C --\u0026gt;|Two| E[Result two] {{\u0026lt; /mermaid \u0026gt;}}  renders as\ngraph LR; A[Hard edge] --|Link text| B(Round edge) B -- C{Decision} C --|One| D[Result one] C --|Two| E[Result two]  Sequence example {{\u0026lt;mermaid\u0026gt;}} sequenceDiagram participant Alice participant Bob Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts \u0026lt;br/\u0026gt;prevail... John--\u0026gt;Alice: Great! John-\u0026gt;Bob: How about you? Bob--\u0026gt;John: Jolly good! {{\u0026lt; /mermaid \u0026gt;}}  renders as\nsequenceDiagram participant Alice participant Bob Alice-John: Hello John, how are you? loop Healthcheck John-John: Fight against hypochondria end Note right of John: Rational thoughts prevail... John--Alice: Great! John-Bob: How about you? Bob--John: Jolly good!  GANTT Example {{\u0026lt;mermaid\u0026gt;}} gantt dateFormat YYYY-MM-DD title Adding GANTT diagram functionality to mermaid section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d section Critical tasks Completed task in the critical line :crit, done, 2014-01-06,24h Implement parser and jison :crit, done, after des1, 2d Create tests for parser :crit, active, 3d Future task in critical line :crit, 5d Create tests for renderer :2d Add to mermaid :1d {{\u0026lt; /mermaid \u0026gt;}}  render as\ngantt dateFormat YYYY-MM-DD title Adding GANTT diagram functionality to mermaid section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d section Critical tasks Completed task in the critical line :crit, done, 2014-01-06,24h Implement parser and jison :crit, done, after des1, 2d Create tests for parser :crit, active, 3d Future task in critical line :crit, 5d Create tests for renderer :2d Add to mermaid :1d  "
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/notice/",
	"title": "Notice",
	"tags": [],
	"description": "Disclaimers to help you structure your page",
	"content": " The notice shortcode shows 4 types of disclaimers to help you structure your page.\nNote {{% notice note %}} A notice disclaimer {{% /notice %}}  renders as\nA notice disclaimer\n Info {{% notice info %}} An information disclaimer {{% /notice %}}  renders as\nAn information disclaimer\n Tip {{% notice tip %}} A tip disclaimer {{% /notice %}}  renders as\nA tip disclaimer\n Warning {{% notice warning %}} An warning disclaimer {{% /notice %}}  renders as\nA warning disclaimer\n "
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/siteparam/",
	"title": "Site param",
	"tags": [],
	"description": "Get value of site params variables in your page.",
	"content": "siteparam shortcode is used to help you print values of site params.\nFor instance, in this current site, the editURL variable is used in config.toml\n[params] editURL = \u0026quot;https://github.com/matcornic/hugo-theme-learn/edit/master/exampleSite/content/\u0026quot;  Use the siteparam shortcode to display its value.\n`editURL` Value : {{% siteparam \u0026quot;editURL\u0026quot; %}}  is displayed as\neditURL Value : "
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/ansible/",
	"title": "ansible",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/calico/",
	"title": "calico",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/cni/",
	"title": "cni",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/docker/",
	"title": "docker",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/github/",
	"title": "github",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/golang/",
	"title": "golang",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/helm/",
	"title": "helm",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/istio/",
	"title": "istio",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/java/",
	"title": "java",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/kubeadm/",
	"title": "kubeadm",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/kubernetes/",
	"title": "kubernetes",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/kustomize/",
	"title": "kustomize",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/children/children-1/",
	"title": "page 1",
	"tags": [],
	"description": "This is a demo child page",
	"content": "This is a demo child page\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/children/children-1/children-1-1/",
	"title": "page 1-1",
	"tags": [],
	"description": "This is a demo child page",
	"content": "This is a demo child page\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/children/children-1/children-1-1/children-1-1-1/",
	"title": "page 1-1-1",
	"tags": [],
	"description": "This is a demo child page",
	"content": "This is a demo child page\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/children/children-1/children-1-1/children-1-1-1/children-1-1-1-1/",
	"title": "page 1-1-1-1",
	"tags": [],
	"description": "This is a demo child page",
	"content": "This is a demo child page\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/children/children-1/children-1-1/children-1-1-1/children-1-1-1-1/children-1-1-1-1-1/",
	"title": "page 1-1-1-1-1",
	"tags": [],
	"description": "This is a demo child page",
	"content": "This is a demo child page\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/children/children-2/",
	"title": "page 2",
	"tags": [],
	"description": "",
	"content": "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/children/children-3/",
	"title": "page 3",
	"tags": [],
	"description": "This is a demo child page",
	"content": "This is a demo child page, not displayed in the menu\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/children/children-4/",
	"title": "page 4",
	"tags": [],
	"description": "This is a demo child page",
	"content": "This is a demo child page, not displayed in the menu\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/children/test/",
	"title": "page test",
	"tags": [],
	"description": "This is a page test",
	"content": "This is a test demo child page\n"
},
{
	"uri": "/devops/hugo_githubpages/hugo/shortcodes/children/children-2/test3/",
	"title": "page test 3",
	"tags": [],
	"description": "This is a page test",
	"content": "This is a test 3 demo child page\n"
},
{
	"uri": "/tags/portieris/",
	"title": "portieris",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/python/",
	"title": "python",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/rpi/",
	"title": "rpi",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/security/",
	"title": "security",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/sonobuoy/",
	"title": "sonobuoy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/test-infra/",
	"title": "test-infra",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/testing/",
	"title": "testing",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/vault/",
	"title": "vault",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/wiki/",
	"title": "wiki",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/wip/",
	"title": "wip",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/zuul/",
	"title": "zuul",
	"tags": [],
	"description": "",
	"content": ""
}]